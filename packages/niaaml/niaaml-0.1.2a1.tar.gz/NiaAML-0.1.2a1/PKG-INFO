Metadata-Version: 2.1
Name: niaaml
Version: 0.1.2a1
Summary: Python automated machine learning framework.
Home-page: https://github.com/lukapecnik/NiaAML
License: MIT
Keywords: classification,NiaPy,scikit-learn,nature-inspired algorithms,feature selection,preprocessing
Author: Luka Pečnik
Author-email: lukapecnik96@gmail.com
Requires-Python: >=3.8,<4.0
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Requires-Dist: NiaPy (>=2.0.0rc11,<3.0.0)
Requires-Dist: numpy (>=1.19.1,<2.0.0)
Requires-Dist: scikit-learn (>=0.23.2,<0.24.0)
Project-URL: Repository, https://github.com/lukapecnik/NiaAML
Description-Content-Type: text/x-rst

NiaAML
======

NiaAML is an automated machine learning Python framework based on
nature-inspired algorithms for optimization. The name comes from the
automated machine learning method of the same name [1]. Its
goal is to efficiently compose the best possible classification pipeline
for the given task using components on the input. The components are
divided into three groups: feature seletion algorithms, feature
transformation algorithms and classifiers. The framework uses
nature-inspired algorithms for optimization to choose the best set of
components for the classification pipeline on the output and optimize
their parameters. We use `NiaPy framework <https://github.com/NiaOrg/NiaPy>`_ for the optimization process
which is a popular Python collection of nature-inspired algorithms. The
NiaAML framework is easy to use and customize or expand to suit your
needs.

The NiaAML framework allows you not only to run full pipeline optimization, but also separate implemented components such as classifiers, feature selection algorithms, etc. It currently supports only numeric features on the input. **However, we are planning to add support for categorical features too.**

Installation
------------

Install NiaAML with pip:

.. code:: sh

    pip install niaaml

Usage
-----

See the project's `repository <https://github.com/lukapecnik/NiaAML>`_ for usage examples.

Components
----------

In the following sections you can see a list of currently implemented
components divided into groups: classifiers, feature selection
algorithms and feature transformation algorithms. At the end you can
also see a list of currently implemented fitness functions for the
optimization process.

Classifiers
~~~~~~~~~~~

-  Adaptive Boosting (AdaBoost),
-  Bagging (Bagging),
-  Extremely Randomized Trees (ExtremelyRandomizedTrees),
-  Linear SVC (LinearSVC),
-  Multi Layer Perceptron (MultiLayerPerceptron),
-  Random Forest Classifier (RandomForestClassifier).

Feature Selection Algorithms
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

-  Select K Best (SelectKBest),
-  Select Percentile (SelectPercentile),
-  Variance Threshold (VarianceThreshold).

Nature-Inspired
^^^^^^^^^^^^^^^

-  Bat Algorithm (BatAlgorithm),
-  Differential Evolution (DifferentialEvolution),
-  Self-Adaptive Differential Evolution (jDEFSTH),
-  Grey Wolf Optimizer (GreyWolfOptimizer),
-  Particle Swarm Optimization (ParticleSwarmOptimization).

Feature Transformation Algorithms
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

-  Normalizer (Normalizer),
-  Standard Scaler (StandardScaler).

Fitness Functions
~~~~~~~~~~~~~~~~~

-  Accuracy (Accuracy),
-  Cohen's kappa (CohenKappa),
-  F1-Score (F1),
-  Precision (Precision).

Licence
-------

This package is distributed under the MIT License. This license can be
found online at http://www.opensource.org/licenses/MIT.

Disclaimer
----------

This framework is provided as-is, and there are no guarantees that it
fits your purposes or that it is bug-free. Use it at your own risk!

References
----------

[1] Iztok Fister Jr., Milan Zorman, Dušan Fister, Iztok Fister.
Continuous optimizers for automatic design and evaluation of
classification pipelines. In: Frontier applications of nature inspired
computation. Springer tracts in nature-inspired computing, pp.281-301,
2020.

