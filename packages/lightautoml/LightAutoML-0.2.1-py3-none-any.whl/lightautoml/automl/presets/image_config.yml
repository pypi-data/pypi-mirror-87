general_params:
  # possible values are list of ['lgb', 'lgb_tuned', 'linear_l2'] or 'auto'
  use_algos: 'auto'
  skip_conn: False

reader_params:
  samples: 100000
  max_nan_rate: 0.999
  max_constant_rate: 0.999
  cv: 5
  random_state: 42
  roles_params:
  n_jobs: 1
  advanced_roles: True
  # advanced roles parsing params
  # defaults are ok in general case, don't touch it if you don't know it's meanings
  numeric_unique_rate: 0.999
  max_to_3rd_rate: 1.1
  binning_enc_rate: 2
  raw_decr_rate: 1.1
  max_score_rate: 0.2
  abs_score_val: 0.04
  drop_score_co: 0.00

read_csv_params:
  # params for pandas.read_csv func
  decimal: '.'
  sep: ','
  # another params from pandas read_csv docs can be added...


selection_params:
  # selection mode 0/1/2
  # 0 for no selection, 1 - cutoff selection, 2 - iterative selection
  # harder features selection means increasing train time
  mode: 1
  # importance type permutation/gain
  importance_type: 'gain'
  # pretrain selector on holdout set. True - fast/ False - accurate
  fit_on_holdout: True
  cutoff: 0
  feature_group_size: 1
  max_features_cnt_in_result:
  # list of algos to apply selector
  select_algos: [ 'lgb' ]

tuning_params:
  # pretrain tuner on holdout set. True - fast/ False - accurate
  fit_on_holdout: True
  # max tuning iter for lightgbm. Auto - depends on dataset
  # smaller dataset gets more iters
  max_tuning_iter: 101 # 'auto'
  # max tuning time. Tuning time might be set lower depending on timer, but cannot be higher
  max_tuning_time: 300

# params for BoostLGBM MLAlgo
lgb_params:
  default_params: { }
  freeze_defaults: False

# params for LinearLBFGS MLAlgo
# no tuner needed for this algo - regularization params are found during fit
linear_l2_params:
  default_params: { }
  freeze_defaults: False

# params for LinearL1CD MLAlgo
linear_l1_params:
  default_params: { }
  freeze_defaults: False

gbm_pipeline_params:
  top_intersections: 4
  max_intersection_depth: 3
  subsample: 100000
  auto_unique_co: 10
  multiclass_te_co: 3

linear_pipeline_params:
  top_intersections: 4
  max_intersection_depth: 3
  subsample: 100000
  auto_unique_co: 50
  multiclass_te_co: 3

timing_params:
  # select timing mode:
  # 0: no limits - use time limits to create algo's settings but if automl run out of time - let it finish
  # 1: soft - approximate time limits - tasks will finished after timeout
  # 2: hard - hard time limits - stop all tasks before timeout to be exactly in time
  # Any time limitation mode will start working after at least single fold of single model will be computed
  mode: 1
  overhead: 0.1
  # we assume than each algo takes same amount of time to calc. So each algo gets TIME/N_ALGOS.
  # tuning_rate of that time can be given to the params tuner
  # 0 - means no tuning
  # 'auto' - means infer depends on dataset size
  tuning_rate: 0.7

image_pipeline_params:
  # features mode 0/1/2
  # 0 for histogram features, 1 - autocv efficientnet embeddings , 2 - both histogram and embeddings
  feature_mode: 0
  device: 'cuda:0'

cv_simple_features:
  # size of image histogram for each channel
  hist_size: 30
  is_hsv: True
  n_jobs: 4

autocv_features:
  # model name from effnet family
  embed_model: 'efficientnet-b0'
  weights_path: null
  # directory for save / load cache
  cache_dir: './cache_CV'
  subs: 10000
  device: 'cuda:0'
  n_jobs: 4
  random_state: 42
  is_advprop: True
  batch_size: 128
  verbose: True





