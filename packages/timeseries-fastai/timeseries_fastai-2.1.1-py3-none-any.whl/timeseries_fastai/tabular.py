# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/03_tabular.ipynb (unless otherwise specified).

__all__ = ['TabularTS', 'TSPandas', 'setups', 'encodes', 'decodes', 'NormalizeTS', 'setups', 'encodes', 'decodes',
           'ReadTSBatch', 'TabularTSDataloader', 'stack_train_valid']

# Cell
from .imports import *
from .core import *
from fastai.basics import *
from fastai.torch_core import *
from fastai.vision.data import get_grid
from fastai.tabular.core import TabularProc, _TabIloc

# Cell
class TabularTS(CollBase, GetAttr, FilteredBase):
    "A `DataFrame` wrapper that knows which cols are x/y, and returns rows in `__getitem__`"
    _default, with_cont='procs',True
    def __init__(self, df, procs=None, x_names=None, y_names=None, block_y=None, splits=None,
                 do_setup=True, device=None, inplace=False):
        if inplace and splits is not None:
            warn("Using inplace with splits will trigger a pandas error. Set `pd.options.mode.chained_assignment=None` to avoid it.")
        if not inplace: df = df.copy()
        if splits is not None: df = df.iloc[sum(splits, [])]
        self.dataloaders = delegates(self._dl_type.__init__)(self.dataloaders)
        super().__init__(df)

        self.x_names,self.y_names,self.device = L(x_names),L(y_names),device
        if block_y is None and self.y_names:
            # Make ys categorical if they're not numeric
            ys = df[self.y_names]
            if len(ys.select_dtypes(include='number').columns)!=len(ys.columns): block_y = CategoryBlock()
            else: block_y = RegressionBlock()
        if block_y is not None and do_setup:
            if callable(block_y): block_y = block_y()
            procs = L(procs) + block_y.type_tfms
        self.procs = Pipeline(procs)
        self.split = len(df) if splits is None else len(splits[0])
        if do_setup: self.setup()

    def new(self, df):
        return type(self)(df, do_setup=False, block_y=TransformBlock(),
                          **attrdict(self, 'procs','x_names','y_names', 'device'))

    def subset(self, i): return self.new(self.items[slice(0,self.split) if i==0 else slice(self.split,len(self))])
    def copy(self): self.items = self.items.copy(); return self
    def decode(self): return self.procs.decode(self)
    def decode_row(self, row): return self.new(pd.DataFrame(row).T).decode().items.iloc[0]
    def show(self, max_n=10, **kwargs): display_df(self.new(self.all_cols[:max_n]).decode().items)
    def setup(self): self.procs.setup(self)
    def process(self): self.procs(self)
    def loc(self): return self.items.loc
    def iloc(self): return _TabIloc(self)
    def targ(self): return self.items[self.y_names]
    def x_names (self): return self.x_names
    def n_subsets(self): return 2
    def y(self): return self[self.y_names[0]]
    def new_empty(self): return self.new(pd.DataFrame({}, columns=self.items.columns))
    def to_device(self, d=None):
        self.device = d
        return self

    def all_col_names (self):
        ys = [n for n in self.y_names if n in self.items.columns]
        return self.x_names + self.y_names if len(ys) == len(self.y_names) else self.x_names

properties(TabularTS,'loc','iloc','targ','all_col_names','n_subsets','y')

# Cell
class TSPandas(TabularTS):
    def transform(self, cols, f, all_col=True):
        if not all_col: cols = [c for c in cols if c in self.items.columns]
        if len(cols) > 0: self[cols] = self[cols].transform(f)

# Cell
def _add_prop(cls, nm):
    @property
    def f(o): return o[list(getattr(o,nm+'_names'))]
    @f.setter
    def fset(o, v): o[getattr(o,nm+'_names')] = v
    setattr(cls, nm+'s', f)
    setattr(cls, nm+'s', fset)

_add_prop(TabularTS, 'y')
_add_prop(TabularTS, 'x')
_add_prop(TabularTS, 'all_col')

# Cell
def _apply_cats (voc, add, c):
    if not is_categorical_dtype(c):
        return pd.Categorical(c, categories=voc[c.name][add:]).codes+add
    return c.cat.codes+add #if is_categorical_dtype(c) else c.map(voc[c.name].o2i)
def _decode_cats(voc, c): return c.map(dict(enumerate(voc[c.name].items)))

# Cell
@Categorize
def setups(self, to:TabularTS):
    if len(to.y_names) > 0:
        self.vocab = CategoryMap(getattr(to, 'train', to).iloc[:,to.y_names[0]].items)
        self.c = len(self.vocab)
    return self(to)

@Categorize
def encodes(self, to:TabularTS):
    to.transform(to.y_names, partial(_apply_cats, {n: self.vocab for n in to.y_names}, 0), all_col=False)
    return to

@Categorize
def decodes(self, to:TabularTS):
    to.transform(to.y_names, partial(_decode_cats, {n: self.vocab for n in to.y_names}), all_col=False)
    return to

# Cell
class NormalizeTS(TabularProc):
    "Normalize the x variables."
    order = 2
    def setups(self, dsets): self.means,self.stds = dsets.xs.mean(),dsets.xs.std(ddof=0)+1e-7
    def encodes(self, to): to.conts = (to.xs-self.means) / self.stds
    def decodes(self, to): to.conts = (to.xs*self.stds ) + self.means

# Cell
@Normalize
def setups(self, to:TabularTS):
    self.means,self.stds = getattr(to, 'train', to).xs.mean(),getattr(to, 'train', to).xs.std(ddof=0)+1e-7
    return self(to)

@Normalize
def encodes(self, to:TabularTS):
    to.xs = (to.xs-self.means) / self.stds
    return to

@Normalize
def decodes(self, to:TabularTS):
    to.xs = (to.xs*self.stds ) + self.means
    return to

# Cell
def _maybe_expand(o): return o[:,None] if o.ndim==1 else o

# Cell
class ReadTSBatch(ItemTransform):
    def __init__(self, to): self.to = to

    def encodes(self, to):
        res = (tensor(to.xs).float().unsqueeze(1), )
        ys = [n for n in to.y_names if n in to.items.columns]
        if len(ys) == len(to.y_names): res = res + (tensor(to.targ),)
        if to.device is not None: res = to_device(res, to.device)
        return res

    def decodes(self, o):
        o = [_maybe_expand(o_) for o_ in to_np(o) if o_.size != 0]
        vals = np.concatenate(o, axis=1)
        try: df = pd.DataFrame(vals, columns=self.to.all_col_names)
        except: df = pd.DataFrame(vals, columns=self.to.x_names)
        to = self.to.new(df)
        return to

# Cell
@typedispatch
def show_batch(x: TabularTS, y, its, max_n=10, ctxs=None):
    x.show()

# Cell
@delegates()
class TabularTSDataloader(TfmdDL):
    do_item = noops
    def __init__(self, dataset, bs=16, shuffle=False, after_batch=None, num_workers=0, **kwargs):
        if after_batch is None: after_batch = L(TransformBlock().batch_tfms)+ReadTSBatch(dataset)
        super().__init__(dataset, bs=bs, shuffle=shuffle, after_batch=after_batch, num_workers=num_workers, **kwargs)

    def create_batch(self, b): return self.dataset.iloc[b]

TSPandas._dl_type = TabularTSDataloader

# Cell
def stack_train_valid(df_train, df_valid):
    "Stack df_train and df_valid, adds `valid_col`=True/False for df_valid/df_train"
    return pd.concat([df_train.assign(valid_col=False), df_valid.assign(valid_col=True)]).reset_index(drop=True)