# This file was automatically generated by SWIG (http://www.swig.org).
# Version 4.0.1
#
# Do not make changes to this file unless you know what you are doing--modify
# the SWIG interface file instead.


from . import _ITKCommonPython



from sys import version_info as _swig_python_version_info
if _swig_python_version_info < (2, 7, 0):
    raise RuntimeError("Python 2.7 or later required")

# Import the low-level C/C++ module
if __package__ or "." in __name__:
    from . import _itkImageToImageFilterBPython
else:
    import _itkImageToImageFilterBPython

try:
    import builtins as __builtin__
except ImportError:
    import __builtin__

_swig_new_instance_method = _itkImageToImageFilterBPython.SWIG_PyInstanceMethod_New
_swig_new_static_method = _itkImageToImageFilterBPython.SWIG_PyStaticMethod_New

def _swig_repr(self):
    try:
        strthis = "proxy of " + self.this.__repr__()
    except __builtin__.Exception:
        strthis = ""
    return "<%s.%s; %s >" % (self.__class__.__module__, self.__class__.__name__, strthis,)


def _swig_setattr_nondynamic_instance_variable(set):
    def set_instance_attr(self, name, value):
        if name == "thisown":
            self.this.own(value)
        elif name == "this":
            set(self, name, value)
        elif hasattr(self, name) and isinstance(getattr(type(self), name), property):
            set(self, name, value)
        else:
            raise AttributeError("You cannot add instance attributes to %s" % self)
    return set_instance_attr


def _swig_setattr_nondynamic_class_variable(set):
    def set_class_attr(cls, name, value):
        if hasattr(cls, name) and not isinstance(getattr(cls, name), property):
            set(cls, name, value)
        else:
            raise AttributeError("You cannot add class attributes to %s" % cls)
    return set_class_attr


def _swig_add_metaclass(metaclass):
    """Class decorator for adding a metaclass to a SWIG wrapped class - a slimmed down version of six.add_metaclass"""
    def wrapper(cls):
        return metaclass(cls.__name__, cls.__bases__, cls.__dict__.copy())
    return wrapper


class _SwigNonDynamicMeta(type):
    """Meta class to enforce nondynamic attributes (no new attributes) for a class"""
    __setattr__ = _swig_setattr_nondynamic_class_variable(type.__setattr__)


import itk.itkImagePython
import itk.itkRGBAPixelPython
import itk.itkFixedArrayPython
import itk.pyBasePython
import itk.itkPointPython
import itk.vnl_vectorPython
import itk.stdcomplexPython
import itk.vnl_matrixPython
import itk.itkVectorPython
import itk.vnl_vector_refPython
import itk.itkMatrixPython
import itk.vnl_matrix_fixedPython
import itk.itkCovariantVectorPython
import itk.itkSymmetricSecondRankTensorPython
import itk.ITKCommonBasePython
import itk.itkImageRegionPython
import itk.itkSizePython
import itk.itkIndexPython
import itk.itkOffsetPython
import itk.itkRGBPixelPython
import itk.itkVectorImagePython
import itk.itkVariableLengthVectorPython
import itk.itkImageSourcePython
import itk.itkImageSourceCommonPython
import itk.itkImageToImageFilterCommonPython
class itkImageToImageFilterICF2ICF2(itk.itkImageSourcePython.itkImageSourceICF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICF2ICF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF2_cast)

# Register itkImageToImageFilterICF2ICF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF2_swigregister(itkImageToImageFilterICF2ICF2)
itkImageToImageFilterICF2ICF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF2_cast

class itkImageToImageFilterICF2ICF3(itk.itkImageSourcePython.itkImageSourceICF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICF2ICF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF3_cast)

# Register itkImageToImageFilterICF2ICF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF3_swigregister(itkImageToImageFilterICF2ICF3)
itkImageToImageFilterICF2ICF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICF2ICF3_cast

class itkImageToImageFilterICF2ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICF2ID2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ID2_cast)

# Register itkImageToImageFilterICF2ID2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICF2ID2_swigregister(itkImageToImageFilterICF2ID2)
itkImageToImageFilterICF2ID2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICF2ID2_cast

class itkImageToImageFilterICF2IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICF2IF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IF2_cast)

# Register itkImageToImageFilterICF2IF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICF2IF2_swigregister(itkImageToImageFilterICF2IF2)
itkImageToImageFilterICF2IF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICF2IF2_cast

class itkImageToImageFilterICF2ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICF2ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2ISS2_cast)

# Register itkImageToImageFilterICF2ISS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICF2ISS2_swigregister(itkImageToImageFilterICF2ISS2)
itkImageToImageFilterICF2ISS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICF2ISS2_cast

class itkImageToImageFilterICF2IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICF2IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUC2_cast)

# Register itkImageToImageFilterICF2IUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUC2_swigregister(itkImageToImageFilterICF2IUC2)
itkImageToImageFilterICF2IUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICF2IUC2_cast

class itkImageToImageFilterICF2IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICF2IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUS2_cast)

# Register itkImageToImageFilterICF2IUS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICF2IUS2_swigregister(itkImageToImageFilterICF2IUS2)
itkImageToImageFilterICF2IUS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICF2IUS2_cast

class itkImageToImageFilterICF3ICF2(itk.itkImageSourcePython.itkImageSourceICF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICF3ICF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF2_cast)

# Register itkImageToImageFilterICF3ICF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF2_swigregister(itkImageToImageFilterICF3ICF2)
itkImageToImageFilterICF3ICF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF2_cast

class itkImageToImageFilterICF3ICF3(itk.itkImageSourcePython.itkImageSourceICF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICF3ICF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF3_cast)

# Register itkImageToImageFilterICF3ICF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF3_swigregister(itkImageToImageFilterICF3ICF3)
itkImageToImageFilterICF3ICF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICF3ICF3_cast

class itkImageToImageFilterICF3ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICF3ID3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ID3_cast)

# Register itkImageToImageFilterICF3ID3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICF3ID3_swigregister(itkImageToImageFilterICF3ID3)
itkImageToImageFilterICF3ID3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICF3ID3_cast

class itkImageToImageFilterICF3IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICF3IF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IF3_cast)

# Register itkImageToImageFilterICF3IF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICF3IF3_swigregister(itkImageToImageFilterICF3IF3)
itkImageToImageFilterICF3IF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICF3IF3_cast

class itkImageToImageFilterICF3ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICF3ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3ISS3_cast)

# Register itkImageToImageFilterICF3ISS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICF3ISS3_swigregister(itkImageToImageFilterICF3ISS3)
itkImageToImageFilterICF3ISS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICF3ISS3_cast

class itkImageToImageFilterICF3IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICF3IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUC3_cast)

# Register itkImageToImageFilterICF3IUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUC3_swigregister(itkImageToImageFilterICF3IUC3)
itkImageToImageFilterICF3IUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICF3IUC3_cast

class itkImageToImageFilterICF3IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICF3IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUS3_cast)

# Register itkImageToImageFilterICF3IUS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICF3IUS3_swigregister(itkImageToImageFilterICF3IUS3)
itkImageToImageFilterICF3IUS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICF3IUS3_cast

class itkImageToImageFilterICVF22ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF22ID2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ID2_cast)

# Register itkImageToImageFilterICVF22ID2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ID2_swigregister(itkImageToImageFilterICVF22ID2)
itkImageToImageFilterICVF22ID2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF22ID2_cast

class itkImageToImageFilterICVF22IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF22IF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IF2_cast)

# Register itkImageToImageFilterICVF22IF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IF2_swigregister(itkImageToImageFilterICVF22IF2)
itkImageToImageFilterICVF22IF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF22IF2_cast

class itkImageToImageFilterICVF22ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF22ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ISS2_cast)

# Register itkImageToImageFilterICVF22ISS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF22ISS2_swigregister(itkImageToImageFilterICVF22ISS2)
itkImageToImageFilterICVF22ISS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF22ISS2_cast

class itkImageToImageFilterICVF22IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF22IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUC2_cast)

# Register itkImageToImageFilterICVF22IUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUC2_swigregister(itkImageToImageFilterICVF22IUC2)
itkImageToImageFilterICVF22IUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUC2_cast

class itkImageToImageFilterICVF22IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF22IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUS2_cast)

# Register itkImageToImageFilterICVF22IUS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUS2_swigregister(itkImageToImageFilterICVF22IUS2)
itkImageToImageFilterICVF22IUS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF22IUS2_cast

class itkImageToImageFilterICVF23ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF23ID3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ID3_cast)

# Register itkImageToImageFilterICVF23ID3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ID3_swigregister(itkImageToImageFilterICVF23ID3)
itkImageToImageFilterICVF23ID3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF23ID3_cast

class itkImageToImageFilterICVF23IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF23IF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IF3_cast)

# Register itkImageToImageFilterICVF23IF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IF3_swigregister(itkImageToImageFilterICVF23IF3)
itkImageToImageFilterICVF23IF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF23IF3_cast

class itkImageToImageFilterICVF23ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF23ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ISS3_cast)

# Register itkImageToImageFilterICVF23ISS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF23ISS3_swigregister(itkImageToImageFilterICVF23ISS3)
itkImageToImageFilterICVF23ISS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF23ISS3_cast

class itkImageToImageFilterICVF23IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF23IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUC3_cast)

# Register itkImageToImageFilterICVF23IUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUC3_swigregister(itkImageToImageFilterICVF23IUC3)
itkImageToImageFilterICVF23IUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUC3_cast

class itkImageToImageFilterICVF23IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF23IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUS3_cast)

# Register itkImageToImageFilterICVF23IUS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUS3_swigregister(itkImageToImageFilterICVF23IUS3)
itkImageToImageFilterICVF23IUS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF23IUS3_cast

class itkImageToImageFilterICVF32ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF32ID2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ID2_cast)

# Register itkImageToImageFilterICVF32ID2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ID2_swigregister(itkImageToImageFilterICVF32ID2)
itkImageToImageFilterICVF32ID2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF32ID2_cast

class itkImageToImageFilterICVF32IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF32IF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IF2_cast)

# Register itkImageToImageFilterICVF32IF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IF2_swigregister(itkImageToImageFilterICVF32IF2)
itkImageToImageFilterICVF32IF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF32IF2_cast

class itkImageToImageFilterICVF32ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF32ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ISS2_cast)

# Register itkImageToImageFilterICVF32ISS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF32ISS2_swigregister(itkImageToImageFilterICVF32ISS2)
itkImageToImageFilterICVF32ISS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF32ISS2_cast

class itkImageToImageFilterICVF32IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF32IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUC2_cast)

# Register itkImageToImageFilterICVF32IUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUC2_swigregister(itkImageToImageFilterICVF32IUC2)
itkImageToImageFilterICVF32IUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUC2_cast

class itkImageToImageFilterICVF32IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF32IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUS2_cast)

# Register itkImageToImageFilterICVF32IUS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUS2_swigregister(itkImageToImageFilterICVF32IUS2)
itkImageToImageFilterICVF32IUS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF32IUS2_cast

class itkImageToImageFilterICVF33ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF33ID3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ID3_cast)

# Register itkImageToImageFilterICVF33ID3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ID3_swigregister(itkImageToImageFilterICVF33ID3)
itkImageToImageFilterICVF33ID3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF33ID3_cast

class itkImageToImageFilterICVF33IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF33IF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IF3_cast)

# Register itkImageToImageFilterICVF33IF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IF3_swigregister(itkImageToImageFilterICVF33IF3)
itkImageToImageFilterICVF33IF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF33IF3_cast

class itkImageToImageFilterICVF33ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF33ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ISS3_cast)

# Register itkImageToImageFilterICVF33ISS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF33ISS3_swigregister(itkImageToImageFilterICVF33ISS3)
itkImageToImageFilterICVF33ISS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF33ISS3_cast

class itkImageToImageFilterICVF33IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF33IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUC3_cast)

# Register itkImageToImageFilterICVF33IUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUC3_swigregister(itkImageToImageFilterICVF33IUC3)
itkImageToImageFilterICVF33IUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUC3_cast

class itkImageToImageFilterICVF33IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF33IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUS3_cast)

# Register itkImageToImageFilterICVF33IUS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUS3_swigregister(itkImageToImageFilterICVF33IUS3)
itkImageToImageFilterICVF33IUS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF33IUS3_cast

class itkImageToImageFilterICVF42ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF42ID2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ID2_cast)

# Register itkImageToImageFilterICVF42ID2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ID2_swigregister(itkImageToImageFilterICVF42ID2)
itkImageToImageFilterICVF42ID2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF42ID2_cast

class itkImageToImageFilterICVF42IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF42IF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IF2_cast)

# Register itkImageToImageFilterICVF42IF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IF2_swigregister(itkImageToImageFilterICVF42IF2)
itkImageToImageFilterICVF42IF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF42IF2_cast

class itkImageToImageFilterICVF42ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF42ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ISS2_cast)

# Register itkImageToImageFilterICVF42ISS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF42ISS2_swigregister(itkImageToImageFilterICVF42ISS2)
itkImageToImageFilterICVF42ISS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF42ISS2_cast

class itkImageToImageFilterICVF42IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF42IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUC2_cast)

# Register itkImageToImageFilterICVF42IUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUC2_swigregister(itkImageToImageFilterICVF42IUC2)
itkImageToImageFilterICVF42IUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUC2_cast

class itkImageToImageFilterICVF42IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF42IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUS2_cast)

# Register itkImageToImageFilterICVF42IUS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUS2_swigregister(itkImageToImageFilterICVF42IUS2)
itkImageToImageFilterICVF42IUS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF42IUS2_cast

class itkImageToImageFilterICVF43ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF43ID3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ID3_cast)

# Register itkImageToImageFilterICVF43ID3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ID3_swigregister(itkImageToImageFilterICVF43ID3)
itkImageToImageFilterICVF43ID3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF43ID3_cast

class itkImageToImageFilterICVF43IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF43IF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IF3_cast)

# Register itkImageToImageFilterICVF43IF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IF3_swigregister(itkImageToImageFilterICVF43IF3)
itkImageToImageFilterICVF43IF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF43IF3_cast

class itkImageToImageFilterICVF43ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF43ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ISS3_cast)

# Register itkImageToImageFilterICVF43ISS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF43ISS3_swigregister(itkImageToImageFilterICVF43ISS3)
itkImageToImageFilterICVF43ISS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF43ISS3_cast

class itkImageToImageFilterICVF43IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF43IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUC3_cast)

# Register itkImageToImageFilterICVF43IUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUC3_swigregister(itkImageToImageFilterICVF43IUC3)
itkImageToImageFilterICVF43IUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUC3_cast

class itkImageToImageFilterICVF43IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterICVF43IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUS3_cast)

# Register itkImageToImageFilterICVF43IUS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUS3_swigregister(itkImageToImageFilterICVF43IUS3)
itkImageToImageFilterICVF43IUS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterICVF43IUS3_cast

class itkImageToImageFilterID2ICF2(itk.itkImageSourcePython.itkImageSourceICF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID2ICF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICF2_cast)

# Register itkImageToImageFilterID2ICF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID2ICF2_swigregister(itkImageToImageFilterID2ICF2)
itkImageToImageFilterID2ICF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID2ICF2_cast

class itkImageToImageFilterID2ICVD22(itk.itkImageSourcePython.itkImageSourceICVD22):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVD22_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVD22_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVD22_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVD22_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVD22_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVD22_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVD22_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVD22_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVD22_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVD22_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID2ICVD22
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVD22_cast)

# Register itkImageToImageFilterID2ICVD22 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVD22_swigregister(itkImageToImageFilterID2ICVD22)
itkImageToImageFilterID2ICVD22_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID2ICVD22_cast

class itkImageToImageFilterID2ICVF22(itk.itkImageSourcePython.itkImageSourceICVF22):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF22_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF22_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF22_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF22_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF22_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF22_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF22_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF22_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF22_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF22_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID2ICVF22
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF22_cast)

# Register itkImageToImageFilterID2ICVF22 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF22_swigregister(itkImageToImageFilterID2ICVF22)
itkImageToImageFilterID2ICVF22_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF22_cast

class itkImageToImageFilterID2ICVF32(itk.itkImageSourcePython.itkImageSourceICVF32):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF32_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF32_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF32_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF32_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF32_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF32_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF32_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF32_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF32_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF32_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID2ICVF32
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF32_cast)

# Register itkImageToImageFilterID2ICVF32 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF32_swigregister(itkImageToImageFilterID2ICVF32)
itkImageToImageFilterID2ICVF32_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF32_cast

class itkImageToImageFilterID2ICVF42(itk.itkImageSourcePython.itkImageSourceICVF42):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF42_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF42_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF42_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF42_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF42_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF42_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF42_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF42_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF42_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF42_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID2ICVF42
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF42_cast)

# Register itkImageToImageFilterID2ICVF42 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF42_swigregister(itkImageToImageFilterID2ICVF42)
itkImageToImageFilterID2ICVF42_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID2ICVF42_cast

class itkImageToImageFilterID2ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID2ID3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ID3_cast)

# Register itkImageToImageFilterID2ID3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID2ID3_swigregister(itkImageToImageFilterID2ID3)
itkImageToImageFilterID2ID3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID2ID3_cast

class itkImageToImageFilterID2IRGBAUC2(itk.itkImageSourcePython.itkImageSourceIRGBAUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBAUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBAUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBAUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBAUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBAUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBAUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBAUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBAUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBAUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBAUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID2IRGBAUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBAUC2_cast)

# Register itkImageToImageFilterID2IRGBAUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBAUC2_swigregister(itkImageToImageFilterID2IRGBAUC2)
itkImageToImageFilterID2IRGBAUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBAUC2_cast

class itkImageToImageFilterID2IRGBUC2(itk.itkImageSourcePython.itkImageSourceIRGBUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID2IRGBUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBUC2_cast)

# Register itkImageToImageFilterID2IRGBUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBUC2_swigregister(itkImageToImageFilterID2IRGBUC2)
itkImageToImageFilterID2IRGBUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID2IRGBUC2_cast

class itkImageToImageFilterID2ISSRTD22(itk.itkImageSourcePython.itkImageSourceISSRTD22):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ISSRTD22_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ISSRTD22_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ISSRTD22_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ISSRTD22_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ISSRTD22_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ISSRTD22_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ISSRTD22_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ISSRTD22_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ISSRTD22_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ISSRTD22_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID2ISSRTD22
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2ISSRTD22_cast)

# Register itkImageToImageFilterID2ISSRTD22 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID2ISSRTD22_swigregister(itkImageToImageFilterID2ISSRTD22)
itkImageToImageFilterID2ISSRTD22_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID2ISSRTD22_cast

class itkImageToImageFilterID2IVF22(itk.itkImageSourcePython.itkImageSourceIVF22):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF22_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF22_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF22_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF22_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF22_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF22_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF22_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF22_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF22_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF22_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID2IVF22
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF22_cast)

# Register itkImageToImageFilterID2IVF22 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF22_swigregister(itkImageToImageFilterID2IVF22)
itkImageToImageFilterID2IVF22_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID2IVF22_cast

class itkImageToImageFilterID2IVF32(itk.itkImageSourcePython.itkImageSourceIVF32):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF32_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF32_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF32_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF32_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF32_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF32_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF32_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF32_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF32_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF32_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID2IVF32
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF32_cast)

# Register itkImageToImageFilterID2IVF32 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF32_swigregister(itkImageToImageFilterID2IVF32)
itkImageToImageFilterID2IVF32_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID2IVF32_cast

class itkImageToImageFilterID2IVF42(itk.itkImageSourcePython.itkImageSourceIVF42):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF42_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF42_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF42_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF42_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF42_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF42_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF42_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF42_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF42_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF42_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID2IVF42
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF42_cast)

# Register itkImageToImageFilterID2IVF42 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID2IVF42_swigregister(itkImageToImageFilterID2IVF42)
itkImageToImageFilterID2IVF42_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID2IVF42_cast

class itkImageToImageFilterID2VID2(itk.itkImageSourcePython.itkImageSourceVID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID2VID2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VID2_cast)

# Register itkImageToImageFilterID2VID2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID2VID2_swigregister(itkImageToImageFilterID2VID2)
itkImageToImageFilterID2VID2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID2VID2_cast

class itkImageToImageFilterID2VIF2(itk.itkImageSourcePython.itkImageSourceVIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID2VIF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIF2_cast)

# Register itkImageToImageFilterID2VIF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID2VIF2_swigregister(itkImageToImageFilterID2VIF2)
itkImageToImageFilterID2VIF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID2VIF2_cast

class itkImageToImageFilterID2VISS2(itk.itkImageSourcePython.itkImageSourceVISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID2VISS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VISS2_cast)

# Register itkImageToImageFilterID2VISS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID2VISS2_swigregister(itkImageToImageFilterID2VISS2)
itkImageToImageFilterID2VISS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID2VISS2_cast

class itkImageToImageFilterID2VIUC2(itk.itkImageSourcePython.itkImageSourceVIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID2VIUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUC2_cast)

# Register itkImageToImageFilterID2VIUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUC2_swigregister(itkImageToImageFilterID2VIUC2)
itkImageToImageFilterID2VIUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID2VIUC2_cast

class itkImageToImageFilterID2VIUS2(itk.itkImageSourcePython.itkImageSourceVIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID2VIUS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUS2_cast)

# Register itkImageToImageFilterID2VIUS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID2VIUS2_swigregister(itkImageToImageFilterID2VIUS2)
itkImageToImageFilterID2VIUS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID2VIUS2_cast

class itkImageToImageFilterID3ICF3(itk.itkImageSourcePython.itkImageSourceICF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID3ICF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICF3_cast)

# Register itkImageToImageFilterID3ICF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID3ICF3_swigregister(itkImageToImageFilterID3ICF3)
itkImageToImageFilterID3ICF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID3ICF3_cast

class itkImageToImageFilterID3ICVD33(itk.itkImageSourcePython.itkImageSourceICVD33):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVD33_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVD33_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVD33_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVD33_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVD33_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVD33_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVD33_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVD33_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVD33_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVD33_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID3ICVD33
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVD33_cast)

# Register itkImageToImageFilterID3ICVD33 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVD33_swigregister(itkImageToImageFilterID3ICVD33)
itkImageToImageFilterID3ICVD33_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID3ICVD33_cast

class itkImageToImageFilterID3ICVF23(itk.itkImageSourcePython.itkImageSourceICVF23):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF23_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF23_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF23_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF23_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF23_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF23_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF23_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF23_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF23_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF23_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID3ICVF23
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF23_cast)

# Register itkImageToImageFilterID3ICVF23 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF23_swigregister(itkImageToImageFilterID3ICVF23)
itkImageToImageFilterID3ICVF23_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF23_cast

class itkImageToImageFilterID3ICVF33(itk.itkImageSourcePython.itkImageSourceICVF33):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF33_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF33_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF33_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF33_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF33_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF33_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF33_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF33_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF33_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF33_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID3ICVF33
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF33_cast)

# Register itkImageToImageFilterID3ICVF33 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF33_swigregister(itkImageToImageFilterID3ICVF33)
itkImageToImageFilterID3ICVF33_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF33_cast

class itkImageToImageFilterID3ICVF43(itk.itkImageSourcePython.itkImageSourceICVF43):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF43_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF43_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF43_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF43_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF43_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF43_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF43_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF43_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF43_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF43_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID3ICVF43
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF43_cast)

# Register itkImageToImageFilterID3ICVF43 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF43_swigregister(itkImageToImageFilterID3ICVF43)
itkImageToImageFilterID3ICVF43_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID3ICVF43_cast

class itkImageToImageFilterID3ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID3ID2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ID2_cast)

# Register itkImageToImageFilterID3ID2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID3ID2_swigregister(itkImageToImageFilterID3ID2)
itkImageToImageFilterID3ID2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID3ID2_cast

class itkImageToImageFilterID3IRGBAUC3(itk.itkImageSourcePython.itkImageSourceIRGBAUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBAUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBAUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBAUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBAUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBAUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBAUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBAUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBAUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBAUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBAUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID3IRGBAUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBAUC3_cast)

# Register itkImageToImageFilterID3IRGBAUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBAUC3_swigregister(itkImageToImageFilterID3IRGBAUC3)
itkImageToImageFilterID3IRGBAUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBAUC3_cast

class itkImageToImageFilterID3IRGBUC3(itk.itkImageSourcePython.itkImageSourceIRGBUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID3IRGBUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBUC3_cast)

# Register itkImageToImageFilterID3IRGBUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBUC3_swigregister(itkImageToImageFilterID3IRGBUC3)
itkImageToImageFilterID3IRGBUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID3IRGBUC3_cast

class itkImageToImageFilterID3ISSRTD33(itk.itkImageSourcePython.itkImageSourceISSRTD33):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ISSRTD33_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ISSRTD33_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ISSRTD33_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ISSRTD33_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ISSRTD33_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ISSRTD33_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ISSRTD33_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ISSRTD33_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ISSRTD33_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ISSRTD33_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID3ISSRTD33
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3ISSRTD33_cast)

# Register itkImageToImageFilterID3ISSRTD33 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID3ISSRTD33_swigregister(itkImageToImageFilterID3ISSRTD33)
itkImageToImageFilterID3ISSRTD33_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID3ISSRTD33_cast

class itkImageToImageFilterID3IVF23(itk.itkImageSourcePython.itkImageSourceIVF23):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF23_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF23_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF23_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF23_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF23_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF23_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF23_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF23_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF23_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF23_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID3IVF23
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF23_cast)

# Register itkImageToImageFilterID3IVF23 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF23_swigregister(itkImageToImageFilterID3IVF23)
itkImageToImageFilterID3IVF23_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID3IVF23_cast

class itkImageToImageFilterID3IVF33(itk.itkImageSourcePython.itkImageSourceIVF33):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF33_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF33_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF33_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF33_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF33_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF33_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF33_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF33_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF33_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF33_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID3IVF33
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF33_cast)

# Register itkImageToImageFilterID3IVF33 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF33_swigregister(itkImageToImageFilterID3IVF33)
itkImageToImageFilterID3IVF33_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID3IVF33_cast

class itkImageToImageFilterID3IVF43(itk.itkImageSourcePython.itkImageSourceIVF43):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF43_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF43_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF43_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF43_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF43_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF43_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF43_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF43_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF43_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF43_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID3IVF43
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF43_cast)

# Register itkImageToImageFilterID3IVF43 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID3IVF43_swigregister(itkImageToImageFilterID3IVF43)
itkImageToImageFilterID3IVF43_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID3IVF43_cast

class itkImageToImageFilterID3VID3(itk.itkImageSourcePython.itkImageSourceVID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID3VID3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VID3_cast)

# Register itkImageToImageFilterID3VID3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID3VID3_swigregister(itkImageToImageFilterID3VID3)
itkImageToImageFilterID3VID3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID3VID3_cast

class itkImageToImageFilterID3VIF3(itk.itkImageSourcePython.itkImageSourceVIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID3VIF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIF3_cast)

# Register itkImageToImageFilterID3VIF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID3VIF3_swigregister(itkImageToImageFilterID3VIF3)
itkImageToImageFilterID3VIF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID3VIF3_cast

class itkImageToImageFilterID3VISS3(itk.itkImageSourcePython.itkImageSourceVISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID3VISS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VISS3_cast)

# Register itkImageToImageFilterID3VISS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID3VISS3_swigregister(itkImageToImageFilterID3VISS3)
itkImageToImageFilterID3VISS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID3VISS3_cast

class itkImageToImageFilterID3VIUC3(itk.itkImageSourcePython.itkImageSourceVIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID3VIUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUC3_cast)

# Register itkImageToImageFilterID3VIUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUC3_swigregister(itkImageToImageFilterID3VIUC3)
itkImageToImageFilterID3VIUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID3VIUC3_cast

class itkImageToImageFilterID3VIUS3(itk.itkImageSourcePython.itkImageSourceVIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterID3VIUS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUS3_cast)

# Register itkImageToImageFilterID3VIUS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterID3VIUS3_swigregister(itkImageToImageFilterID3VIUS3)
itkImageToImageFilterID3VIUS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterID3VIUS3_cast

class itkImageToImageFilterIF2ICF2(itk.itkImageSourcePython.itkImageSourceICF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF2ICF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICF2_cast)

# Register itkImageToImageFilterIF2ICF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICF2_swigregister(itkImageToImageFilterIF2ICF2)
itkImageToImageFilterIF2ICF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF2ICF2_cast

class itkImageToImageFilterIF2ICVD22(itk.itkImageSourcePython.itkImageSourceICVD22):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVD22_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVD22_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVD22_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVD22_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVD22_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVD22_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVD22_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVD22_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVD22_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVD22_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF2ICVD22
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVD22_cast)

# Register itkImageToImageFilterIF2ICVD22 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVD22_swigregister(itkImageToImageFilterIF2ICVD22)
itkImageToImageFilterIF2ICVD22_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVD22_cast

class itkImageToImageFilterIF2ICVF22(itk.itkImageSourcePython.itkImageSourceICVF22):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF22_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF22_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF22_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF22_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF22_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF22_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF22_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF22_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF22_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF22_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF2ICVF22
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF22_cast)

# Register itkImageToImageFilterIF2ICVF22 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF22_swigregister(itkImageToImageFilterIF2ICVF22)
itkImageToImageFilterIF2ICVF22_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF22_cast

class itkImageToImageFilterIF2ICVF32(itk.itkImageSourcePython.itkImageSourceICVF32):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF32_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF32_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF32_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF32_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF32_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF32_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF32_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF32_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF32_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF32_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF2ICVF32
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF32_cast)

# Register itkImageToImageFilterIF2ICVF32 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF32_swigregister(itkImageToImageFilterIF2ICVF32)
itkImageToImageFilterIF2ICVF32_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF32_cast

class itkImageToImageFilterIF2ICVF42(itk.itkImageSourcePython.itkImageSourceICVF42):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF42_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF42_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF42_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF42_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF42_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF42_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF42_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF42_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF42_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF42_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF2ICVF42
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF42_cast)

# Register itkImageToImageFilterIF2ICVF42 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF42_swigregister(itkImageToImageFilterIF2ICVF42)
itkImageToImageFilterIF2ICVF42_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF2ICVF42_cast

class itkImageToImageFilterIF2IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF2IF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IF3_cast)

# Register itkImageToImageFilterIF2IF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF2IF3_swigregister(itkImageToImageFilterIF2IF3)
itkImageToImageFilterIF2IF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF2IF3_cast

class itkImageToImageFilterIF2IRGBAUC2(itk.itkImageSourcePython.itkImageSourceIRGBAUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBAUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBAUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBAUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBAUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBAUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBAUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBAUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBAUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBAUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBAUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF2IRGBAUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBAUC2_cast)

# Register itkImageToImageFilterIF2IRGBAUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBAUC2_swigregister(itkImageToImageFilterIF2IRGBAUC2)
itkImageToImageFilterIF2IRGBAUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBAUC2_cast

class itkImageToImageFilterIF2IRGBUC2(itk.itkImageSourcePython.itkImageSourceIRGBUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF2IRGBUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBUC2_cast)

# Register itkImageToImageFilterIF2IRGBUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBUC2_swigregister(itkImageToImageFilterIF2IRGBUC2)
itkImageToImageFilterIF2IRGBUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF2IRGBUC2_cast

class itkImageToImageFilterIF2ISSRTD22(itk.itkImageSourcePython.itkImageSourceISSRTD22):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ISSRTD22_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ISSRTD22_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ISSRTD22_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ISSRTD22_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ISSRTD22_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ISSRTD22_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ISSRTD22_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ISSRTD22_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ISSRTD22_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ISSRTD22_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF2ISSRTD22
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2ISSRTD22_cast)

# Register itkImageToImageFilterIF2ISSRTD22 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF2ISSRTD22_swigregister(itkImageToImageFilterIF2ISSRTD22)
itkImageToImageFilterIF2ISSRTD22_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF2ISSRTD22_cast

class itkImageToImageFilterIF2IVF22(itk.itkImageSourcePython.itkImageSourceIVF22):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF22_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF22_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF22_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF22_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF22_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF22_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF22_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF22_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF22_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF22_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF2IVF22
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF22_cast)

# Register itkImageToImageFilterIF2IVF22 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF22_swigregister(itkImageToImageFilterIF2IVF22)
itkImageToImageFilterIF2IVF22_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF22_cast

class itkImageToImageFilterIF2IVF32(itk.itkImageSourcePython.itkImageSourceIVF32):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF32_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF32_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF32_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF32_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF32_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF32_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF32_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF32_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF32_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF32_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF2IVF32
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF32_cast)

# Register itkImageToImageFilterIF2IVF32 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF32_swigregister(itkImageToImageFilterIF2IVF32)
itkImageToImageFilterIF2IVF32_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF32_cast

class itkImageToImageFilterIF2IVF42(itk.itkImageSourcePython.itkImageSourceIVF42):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF42_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF42_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF42_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF42_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF42_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF42_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF42_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF42_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF42_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF42_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF2IVF42
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF42_cast)

# Register itkImageToImageFilterIF2IVF42 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF42_swigregister(itkImageToImageFilterIF2IVF42)
itkImageToImageFilterIF2IVF42_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF2IVF42_cast

class itkImageToImageFilterIF2VID2(itk.itkImageSourcePython.itkImageSourceVID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF2VID2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VID2_cast)

# Register itkImageToImageFilterIF2VID2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF2VID2_swigregister(itkImageToImageFilterIF2VID2)
itkImageToImageFilterIF2VID2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF2VID2_cast

class itkImageToImageFilterIF2VIF2(itk.itkImageSourcePython.itkImageSourceVIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF2VIF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIF2_cast)

# Register itkImageToImageFilterIF2VIF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIF2_swigregister(itkImageToImageFilterIF2VIF2)
itkImageToImageFilterIF2VIF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF2VIF2_cast

class itkImageToImageFilterIF2VISS2(itk.itkImageSourcePython.itkImageSourceVISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF2VISS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VISS2_cast)

# Register itkImageToImageFilterIF2VISS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF2VISS2_swigregister(itkImageToImageFilterIF2VISS2)
itkImageToImageFilterIF2VISS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF2VISS2_cast

class itkImageToImageFilterIF2VIUC2(itk.itkImageSourcePython.itkImageSourceVIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF2VIUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUC2_cast)

# Register itkImageToImageFilterIF2VIUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUC2_swigregister(itkImageToImageFilterIF2VIUC2)
itkImageToImageFilterIF2VIUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUC2_cast

class itkImageToImageFilterIF2VIUS2(itk.itkImageSourcePython.itkImageSourceVIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF2VIUS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUS2_cast)

# Register itkImageToImageFilterIF2VIUS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUS2_swigregister(itkImageToImageFilterIF2VIUS2)
itkImageToImageFilterIF2VIUS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF2VIUS2_cast

class itkImageToImageFilterIF3ICF3(itk.itkImageSourcePython.itkImageSourceICF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF3ICF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICF3_cast)

# Register itkImageToImageFilterIF3ICF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICF3_swigregister(itkImageToImageFilterIF3ICF3)
itkImageToImageFilterIF3ICF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF3ICF3_cast

class itkImageToImageFilterIF3ICVD33(itk.itkImageSourcePython.itkImageSourceICVD33):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVD33_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVD33_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVD33_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVD33_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVD33_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVD33_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVD33_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVD33_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVD33_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVD33_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF3ICVD33
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVD33_cast)

# Register itkImageToImageFilterIF3ICVD33 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVD33_swigregister(itkImageToImageFilterIF3ICVD33)
itkImageToImageFilterIF3ICVD33_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVD33_cast

class itkImageToImageFilterIF3ICVF23(itk.itkImageSourcePython.itkImageSourceICVF23):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF23_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF23_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF23_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF23_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF23_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF23_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF23_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF23_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF23_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF23_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF3ICVF23
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF23_cast)

# Register itkImageToImageFilterIF3ICVF23 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF23_swigregister(itkImageToImageFilterIF3ICVF23)
itkImageToImageFilterIF3ICVF23_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF23_cast

class itkImageToImageFilterIF3ICVF33(itk.itkImageSourcePython.itkImageSourceICVF33):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF33_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF33_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF33_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF33_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF33_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF33_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF33_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF33_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF33_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF33_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF3ICVF33
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF33_cast)

# Register itkImageToImageFilterIF3ICVF33 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF33_swigregister(itkImageToImageFilterIF3ICVF33)
itkImageToImageFilterIF3ICVF33_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF33_cast

class itkImageToImageFilterIF3ICVF43(itk.itkImageSourcePython.itkImageSourceICVF43):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF43_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF43_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF43_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF43_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF43_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF43_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF43_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF43_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF43_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF43_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF3ICVF43
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF43_cast)

# Register itkImageToImageFilterIF3ICVF43 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF43_swigregister(itkImageToImageFilterIF3ICVF43)
itkImageToImageFilterIF3ICVF43_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF3ICVF43_cast

class itkImageToImageFilterIF3IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF3IF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IF2_cast)

# Register itkImageToImageFilterIF3IF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF3IF2_swigregister(itkImageToImageFilterIF3IF2)
itkImageToImageFilterIF3IF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF3IF2_cast

class itkImageToImageFilterIF3IRGBAUC3(itk.itkImageSourcePython.itkImageSourceIRGBAUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBAUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBAUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBAUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBAUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBAUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBAUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBAUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBAUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBAUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBAUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF3IRGBAUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBAUC3_cast)

# Register itkImageToImageFilterIF3IRGBAUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBAUC3_swigregister(itkImageToImageFilterIF3IRGBAUC3)
itkImageToImageFilterIF3IRGBAUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBAUC3_cast

class itkImageToImageFilterIF3IRGBUC3(itk.itkImageSourcePython.itkImageSourceIRGBUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF3IRGBUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBUC3_cast)

# Register itkImageToImageFilterIF3IRGBUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBUC3_swigregister(itkImageToImageFilterIF3IRGBUC3)
itkImageToImageFilterIF3IRGBUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF3IRGBUC3_cast

class itkImageToImageFilterIF3ISSRTD33(itk.itkImageSourcePython.itkImageSourceISSRTD33):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ISSRTD33_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ISSRTD33_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ISSRTD33_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ISSRTD33_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ISSRTD33_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ISSRTD33_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ISSRTD33_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ISSRTD33_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ISSRTD33_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ISSRTD33_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF3ISSRTD33
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3ISSRTD33_cast)

# Register itkImageToImageFilterIF3ISSRTD33 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF3ISSRTD33_swigregister(itkImageToImageFilterIF3ISSRTD33)
itkImageToImageFilterIF3ISSRTD33_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF3ISSRTD33_cast

class itkImageToImageFilterIF3IVF23(itk.itkImageSourcePython.itkImageSourceIVF23):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF23_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF23_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF23_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF23_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF23_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF23_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF23_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF23_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF23_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF23_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF3IVF23
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF23_cast)

# Register itkImageToImageFilterIF3IVF23 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF23_swigregister(itkImageToImageFilterIF3IVF23)
itkImageToImageFilterIF3IVF23_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF23_cast

class itkImageToImageFilterIF3IVF33(itk.itkImageSourcePython.itkImageSourceIVF33):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF33_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF33_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF33_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF33_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF33_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF33_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF33_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF33_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF33_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF33_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF3IVF33
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF33_cast)

# Register itkImageToImageFilterIF3IVF33 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF33_swigregister(itkImageToImageFilterIF3IVF33)
itkImageToImageFilterIF3IVF33_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF33_cast

class itkImageToImageFilterIF3IVF43(itk.itkImageSourcePython.itkImageSourceIVF43):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF43_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF43_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF43_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF43_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF43_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF43_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF43_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF43_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF43_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF43_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF3IVF43
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF43_cast)

# Register itkImageToImageFilterIF3IVF43 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF43_swigregister(itkImageToImageFilterIF3IVF43)
itkImageToImageFilterIF3IVF43_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF3IVF43_cast

class itkImageToImageFilterIF3VID3(itk.itkImageSourcePython.itkImageSourceVID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF3VID3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VID3_cast)

# Register itkImageToImageFilterIF3VID3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF3VID3_swigregister(itkImageToImageFilterIF3VID3)
itkImageToImageFilterIF3VID3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF3VID3_cast

class itkImageToImageFilterIF3VIF3(itk.itkImageSourcePython.itkImageSourceVIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF3VIF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIF3_cast)

# Register itkImageToImageFilterIF3VIF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIF3_swigregister(itkImageToImageFilterIF3VIF3)
itkImageToImageFilterIF3VIF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF3VIF3_cast

class itkImageToImageFilterIF3VISS3(itk.itkImageSourcePython.itkImageSourceVISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF3VISS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VISS3_cast)

# Register itkImageToImageFilterIF3VISS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF3VISS3_swigregister(itkImageToImageFilterIF3VISS3)
itkImageToImageFilterIF3VISS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF3VISS3_cast

class itkImageToImageFilterIF3VIUC3(itk.itkImageSourcePython.itkImageSourceVIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF3VIUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUC3_cast)

# Register itkImageToImageFilterIF3VIUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUC3_swigregister(itkImageToImageFilterIF3VIUC3)
itkImageToImageFilterIF3VIUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUC3_cast

class itkImageToImageFilterIF3VIUS3(itk.itkImageSourcePython.itkImageSourceVIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIF3VIUS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUS3_cast)

# Register itkImageToImageFilterIF3VIUS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUS3_swigregister(itkImageToImageFilterIF3VIUS3)
itkImageToImageFilterIF3VIUS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIF3VIUS3_cast

class itkImageToImageFilterIRGBAUC2ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBAUC2ID2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ID2_cast)

# Register itkImageToImageFilterIRGBAUC2ID2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ID2_swigregister(itkImageToImageFilterIRGBAUC2ID2)
itkImageToImageFilterIRGBAUC2ID2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ID2_cast

class itkImageToImageFilterIRGBAUC2IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBAUC2IF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IF2_cast)

# Register itkImageToImageFilterIRGBAUC2IF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IF2_swigregister(itkImageToImageFilterIRGBAUC2IF2)
itkImageToImageFilterIRGBAUC2IF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IF2_cast

class itkImageToImageFilterIRGBAUC2ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBAUC2ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ISS2_cast)

# Register itkImageToImageFilterIRGBAUC2ISS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ISS2_swigregister(itkImageToImageFilterIRGBAUC2ISS2)
itkImageToImageFilterIRGBAUC2ISS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2ISS2_cast

class itkImageToImageFilterIRGBAUC2IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBAUC2IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUC2_cast)

# Register itkImageToImageFilterIRGBAUC2IUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUC2_swigregister(itkImageToImageFilterIRGBAUC2IUC2)
itkImageToImageFilterIRGBAUC2IUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUC2_cast

class itkImageToImageFilterIRGBAUC2IUL2(itk.itkImageSourcePython.itkImageSourceIUL2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUL2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUL2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUL2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUL2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUL2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUL2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUL2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUL2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUL2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUL2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBAUC2IUL2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUL2_cast)

# Register itkImageToImageFilterIRGBAUC2IUL2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUL2_swigregister(itkImageToImageFilterIRGBAUC2IUL2)
itkImageToImageFilterIRGBAUC2IUL2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUL2_cast

class itkImageToImageFilterIRGBAUC2IULL2(itk.itkImageSourcePython.itkImageSourceIULL2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IULL2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IULL2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IULL2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IULL2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IULL2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IULL2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IULL2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IULL2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IULL2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IULL2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBAUC2IULL2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IULL2_cast)

# Register itkImageToImageFilterIRGBAUC2IULL2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IULL2_swigregister(itkImageToImageFilterIRGBAUC2IULL2)
itkImageToImageFilterIRGBAUC2IULL2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IULL2_cast

class itkImageToImageFilterIRGBAUC2IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBAUC2IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUS2_cast)

# Register itkImageToImageFilterIRGBAUC2IUS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUS2_swigregister(itkImageToImageFilterIRGBAUC2IUS2)
itkImageToImageFilterIRGBAUC2IUS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC2IUS2_cast

class itkImageToImageFilterIRGBAUC3ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBAUC3ID3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ID3_cast)

# Register itkImageToImageFilterIRGBAUC3ID3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ID3_swigregister(itkImageToImageFilterIRGBAUC3ID3)
itkImageToImageFilterIRGBAUC3ID3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ID3_cast

class itkImageToImageFilterIRGBAUC3IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBAUC3IF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IF3_cast)

# Register itkImageToImageFilterIRGBAUC3IF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IF3_swigregister(itkImageToImageFilterIRGBAUC3IF3)
itkImageToImageFilterIRGBAUC3IF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IF3_cast

class itkImageToImageFilterIRGBAUC3ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBAUC3ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ISS3_cast)

# Register itkImageToImageFilterIRGBAUC3ISS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ISS3_swigregister(itkImageToImageFilterIRGBAUC3ISS3)
itkImageToImageFilterIRGBAUC3ISS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3ISS3_cast

class itkImageToImageFilterIRGBAUC3IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBAUC3IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUC3_cast)

# Register itkImageToImageFilterIRGBAUC3IUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUC3_swigregister(itkImageToImageFilterIRGBAUC3IUC3)
itkImageToImageFilterIRGBAUC3IUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUC3_cast

class itkImageToImageFilterIRGBAUC3IUL3(itk.itkImageSourcePython.itkImageSourceIUL3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUL3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUL3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUL3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUL3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUL3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUL3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUL3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUL3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUL3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUL3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBAUC3IUL3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUL3_cast)

# Register itkImageToImageFilterIRGBAUC3IUL3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUL3_swigregister(itkImageToImageFilterIRGBAUC3IUL3)
itkImageToImageFilterIRGBAUC3IUL3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUL3_cast

class itkImageToImageFilterIRGBAUC3IULL3(itk.itkImageSourcePython.itkImageSourceIULL3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IULL3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IULL3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IULL3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IULL3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IULL3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IULL3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IULL3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IULL3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IULL3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IULL3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBAUC3IULL3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IULL3_cast)

# Register itkImageToImageFilterIRGBAUC3IULL3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IULL3_swigregister(itkImageToImageFilterIRGBAUC3IULL3)
itkImageToImageFilterIRGBAUC3IULL3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IULL3_cast

class itkImageToImageFilterIRGBAUC3IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBAUC3IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUS3_cast)

# Register itkImageToImageFilterIRGBAUC3IUS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUS3_swigregister(itkImageToImageFilterIRGBAUC3IUS3)
itkImageToImageFilterIRGBAUC3IUS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBAUC3IUS3_cast

class itkImageToImageFilterIRGBUC2ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBUC2ID2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ID2_cast)

# Register itkImageToImageFilterIRGBUC2ID2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ID2_swigregister(itkImageToImageFilterIRGBUC2ID2)
itkImageToImageFilterIRGBUC2ID2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ID2_cast

class itkImageToImageFilterIRGBUC2IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBUC2IF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IF2_cast)

# Register itkImageToImageFilterIRGBUC2IF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IF2_swigregister(itkImageToImageFilterIRGBUC2IF2)
itkImageToImageFilterIRGBUC2IF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IF2_cast

class itkImageToImageFilterIRGBUC2IRGBUC3(itk.itkImageSourcePython.itkImageSourceIRGBUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IRGBUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IRGBUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IRGBUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IRGBUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IRGBUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IRGBUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IRGBUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IRGBUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IRGBUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IRGBUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBUC2IRGBUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IRGBUC3_cast)

# Register itkImageToImageFilterIRGBUC2IRGBUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IRGBUC3_swigregister(itkImageToImageFilterIRGBUC2IRGBUC3)
itkImageToImageFilterIRGBUC2IRGBUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IRGBUC3_cast

class itkImageToImageFilterIRGBUC2ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBUC2ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ISS2_cast)

# Register itkImageToImageFilterIRGBUC2ISS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ISS2_swigregister(itkImageToImageFilterIRGBUC2ISS2)
itkImageToImageFilterIRGBUC2ISS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2ISS2_cast

class itkImageToImageFilterIRGBUC2IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBUC2IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUC2_cast)

# Register itkImageToImageFilterIRGBUC2IUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUC2_swigregister(itkImageToImageFilterIRGBUC2IUC2)
itkImageToImageFilterIRGBUC2IUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUC2_cast

class itkImageToImageFilterIRGBUC2IUL2(itk.itkImageSourcePython.itkImageSourceIUL2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUL2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUL2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUL2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUL2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUL2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUL2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUL2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUL2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUL2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUL2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBUC2IUL2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUL2_cast)

# Register itkImageToImageFilterIRGBUC2IUL2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUL2_swigregister(itkImageToImageFilterIRGBUC2IUL2)
itkImageToImageFilterIRGBUC2IUL2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUL2_cast

class itkImageToImageFilterIRGBUC2IULL2(itk.itkImageSourcePython.itkImageSourceIULL2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IULL2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IULL2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IULL2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IULL2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IULL2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IULL2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IULL2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IULL2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IULL2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IULL2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBUC2IULL2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IULL2_cast)

# Register itkImageToImageFilterIRGBUC2IULL2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IULL2_swigregister(itkImageToImageFilterIRGBUC2IULL2)
itkImageToImageFilterIRGBUC2IULL2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IULL2_cast

class itkImageToImageFilterIRGBUC2IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBUC2IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUS2_cast)

# Register itkImageToImageFilterIRGBUC2IUS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUS2_swigregister(itkImageToImageFilterIRGBUC2IUS2)
itkImageToImageFilterIRGBUC2IUS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC2IUS2_cast

class itkImageToImageFilterIRGBUC3ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBUC3ID3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ID3_cast)

# Register itkImageToImageFilterIRGBUC3ID3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ID3_swigregister(itkImageToImageFilterIRGBUC3ID3)
itkImageToImageFilterIRGBUC3ID3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ID3_cast

class itkImageToImageFilterIRGBUC3IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBUC3IF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IF3_cast)

# Register itkImageToImageFilterIRGBUC3IF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IF3_swigregister(itkImageToImageFilterIRGBUC3IF3)
itkImageToImageFilterIRGBUC3IF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IF3_cast

class itkImageToImageFilterIRGBUC3IRGBUC2(itk.itkImageSourcePython.itkImageSourceIRGBUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IRGBUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IRGBUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IRGBUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IRGBUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IRGBUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IRGBUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IRGBUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IRGBUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IRGBUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IRGBUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBUC3IRGBUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IRGBUC2_cast)

# Register itkImageToImageFilterIRGBUC3IRGBUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IRGBUC2_swigregister(itkImageToImageFilterIRGBUC3IRGBUC2)
itkImageToImageFilterIRGBUC3IRGBUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IRGBUC2_cast

class itkImageToImageFilterIRGBUC3ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBUC3ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ISS3_cast)

# Register itkImageToImageFilterIRGBUC3ISS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ISS3_swigregister(itkImageToImageFilterIRGBUC3ISS3)
itkImageToImageFilterIRGBUC3ISS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3ISS3_cast

class itkImageToImageFilterIRGBUC3IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBUC3IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUC3_cast)

# Register itkImageToImageFilterIRGBUC3IUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUC3_swigregister(itkImageToImageFilterIRGBUC3IUC3)
itkImageToImageFilterIRGBUC3IUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUC3_cast

class itkImageToImageFilterIRGBUC3IUL3(itk.itkImageSourcePython.itkImageSourceIUL3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUL3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUL3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUL3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUL3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUL3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUL3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUL3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUL3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUL3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUL3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBUC3IUL3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUL3_cast)

# Register itkImageToImageFilterIRGBUC3IUL3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUL3_swigregister(itkImageToImageFilterIRGBUC3IUL3)
itkImageToImageFilterIRGBUC3IUL3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUL3_cast

class itkImageToImageFilterIRGBUC3IULL3(itk.itkImageSourcePython.itkImageSourceIULL3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IULL3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IULL3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IULL3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IULL3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IULL3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IULL3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IULL3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IULL3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IULL3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IULL3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBUC3IULL3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IULL3_cast)

# Register itkImageToImageFilterIRGBUC3IULL3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IULL3_swigregister(itkImageToImageFilterIRGBUC3IULL3)
itkImageToImageFilterIRGBUC3IULL3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IULL3_cast

class itkImageToImageFilterIRGBUC3IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIRGBUC3IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUS3_cast)

# Register itkImageToImageFilterIRGBUC3IUS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUS3_swigregister(itkImageToImageFilterIRGBUC3IUS3)
itkImageToImageFilterIRGBUC3IUS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIRGBUC3IUS3_cast

class itkImageToImageFilterISS2ICF2(itk.itkImageSourcePython.itkImageSourceICF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS2ICF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICF2_cast)

# Register itkImageToImageFilterISS2ICF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICF2_swigregister(itkImageToImageFilterISS2ICF2)
itkImageToImageFilterISS2ICF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS2ICF2_cast

class itkImageToImageFilterISS2ICVF22(itk.itkImageSourcePython.itkImageSourceICVF22):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF22_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF22_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF22_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF22_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF22_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF22_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF22_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF22_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF22_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF22_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS2ICVF22
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF22_cast)

# Register itkImageToImageFilterISS2ICVF22 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF22_swigregister(itkImageToImageFilterISS2ICVF22)
itkImageToImageFilterISS2ICVF22_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF22_cast

class itkImageToImageFilterISS2ICVF32(itk.itkImageSourcePython.itkImageSourceICVF32):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF32_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF32_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF32_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF32_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF32_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF32_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF32_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF32_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF32_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF32_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS2ICVF32
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF32_cast)

# Register itkImageToImageFilterISS2ICVF32 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF32_swigregister(itkImageToImageFilterISS2ICVF32)
itkImageToImageFilterISS2ICVF32_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF32_cast

class itkImageToImageFilterISS2ICVF42(itk.itkImageSourcePython.itkImageSourceICVF42):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF42_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF42_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF42_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF42_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF42_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF42_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF42_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF42_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF42_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF42_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS2ICVF42
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF42_cast)

# Register itkImageToImageFilterISS2ICVF42 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF42_swigregister(itkImageToImageFilterISS2ICVF42)
itkImageToImageFilterISS2ICVF42_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS2ICVF42_cast

class itkImageToImageFilterISS2IRGBAUC2(itk.itkImageSourcePython.itkImageSourceIRGBAUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBAUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBAUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBAUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBAUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBAUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBAUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBAUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBAUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBAUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBAUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS2IRGBAUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBAUC2_cast)

# Register itkImageToImageFilterISS2IRGBAUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBAUC2_swigregister(itkImageToImageFilterISS2IRGBAUC2)
itkImageToImageFilterISS2IRGBAUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBAUC2_cast

class itkImageToImageFilterISS2IRGBUC2(itk.itkImageSourcePython.itkImageSourceIRGBUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS2IRGBUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBUC2_cast)

# Register itkImageToImageFilterISS2IRGBUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBUC2_swigregister(itkImageToImageFilterISS2IRGBUC2)
itkImageToImageFilterISS2IRGBUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS2IRGBUC2_cast

class itkImageToImageFilterISS2ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS2ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISS3_cast)

# Register itkImageToImageFilterISS2ISS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISS3_swigregister(itkImageToImageFilterISS2ISS3)
itkImageToImageFilterISS2ISS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS2ISS3_cast

class itkImageToImageFilterISS2ISSRTD22(itk.itkImageSourcePython.itkImageSourceISSRTD22):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISSRTD22_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISSRTD22_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISSRTD22_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISSRTD22_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISSRTD22_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISSRTD22_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISSRTD22_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISSRTD22_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISSRTD22_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISSRTD22_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS2ISSRTD22
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISSRTD22_cast)

# Register itkImageToImageFilterISS2ISSRTD22 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS2ISSRTD22_swigregister(itkImageToImageFilterISS2ISSRTD22)
itkImageToImageFilterISS2ISSRTD22_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS2ISSRTD22_cast

class itkImageToImageFilterISS2IVF22(itk.itkImageSourcePython.itkImageSourceIVF22):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF22_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF22_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF22_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF22_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF22_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF22_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF22_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF22_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF22_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF22_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS2IVF22
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF22_cast)

# Register itkImageToImageFilterISS2IVF22 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF22_swigregister(itkImageToImageFilterISS2IVF22)
itkImageToImageFilterISS2IVF22_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF22_cast

class itkImageToImageFilterISS2IVF32(itk.itkImageSourcePython.itkImageSourceIVF32):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF32_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF32_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF32_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF32_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF32_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF32_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF32_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF32_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF32_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF32_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS2IVF32
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF32_cast)

# Register itkImageToImageFilterISS2IVF32 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF32_swigregister(itkImageToImageFilterISS2IVF32)
itkImageToImageFilterISS2IVF32_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF32_cast

class itkImageToImageFilterISS2IVF42(itk.itkImageSourcePython.itkImageSourceIVF42):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF42_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF42_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF42_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF42_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF42_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF42_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF42_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF42_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF42_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF42_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS2IVF42
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF42_cast)

# Register itkImageToImageFilterISS2IVF42 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF42_swigregister(itkImageToImageFilterISS2IVF42)
itkImageToImageFilterISS2IVF42_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS2IVF42_cast

class itkImageToImageFilterISS2VID2(itk.itkImageSourcePython.itkImageSourceVID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS2VID2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VID2_cast)

# Register itkImageToImageFilterISS2VID2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS2VID2_swigregister(itkImageToImageFilterISS2VID2)
itkImageToImageFilterISS2VID2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS2VID2_cast

class itkImageToImageFilterISS2VIF2(itk.itkImageSourcePython.itkImageSourceVIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS2VIF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIF2_cast)

# Register itkImageToImageFilterISS2VIF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIF2_swigregister(itkImageToImageFilterISS2VIF2)
itkImageToImageFilterISS2VIF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS2VIF2_cast

class itkImageToImageFilterISS2VISS2(itk.itkImageSourcePython.itkImageSourceVISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS2VISS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VISS2_cast)

# Register itkImageToImageFilterISS2VISS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS2VISS2_swigregister(itkImageToImageFilterISS2VISS2)
itkImageToImageFilterISS2VISS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS2VISS2_cast

class itkImageToImageFilterISS2VIUC2(itk.itkImageSourcePython.itkImageSourceVIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS2VIUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUC2_cast)

# Register itkImageToImageFilterISS2VIUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUC2_swigregister(itkImageToImageFilterISS2VIUC2)
itkImageToImageFilterISS2VIUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUC2_cast

class itkImageToImageFilterISS2VIUS2(itk.itkImageSourcePython.itkImageSourceVIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS2VIUS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUS2_cast)

# Register itkImageToImageFilterISS2VIUS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUS2_swigregister(itkImageToImageFilterISS2VIUS2)
itkImageToImageFilterISS2VIUS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS2VIUS2_cast

class itkImageToImageFilterISS3ICF3(itk.itkImageSourcePython.itkImageSourceICF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS3ICF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICF3_cast)

# Register itkImageToImageFilterISS3ICF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICF3_swigregister(itkImageToImageFilterISS3ICF3)
itkImageToImageFilterISS3ICF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS3ICF3_cast

class itkImageToImageFilterISS3ICVF23(itk.itkImageSourcePython.itkImageSourceICVF23):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF23_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF23_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF23_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF23_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF23_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF23_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF23_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF23_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF23_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF23_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS3ICVF23
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF23_cast)

# Register itkImageToImageFilterISS3ICVF23 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF23_swigregister(itkImageToImageFilterISS3ICVF23)
itkImageToImageFilterISS3ICVF23_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF23_cast

class itkImageToImageFilterISS3ICVF33(itk.itkImageSourcePython.itkImageSourceICVF33):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF33_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF33_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF33_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF33_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF33_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF33_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF33_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF33_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF33_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF33_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS3ICVF33
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF33_cast)

# Register itkImageToImageFilterISS3ICVF33 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF33_swigregister(itkImageToImageFilterISS3ICVF33)
itkImageToImageFilterISS3ICVF33_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF33_cast

class itkImageToImageFilterISS3ICVF43(itk.itkImageSourcePython.itkImageSourceICVF43):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF43_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF43_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF43_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF43_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF43_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF43_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF43_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF43_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF43_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF43_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS3ICVF43
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF43_cast)

# Register itkImageToImageFilterISS3ICVF43 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF43_swigregister(itkImageToImageFilterISS3ICVF43)
itkImageToImageFilterISS3ICVF43_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS3ICVF43_cast

class itkImageToImageFilterISS3IRGBAUC3(itk.itkImageSourcePython.itkImageSourceIRGBAUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBAUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBAUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBAUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBAUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBAUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBAUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBAUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBAUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBAUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBAUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS3IRGBAUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBAUC3_cast)

# Register itkImageToImageFilterISS3IRGBAUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBAUC3_swigregister(itkImageToImageFilterISS3IRGBAUC3)
itkImageToImageFilterISS3IRGBAUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBAUC3_cast

class itkImageToImageFilterISS3IRGBUC3(itk.itkImageSourcePython.itkImageSourceIRGBUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS3IRGBUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBUC3_cast)

# Register itkImageToImageFilterISS3IRGBUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBUC3_swigregister(itkImageToImageFilterISS3IRGBUC3)
itkImageToImageFilterISS3IRGBUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS3IRGBUC3_cast

class itkImageToImageFilterISS3ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS3ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISS2_cast)

# Register itkImageToImageFilterISS3ISS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISS2_swigregister(itkImageToImageFilterISS3ISS2)
itkImageToImageFilterISS3ISS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS3ISS2_cast

class itkImageToImageFilterISS3ISSRTD33(itk.itkImageSourcePython.itkImageSourceISSRTD33):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISSRTD33_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISSRTD33_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISSRTD33_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISSRTD33_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISSRTD33_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISSRTD33_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISSRTD33_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISSRTD33_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISSRTD33_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISSRTD33_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS3ISSRTD33
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISSRTD33_cast)

# Register itkImageToImageFilterISS3ISSRTD33 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS3ISSRTD33_swigregister(itkImageToImageFilterISS3ISSRTD33)
itkImageToImageFilterISS3ISSRTD33_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS3ISSRTD33_cast

class itkImageToImageFilterISS3IVF23(itk.itkImageSourcePython.itkImageSourceIVF23):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF23_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF23_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF23_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF23_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF23_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF23_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF23_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF23_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF23_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF23_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS3IVF23
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF23_cast)

# Register itkImageToImageFilterISS3IVF23 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF23_swigregister(itkImageToImageFilterISS3IVF23)
itkImageToImageFilterISS3IVF23_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF23_cast

class itkImageToImageFilterISS3IVF33(itk.itkImageSourcePython.itkImageSourceIVF33):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF33_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF33_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF33_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF33_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF33_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF33_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF33_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF33_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF33_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF33_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS3IVF33
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF33_cast)

# Register itkImageToImageFilterISS3IVF33 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF33_swigregister(itkImageToImageFilterISS3IVF33)
itkImageToImageFilterISS3IVF33_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF33_cast

class itkImageToImageFilterISS3IVF43(itk.itkImageSourcePython.itkImageSourceIVF43):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF43_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF43_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF43_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF43_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF43_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF43_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF43_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF43_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF43_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF43_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS3IVF43
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF43_cast)

# Register itkImageToImageFilterISS3IVF43 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF43_swigregister(itkImageToImageFilterISS3IVF43)
itkImageToImageFilterISS3IVF43_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS3IVF43_cast

class itkImageToImageFilterISS3VID3(itk.itkImageSourcePython.itkImageSourceVID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS3VID3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VID3_cast)

# Register itkImageToImageFilterISS3VID3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS3VID3_swigregister(itkImageToImageFilterISS3VID3)
itkImageToImageFilterISS3VID3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS3VID3_cast

class itkImageToImageFilterISS3VIF3(itk.itkImageSourcePython.itkImageSourceVIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS3VIF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIF3_cast)

# Register itkImageToImageFilterISS3VIF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIF3_swigregister(itkImageToImageFilterISS3VIF3)
itkImageToImageFilterISS3VIF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS3VIF3_cast

class itkImageToImageFilterISS3VISS3(itk.itkImageSourcePython.itkImageSourceVISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS3VISS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VISS3_cast)

# Register itkImageToImageFilterISS3VISS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS3VISS3_swigregister(itkImageToImageFilterISS3VISS3)
itkImageToImageFilterISS3VISS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS3VISS3_cast

class itkImageToImageFilterISS3VIUC3(itk.itkImageSourcePython.itkImageSourceVIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS3VIUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUC3_cast)

# Register itkImageToImageFilterISS3VIUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUC3_swigregister(itkImageToImageFilterISS3VIUC3)
itkImageToImageFilterISS3VIUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUC3_cast

class itkImageToImageFilterISS3VIUS3(itk.itkImageSourcePython.itkImageSourceVIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISS3VIUS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUS3_cast)

# Register itkImageToImageFilterISS3VIUS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUS3_swigregister(itkImageToImageFilterISS3VIUS3)
itkImageToImageFilterISS3VIUS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISS3VIUS3_cast

class itkImageToImageFilterISSRTD22ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISSRTD22ID2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ID2_cast)

# Register itkImageToImageFilterISSRTD22ID2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ID2_swigregister(itkImageToImageFilterISSRTD22ID2)
itkImageToImageFilterISSRTD22ID2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ID2_cast

class itkImageToImageFilterISSRTD22IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISSRTD22IF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IF2_cast)

# Register itkImageToImageFilterISSRTD22IF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IF2_swigregister(itkImageToImageFilterISSRTD22IF2)
itkImageToImageFilterISSRTD22IF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IF2_cast

class itkImageToImageFilterISSRTD22ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISSRTD22ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISS2_cast)

# Register itkImageToImageFilterISSRTD22ISS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISS2_swigregister(itkImageToImageFilterISSRTD22ISS2)
itkImageToImageFilterISSRTD22ISS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISS2_cast

class itkImageToImageFilterISSRTD22ISSRTD22(itk.itkImageSourcePython.itkImageSourceISSRTD22):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISSRTD22_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISSRTD22_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISSRTD22_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISSRTD22_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISSRTD22_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISSRTD22_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISSRTD22_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISSRTD22_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISSRTD22_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISSRTD22_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISSRTD22ISSRTD22
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISSRTD22_cast)

# Register itkImageToImageFilterISSRTD22ISSRTD22 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISSRTD22_swigregister(itkImageToImageFilterISSRTD22ISSRTD22)
itkImageToImageFilterISSRTD22ISSRTD22_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22ISSRTD22_cast

class itkImageToImageFilterISSRTD22IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISSRTD22IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUC2_cast)

# Register itkImageToImageFilterISSRTD22IUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUC2_swigregister(itkImageToImageFilterISSRTD22IUC2)
itkImageToImageFilterISSRTD22IUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUC2_cast

class itkImageToImageFilterISSRTD22IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISSRTD22IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUS2_cast)

# Register itkImageToImageFilterISSRTD22IUS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUS2_swigregister(itkImageToImageFilterISSRTD22IUS2)
itkImageToImageFilterISSRTD22IUS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISSRTD22IUS2_cast

class itkImageToImageFilterISSRTD33ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISSRTD33ID3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ID3_cast)

# Register itkImageToImageFilterISSRTD33ID3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ID3_swigregister(itkImageToImageFilterISSRTD33ID3)
itkImageToImageFilterISSRTD33ID3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ID3_cast

class itkImageToImageFilterISSRTD33IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISSRTD33IF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IF3_cast)

# Register itkImageToImageFilterISSRTD33IF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IF3_swigregister(itkImageToImageFilterISSRTD33IF3)
itkImageToImageFilterISSRTD33IF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IF3_cast

class itkImageToImageFilterISSRTD33ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISSRTD33ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISS3_cast)

# Register itkImageToImageFilterISSRTD33ISS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISS3_swigregister(itkImageToImageFilterISSRTD33ISS3)
itkImageToImageFilterISSRTD33ISS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISS3_cast

class itkImageToImageFilterISSRTD33ISSRTD33(itk.itkImageSourcePython.itkImageSourceISSRTD33):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISSRTD33_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISSRTD33_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISSRTD33_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISSRTD33_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISSRTD33_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISSRTD33_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISSRTD33_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISSRTD33_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISSRTD33_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISSRTD33_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISSRTD33ISSRTD33
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISSRTD33_cast)

# Register itkImageToImageFilterISSRTD33ISSRTD33 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISSRTD33_swigregister(itkImageToImageFilterISSRTD33ISSRTD33)
itkImageToImageFilterISSRTD33ISSRTD33_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33ISSRTD33_cast

class itkImageToImageFilterISSRTD33IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISSRTD33IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUC3_cast)

# Register itkImageToImageFilterISSRTD33IUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUC3_swigregister(itkImageToImageFilterISSRTD33IUC3)
itkImageToImageFilterISSRTD33IUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUC3_cast

class itkImageToImageFilterISSRTD33IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterISSRTD33IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUS3_cast)

# Register itkImageToImageFilterISSRTD33IUS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUS3_swigregister(itkImageToImageFilterISSRTD33IUS3)
itkImageToImageFilterISSRTD33IUS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterISSRTD33IUS3_cast

class itkImageToImageFilterIUC2ICF2(itk.itkImageSourcePython.itkImageSourceICF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC2ICF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICF2_cast)

# Register itkImageToImageFilterIUC2ICF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICF2_swigregister(itkImageToImageFilterIUC2ICF2)
itkImageToImageFilterIUC2ICF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICF2_cast

class itkImageToImageFilterIUC2ICVF22(itk.itkImageSourcePython.itkImageSourceICVF22):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF22_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF22_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF22_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF22_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF22_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF22_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF22_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF22_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF22_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF22_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC2ICVF22
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF22_cast)

# Register itkImageToImageFilterIUC2ICVF22 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF22_swigregister(itkImageToImageFilterIUC2ICVF22)
itkImageToImageFilterIUC2ICVF22_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF22_cast

class itkImageToImageFilterIUC2ICVF32(itk.itkImageSourcePython.itkImageSourceICVF32):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF32_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF32_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF32_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF32_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF32_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF32_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF32_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF32_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF32_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF32_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC2ICVF32
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF32_cast)

# Register itkImageToImageFilterIUC2ICVF32 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF32_swigregister(itkImageToImageFilterIUC2ICVF32)
itkImageToImageFilterIUC2ICVF32_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF32_cast

class itkImageToImageFilterIUC2ICVF42(itk.itkImageSourcePython.itkImageSourceICVF42):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF42_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF42_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF42_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF42_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF42_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF42_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF42_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF42_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF42_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF42_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC2ICVF42
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF42_cast)

# Register itkImageToImageFilterIUC2ICVF42 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF42_swigregister(itkImageToImageFilterIUC2ICVF42)
itkImageToImageFilterIUC2ICVF42_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC2ICVF42_cast

class itkImageToImageFilterIUC2IRGBAUC2(itk.itkImageSourcePython.itkImageSourceIRGBAUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBAUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBAUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBAUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBAUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBAUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBAUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBAUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBAUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBAUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBAUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC2IRGBAUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBAUC2_cast)

# Register itkImageToImageFilterIUC2IRGBAUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBAUC2_swigregister(itkImageToImageFilterIUC2IRGBAUC2)
itkImageToImageFilterIUC2IRGBAUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBAUC2_cast

class itkImageToImageFilterIUC2IRGBUC2(itk.itkImageSourcePython.itkImageSourceIRGBUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC2IRGBUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBUC2_cast)

# Register itkImageToImageFilterIUC2IRGBUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBUC2_swigregister(itkImageToImageFilterIUC2IRGBUC2)
itkImageToImageFilterIUC2IRGBUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC2IRGBUC2_cast

class itkImageToImageFilterIUC2ISSRTD22(itk.itkImageSourcePython.itkImageSourceISSRTD22):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ISSRTD22_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ISSRTD22_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ISSRTD22_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ISSRTD22_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ISSRTD22_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ISSRTD22_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ISSRTD22_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ISSRTD22_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ISSRTD22_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ISSRTD22_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC2ISSRTD22
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ISSRTD22_cast)

# Register itkImageToImageFilterIUC2ISSRTD22 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC2ISSRTD22_swigregister(itkImageToImageFilterIUC2ISSRTD22)
itkImageToImageFilterIUC2ISSRTD22_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC2ISSRTD22_cast

class itkImageToImageFilterIUC2IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC2IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IUC3_cast)

# Register itkImageToImageFilterIUC2IUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IUC3_swigregister(itkImageToImageFilterIUC2IUC3)
itkImageToImageFilterIUC2IUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC2IUC3_cast

class itkImageToImageFilterIUC2IVF22(itk.itkImageSourcePython.itkImageSourceIVF22):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF22_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF22_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF22_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF22_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF22_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF22_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF22_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF22_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF22_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF22_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC2IVF22
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF22_cast)

# Register itkImageToImageFilterIUC2IVF22 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF22_swigregister(itkImageToImageFilterIUC2IVF22)
itkImageToImageFilterIUC2IVF22_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF22_cast

class itkImageToImageFilterIUC2IVF32(itk.itkImageSourcePython.itkImageSourceIVF32):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF32_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF32_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF32_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF32_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF32_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF32_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF32_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF32_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF32_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF32_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC2IVF32
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF32_cast)

# Register itkImageToImageFilterIUC2IVF32 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF32_swigregister(itkImageToImageFilterIUC2IVF32)
itkImageToImageFilterIUC2IVF32_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF32_cast

class itkImageToImageFilterIUC2IVF42(itk.itkImageSourcePython.itkImageSourceIVF42):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF42_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF42_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF42_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF42_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF42_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF42_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF42_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF42_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF42_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF42_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC2IVF42
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF42_cast)

# Register itkImageToImageFilterIUC2IVF42 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF42_swigregister(itkImageToImageFilterIUC2IVF42)
itkImageToImageFilterIUC2IVF42_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC2IVF42_cast

class itkImageToImageFilterIUC2VID2(itk.itkImageSourcePython.itkImageSourceVID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC2VID2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VID2_cast)

# Register itkImageToImageFilterIUC2VID2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VID2_swigregister(itkImageToImageFilterIUC2VID2)
itkImageToImageFilterIUC2VID2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC2VID2_cast

class itkImageToImageFilterIUC2VIF2(itk.itkImageSourcePython.itkImageSourceVIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC2VIF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIF2_cast)

# Register itkImageToImageFilterIUC2VIF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIF2_swigregister(itkImageToImageFilterIUC2VIF2)
itkImageToImageFilterIUC2VIF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIF2_cast

class itkImageToImageFilterIUC2VISS2(itk.itkImageSourcePython.itkImageSourceVISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC2VISS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VISS2_cast)

# Register itkImageToImageFilterIUC2VISS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VISS2_swigregister(itkImageToImageFilterIUC2VISS2)
itkImageToImageFilterIUC2VISS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC2VISS2_cast

class itkImageToImageFilterIUC2VIUC2(itk.itkImageSourcePython.itkImageSourceVIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC2VIUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUC2_cast)

# Register itkImageToImageFilterIUC2VIUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUC2_swigregister(itkImageToImageFilterIUC2VIUC2)
itkImageToImageFilterIUC2VIUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUC2_cast

class itkImageToImageFilterIUC2VIUS2(itk.itkImageSourcePython.itkImageSourceVIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC2VIUS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUS2_cast)

# Register itkImageToImageFilterIUC2VIUS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUS2_swigregister(itkImageToImageFilterIUC2VIUS2)
itkImageToImageFilterIUC2VIUS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC2VIUS2_cast

class itkImageToImageFilterIUC3ICF3(itk.itkImageSourcePython.itkImageSourceICF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC3ICF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICF3_cast)

# Register itkImageToImageFilterIUC3ICF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICF3_swigregister(itkImageToImageFilterIUC3ICF3)
itkImageToImageFilterIUC3ICF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICF3_cast

class itkImageToImageFilterIUC3ICVF23(itk.itkImageSourcePython.itkImageSourceICVF23):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF23_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF23_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF23_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF23_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF23_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF23_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF23_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF23_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF23_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF23_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC3ICVF23
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF23_cast)

# Register itkImageToImageFilterIUC3ICVF23 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF23_swigregister(itkImageToImageFilterIUC3ICVF23)
itkImageToImageFilterIUC3ICVF23_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF23_cast

class itkImageToImageFilterIUC3ICVF33(itk.itkImageSourcePython.itkImageSourceICVF33):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF33_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF33_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF33_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF33_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF33_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF33_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF33_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF33_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF33_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF33_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC3ICVF33
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF33_cast)

# Register itkImageToImageFilterIUC3ICVF33 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF33_swigregister(itkImageToImageFilterIUC3ICVF33)
itkImageToImageFilterIUC3ICVF33_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF33_cast

class itkImageToImageFilterIUC3ICVF43(itk.itkImageSourcePython.itkImageSourceICVF43):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF43_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF43_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF43_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF43_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF43_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF43_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF43_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF43_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF43_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF43_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC3ICVF43
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF43_cast)

# Register itkImageToImageFilterIUC3ICVF43 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF43_swigregister(itkImageToImageFilterIUC3ICVF43)
itkImageToImageFilterIUC3ICVF43_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC3ICVF43_cast

class itkImageToImageFilterIUC3IRGBAUC3(itk.itkImageSourcePython.itkImageSourceIRGBAUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBAUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBAUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBAUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBAUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBAUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBAUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBAUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBAUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBAUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBAUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC3IRGBAUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBAUC3_cast)

# Register itkImageToImageFilterIUC3IRGBAUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBAUC3_swigregister(itkImageToImageFilterIUC3IRGBAUC3)
itkImageToImageFilterIUC3IRGBAUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBAUC3_cast

class itkImageToImageFilterIUC3IRGBUC3(itk.itkImageSourcePython.itkImageSourceIRGBUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC3IRGBUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBUC3_cast)

# Register itkImageToImageFilterIUC3IRGBUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBUC3_swigregister(itkImageToImageFilterIUC3IRGBUC3)
itkImageToImageFilterIUC3IRGBUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC3IRGBUC3_cast

class itkImageToImageFilterIUC3ISSRTD33(itk.itkImageSourcePython.itkImageSourceISSRTD33):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ISSRTD33_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ISSRTD33_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ISSRTD33_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ISSRTD33_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ISSRTD33_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ISSRTD33_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ISSRTD33_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ISSRTD33_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ISSRTD33_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ISSRTD33_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC3ISSRTD33
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ISSRTD33_cast)

# Register itkImageToImageFilterIUC3ISSRTD33 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC3ISSRTD33_swigregister(itkImageToImageFilterIUC3ISSRTD33)
itkImageToImageFilterIUC3ISSRTD33_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC3ISSRTD33_cast

class itkImageToImageFilterIUC3IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC3IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IUC2_cast)

# Register itkImageToImageFilterIUC3IUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IUC2_swigregister(itkImageToImageFilterIUC3IUC2)
itkImageToImageFilterIUC3IUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC3IUC2_cast

class itkImageToImageFilterIUC3IVF23(itk.itkImageSourcePython.itkImageSourceIVF23):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF23_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF23_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF23_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF23_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF23_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF23_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF23_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF23_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF23_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF23_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC3IVF23
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF23_cast)

# Register itkImageToImageFilterIUC3IVF23 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF23_swigregister(itkImageToImageFilterIUC3IVF23)
itkImageToImageFilterIUC3IVF23_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF23_cast

class itkImageToImageFilterIUC3IVF33(itk.itkImageSourcePython.itkImageSourceIVF33):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF33_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF33_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF33_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF33_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF33_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF33_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF33_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF33_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF33_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF33_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC3IVF33
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF33_cast)

# Register itkImageToImageFilterIUC3IVF33 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF33_swigregister(itkImageToImageFilterIUC3IVF33)
itkImageToImageFilterIUC3IVF33_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF33_cast

class itkImageToImageFilterIUC3IVF43(itk.itkImageSourcePython.itkImageSourceIVF43):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF43_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF43_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF43_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF43_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF43_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF43_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF43_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF43_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF43_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF43_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC3IVF43
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF43_cast)

# Register itkImageToImageFilterIUC3IVF43 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF43_swigregister(itkImageToImageFilterIUC3IVF43)
itkImageToImageFilterIUC3IVF43_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC3IVF43_cast

class itkImageToImageFilterIUC3VID3(itk.itkImageSourcePython.itkImageSourceVID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC3VID3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VID3_cast)

# Register itkImageToImageFilterIUC3VID3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VID3_swigregister(itkImageToImageFilterIUC3VID3)
itkImageToImageFilterIUC3VID3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC3VID3_cast

class itkImageToImageFilterIUC3VIF3(itk.itkImageSourcePython.itkImageSourceVIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC3VIF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIF3_cast)

# Register itkImageToImageFilterIUC3VIF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIF3_swigregister(itkImageToImageFilterIUC3VIF3)
itkImageToImageFilterIUC3VIF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIF3_cast

class itkImageToImageFilterIUC3VISS3(itk.itkImageSourcePython.itkImageSourceVISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC3VISS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VISS3_cast)

# Register itkImageToImageFilterIUC3VISS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VISS3_swigregister(itkImageToImageFilterIUC3VISS3)
itkImageToImageFilterIUC3VISS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC3VISS3_cast

class itkImageToImageFilterIUC3VIUC3(itk.itkImageSourcePython.itkImageSourceVIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC3VIUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUC3_cast)

# Register itkImageToImageFilterIUC3VIUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUC3_swigregister(itkImageToImageFilterIUC3VIUC3)
itkImageToImageFilterIUC3VIUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUC3_cast

class itkImageToImageFilterIUC3VIUS3(itk.itkImageSourcePython.itkImageSourceVIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUC3VIUS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUS3_cast)

# Register itkImageToImageFilterIUC3VIUS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUS3_swigregister(itkImageToImageFilterIUC3VIUS3)
itkImageToImageFilterIUC3VIUS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUC3VIUS3_cast

class itkImageToImageFilterIUL2IRGBAUC2(itk.itkImageSourcePython.itkImageSourceIRGBAUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBAUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBAUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBAUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBAUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBAUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBAUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBAUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBAUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBAUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBAUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUL2IRGBAUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBAUC2_cast)

# Register itkImageToImageFilterIUL2IRGBAUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBAUC2_swigregister(itkImageToImageFilterIUL2IRGBAUC2)
itkImageToImageFilterIUL2IRGBAUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBAUC2_cast

class itkImageToImageFilterIUL2IRGBUC2(itk.itkImageSourcePython.itkImageSourceIRGBUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUL2IRGBUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBUC2_cast)

# Register itkImageToImageFilterIUL2IRGBUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBUC2_swigregister(itkImageToImageFilterIUL2IRGBUC2)
itkImageToImageFilterIUL2IRGBUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUL2IRGBUC2_cast

class itkImageToImageFilterIUL3IRGBAUC3(itk.itkImageSourcePython.itkImageSourceIRGBAUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBAUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBAUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBAUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBAUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBAUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBAUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBAUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBAUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBAUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBAUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUL3IRGBAUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBAUC3_cast)

# Register itkImageToImageFilterIUL3IRGBAUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBAUC3_swigregister(itkImageToImageFilterIUL3IRGBAUC3)
itkImageToImageFilterIUL3IRGBAUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBAUC3_cast

class itkImageToImageFilterIUL3IRGBUC3(itk.itkImageSourcePython.itkImageSourceIRGBUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUL3IRGBUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBUC3_cast)

# Register itkImageToImageFilterIUL3IRGBUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBUC3_swigregister(itkImageToImageFilterIUL3IRGBUC3)
itkImageToImageFilterIUL3IRGBUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUL3IRGBUC3_cast

class itkImageToImageFilterIULL2IRGBAUC2(itk.itkImageSourcePython.itkImageSourceIRGBAUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBAUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBAUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBAUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBAUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBAUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBAUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBAUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBAUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBAUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBAUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIULL2IRGBAUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBAUC2_cast)

# Register itkImageToImageFilterIULL2IRGBAUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBAUC2_swigregister(itkImageToImageFilterIULL2IRGBAUC2)
itkImageToImageFilterIULL2IRGBAUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBAUC2_cast

class itkImageToImageFilterIULL2IRGBUC2(itk.itkImageSourcePython.itkImageSourceIRGBUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIULL2IRGBUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBUC2_cast)

# Register itkImageToImageFilterIULL2IRGBUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBUC2_swigregister(itkImageToImageFilterIULL2IRGBUC2)
itkImageToImageFilterIULL2IRGBUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIULL2IRGBUC2_cast

class itkImageToImageFilterIULL3IRGBAUC3(itk.itkImageSourcePython.itkImageSourceIRGBAUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBAUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBAUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBAUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBAUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBAUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBAUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBAUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBAUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBAUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBAUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIULL3IRGBAUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBAUC3_cast)

# Register itkImageToImageFilterIULL3IRGBAUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBAUC3_swigregister(itkImageToImageFilterIULL3IRGBAUC3)
itkImageToImageFilterIULL3IRGBAUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBAUC3_cast

class itkImageToImageFilterIULL3IRGBUC3(itk.itkImageSourcePython.itkImageSourceIRGBUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIULL3IRGBUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBUC3_cast)

# Register itkImageToImageFilterIULL3IRGBUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBUC3_swigregister(itkImageToImageFilterIULL3IRGBUC3)
itkImageToImageFilterIULL3IRGBUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIULL3IRGBUC3_cast

class itkImageToImageFilterIUS2ICF2(itk.itkImageSourcePython.itkImageSourceICF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS2ICF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICF2_cast)

# Register itkImageToImageFilterIUS2ICF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICF2_swigregister(itkImageToImageFilterIUS2ICF2)
itkImageToImageFilterIUS2ICF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICF2_cast

class itkImageToImageFilterIUS2ICVF22(itk.itkImageSourcePython.itkImageSourceICVF22):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF22_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF22_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF22_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF22_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF22_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF22_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF22_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF22_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF22_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF22_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS2ICVF22
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF22_cast)

# Register itkImageToImageFilterIUS2ICVF22 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF22_swigregister(itkImageToImageFilterIUS2ICVF22)
itkImageToImageFilterIUS2ICVF22_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF22_cast

class itkImageToImageFilterIUS2ICVF32(itk.itkImageSourcePython.itkImageSourceICVF32):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF32_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF32_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF32_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF32_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF32_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF32_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF32_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF32_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF32_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF32_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS2ICVF32
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF32_cast)

# Register itkImageToImageFilterIUS2ICVF32 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF32_swigregister(itkImageToImageFilterIUS2ICVF32)
itkImageToImageFilterIUS2ICVF32_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF32_cast

class itkImageToImageFilterIUS2ICVF42(itk.itkImageSourcePython.itkImageSourceICVF42):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF42_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF42_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF42_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF42_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF42_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF42_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF42_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF42_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF42_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF42_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS2ICVF42
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF42_cast)

# Register itkImageToImageFilterIUS2ICVF42 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF42_swigregister(itkImageToImageFilterIUS2ICVF42)
itkImageToImageFilterIUS2ICVF42_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS2ICVF42_cast

class itkImageToImageFilterIUS2IRGBAUC2(itk.itkImageSourcePython.itkImageSourceIRGBAUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBAUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBAUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBAUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBAUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBAUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBAUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBAUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBAUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBAUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBAUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS2IRGBAUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBAUC2_cast)

# Register itkImageToImageFilterIUS2IRGBAUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBAUC2_swigregister(itkImageToImageFilterIUS2IRGBAUC2)
itkImageToImageFilterIUS2IRGBAUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBAUC2_cast

class itkImageToImageFilterIUS2IRGBUC2(itk.itkImageSourcePython.itkImageSourceIRGBUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS2IRGBUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBUC2_cast)

# Register itkImageToImageFilterIUS2IRGBUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBUC2_swigregister(itkImageToImageFilterIUS2IRGBUC2)
itkImageToImageFilterIUS2IRGBUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS2IRGBUC2_cast

class itkImageToImageFilterIUS2ISSRTD22(itk.itkImageSourcePython.itkImageSourceISSRTD22):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ISSRTD22_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ISSRTD22_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ISSRTD22_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ISSRTD22_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ISSRTD22_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ISSRTD22_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ISSRTD22_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ISSRTD22_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ISSRTD22_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ISSRTD22_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS2ISSRTD22
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ISSRTD22_cast)

# Register itkImageToImageFilterIUS2ISSRTD22 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS2ISSRTD22_swigregister(itkImageToImageFilterIUS2ISSRTD22)
itkImageToImageFilterIUS2ISSRTD22_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS2ISSRTD22_cast

class itkImageToImageFilterIUS2IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS2IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IUS3_cast)

# Register itkImageToImageFilterIUS2IUS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IUS3_swigregister(itkImageToImageFilterIUS2IUS3)
itkImageToImageFilterIUS2IUS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS2IUS3_cast

class itkImageToImageFilterIUS2IVF22(itk.itkImageSourcePython.itkImageSourceIVF22):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF22_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF22_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF22_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF22_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF22_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF22_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF22_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF22_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF22_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF22_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS2IVF22
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF22_cast)

# Register itkImageToImageFilterIUS2IVF22 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF22_swigregister(itkImageToImageFilterIUS2IVF22)
itkImageToImageFilterIUS2IVF22_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF22_cast

class itkImageToImageFilterIUS2IVF32(itk.itkImageSourcePython.itkImageSourceIVF32):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF32_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF32_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF32_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF32_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF32_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF32_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF32_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF32_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF32_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF32_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS2IVF32
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF32_cast)

# Register itkImageToImageFilterIUS2IVF32 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF32_swigregister(itkImageToImageFilterIUS2IVF32)
itkImageToImageFilterIUS2IVF32_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF32_cast

class itkImageToImageFilterIUS2IVF42(itk.itkImageSourcePython.itkImageSourceIVF42):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF42_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF42_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF42_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF42_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF42_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF42_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF42_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF42_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF42_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF42_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS2IVF42
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF42_cast)

# Register itkImageToImageFilterIUS2IVF42 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF42_swigregister(itkImageToImageFilterIUS2IVF42)
itkImageToImageFilterIUS2IVF42_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS2IVF42_cast

class itkImageToImageFilterIUS2VID2(itk.itkImageSourcePython.itkImageSourceVID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS2VID2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VID2_cast)

# Register itkImageToImageFilterIUS2VID2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VID2_swigregister(itkImageToImageFilterIUS2VID2)
itkImageToImageFilterIUS2VID2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS2VID2_cast

class itkImageToImageFilterIUS2VIF2(itk.itkImageSourcePython.itkImageSourceVIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS2VIF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIF2_cast)

# Register itkImageToImageFilterIUS2VIF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIF2_swigregister(itkImageToImageFilterIUS2VIF2)
itkImageToImageFilterIUS2VIF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIF2_cast

class itkImageToImageFilterIUS2VISS2(itk.itkImageSourcePython.itkImageSourceVISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS2VISS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VISS2_cast)

# Register itkImageToImageFilterIUS2VISS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VISS2_swigregister(itkImageToImageFilterIUS2VISS2)
itkImageToImageFilterIUS2VISS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS2VISS2_cast

class itkImageToImageFilterIUS2VIUC2(itk.itkImageSourcePython.itkImageSourceVIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS2VIUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUC2_cast)

# Register itkImageToImageFilterIUS2VIUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUC2_swigregister(itkImageToImageFilterIUS2VIUC2)
itkImageToImageFilterIUS2VIUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUC2_cast

class itkImageToImageFilterIUS2VIUS2(itk.itkImageSourcePython.itkImageSourceVIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS2VIUS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUS2_cast)

# Register itkImageToImageFilterIUS2VIUS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUS2_swigregister(itkImageToImageFilterIUS2VIUS2)
itkImageToImageFilterIUS2VIUS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS2VIUS2_cast

class itkImageToImageFilterIUS3ICF3(itk.itkImageSourcePython.itkImageSourceICF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS3ICF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICF3_cast)

# Register itkImageToImageFilterIUS3ICF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICF3_swigregister(itkImageToImageFilterIUS3ICF3)
itkImageToImageFilterIUS3ICF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICF3_cast

class itkImageToImageFilterIUS3ICVF23(itk.itkImageSourcePython.itkImageSourceICVF23):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF23_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF23_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF23_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF23_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF23_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF23_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF23_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF23_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF23_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF23_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS3ICVF23
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF23_cast)

# Register itkImageToImageFilterIUS3ICVF23 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF23_swigregister(itkImageToImageFilterIUS3ICVF23)
itkImageToImageFilterIUS3ICVF23_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF23_cast

class itkImageToImageFilterIUS3ICVF33(itk.itkImageSourcePython.itkImageSourceICVF33):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF33_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF33_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF33_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF33_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF33_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF33_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF33_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF33_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF33_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF33_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS3ICVF33
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF33_cast)

# Register itkImageToImageFilterIUS3ICVF33 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF33_swigregister(itkImageToImageFilterIUS3ICVF33)
itkImageToImageFilterIUS3ICVF33_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF33_cast

class itkImageToImageFilterIUS3ICVF43(itk.itkImageSourcePython.itkImageSourceICVF43):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF43_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF43_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF43_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF43_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF43_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF43_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF43_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF43_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF43_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF43_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS3ICVF43
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF43_cast)

# Register itkImageToImageFilterIUS3ICVF43 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF43_swigregister(itkImageToImageFilterIUS3ICVF43)
itkImageToImageFilterIUS3ICVF43_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS3ICVF43_cast

class itkImageToImageFilterIUS3IRGBAUC3(itk.itkImageSourcePython.itkImageSourceIRGBAUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBAUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBAUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBAUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBAUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBAUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBAUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBAUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBAUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBAUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBAUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS3IRGBAUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBAUC3_cast)

# Register itkImageToImageFilterIUS3IRGBAUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBAUC3_swigregister(itkImageToImageFilterIUS3IRGBAUC3)
itkImageToImageFilterIUS3IRGBAUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBAUC3_cast

class itkImageToImageFilterIUS3IRGBUC3(itk.itkImageSourcePython.itkImageSourceIRGBUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS3IRGBUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBUC3_cast)

# Register itkImageToImageFilterIUS3IRGBUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBUC3_swigregister(itkImageToImageFilterIUS3IRGBUC3)
itkImageToImageFilterIUS3IRGBUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS3IRGBUC3_cast

class itkImageToImageFilterIUS3ISSRTD33(itk.itkImageSourcePython.itkImageSourceISSRTD33):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ISSRTD33_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ISSRTD33_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ISSRTD33_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ISSRTD33_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ISSRTD33_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ISSRTD33_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ISSRTD33_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ISSRTD33_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ISSRTD33_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ISSRTD33_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS3ISSRTD33
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ISSRTD33_cast)

# Register itkImageToImageFilterIUS3ISSRTD33 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS3ISSRTD33_swigregister(itkImageToImageFilterIUS3ISSRTD33)
itkImageToImageFilterIUS3ISSRTD33_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS3ISSRTD33_cast

class itkImageToImageFilterIUS3IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS3IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IUS2_cast)

# Register itkImageToImageFilterIUS3IUS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IUS2_swigregister(itkImageToImageFilterIUS3IUS2)
itkImageToImageFilterIUS3IUS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS3IUS2_cast

class itkImageToImageFilterIUS3IVF23(itk.itkImageSourcePython.itkImageSourceIVF23):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF23_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF23_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF23_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF23_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF23_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF23_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF23_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF23_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF23_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF23_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS3IVF23
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF23_cast)

# Register itkImageToImageFilterIUS3IVF23 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF23_swigregister(itkImageToImageFilterIUS3IVF23)
itkImageToImageFilterIUS3IVF23_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF23_cast

class itkImageToImageFilterIUS3IVF33(itk.itkImageSourcePython.itkImageSourceIVF33):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF33_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF33_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF33_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF33_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF33_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF33_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF33_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF33_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF33_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF33_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS3IVF33
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF33_cast)

# Register itkImageToImageFilterIUS3IVF33 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF33_swigregister(itkImageToImageFilterIUS3IVF33)
itkImageToImageFilterIUS3IVF33_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF33_cast

class itkImageToImageFilterIUS3IVF43(itk.itkImageSourcePython.itkImageSourceIVF43):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF43_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF43_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF43_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF43_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF43_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF43_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF43_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF43_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF43_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF43_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS3IVF43
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF43_cast)

# Register itkImageToImageFilterIUS3IVF43 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF43_swigregister(itkImageToImageFilterIUS3IVF43)
itkImageToImageFilterIUS3IVF43_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS3IVF43_cast

class itkImageToImageFilterIUS3VID3(itk.itkImageSourcePython.itkImageSourceVID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS3VID3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VID3_cast)

# Register itkImageToImageFilterIUS3VID3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VID3_swigregister(itkImageToImageFilterIUS3VID3)
itkImageToImageFilterIUS3VID3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS3VID3_cast

class itkImageToImageFilterIUS3VIF3(itk.itkImageSourcePython.itkImageSourceVIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS3VIF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIF3_cast)

# Register itkImageToImageFilterIUS3VIF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIF3_swigregister(itkImageToImageFilterIUS3VIF3)
itkImageToImageFilterIUS3VIF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIF3_cast

class itkImageToImageFilterIUS3VISS3(itk.itkImageSourcePython.itkImageSourceVISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS3VISS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VISS3_cast)

# Register itkImageToImageFilterIUS3VISS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VISS3_swigregister(itkImageToImageFilterIUS3VISS3)
itkImageToImageFilterIUS3VISS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS3VISS3_cast

class itkImageToImageFilterIUS3VIUC3(itk.itkImageSourcePython.itkImageSourceVIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS3VIUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUC3_cast)

# Register itkImageToImageFilterIUS3VIUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUC3_swigregister(itkImageToImageFilterIUS3VIUC3)
itkImageToImageFilterIUS3VIUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUC3_cast

class itkImageToImageFilterIUS3VIUS3(itk.itkImageSourcePython.itkImageSourceVIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIUS3VIUS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUS3_cast)

# Register itkImageToImageFilterIUS3VIUS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUS3_swigregister(itkImageToImageFilterIUS3VIUS3)
itkImageToImageFilterIUS3VIUS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIUS3VIUS3_cast

class itkImageToImageFilterIVF22ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF22ID2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ID2_cast)

# Register itkImageToImageFilterIVF22ID2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ID2_swigregister(itkImageToImageFilterIVF22ID2)
itkImageToImageFilterIVF22ID2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF22ID2_cast

class itkImageToImageFilterIVF22IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF22IF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IF2_cast)

# Register itkImageToImageFilterIVF22IF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IF2_swigregister(itkImageToImageFilterIVF22IF2)
itkImageToImageFilterIVF22IF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF22IF2_cast

class itkImageToImageFilterIVF22ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF22ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ISS2_cast)

# Register itkImageToImageFilterIVF22ISS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF22ISS2_swigregister(itkImageToImageFilterIVF22ISS2)
itkImageToImageFilterIVF22ISS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF22ISS2_cast

class itkImageToImageFilterIVF22IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF22IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUC2_cast)

# Register itkImageToImageFilterIVF22IUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUC2_swigregister(itkImageToImageFilterIVF22IUC2)
itkImageToImageFilterIVF22IUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUC2_cast

class itkImageToImageFilterIVF22IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF22IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUS2_cast)

# Register itkImageToImageFilterIVF22IUS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUS2_swigregister(itkImageToImageFilterIVF22IUS2)
itkImageToImageFilterIVF22IUS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF22IUS2_cast

class itkImageToImageFilterIVF23ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF23ID3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ID3_cast)

# Register itkImageToImageFilterIVF23ID3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ID3_swigregister(itkImageToImageFilterIVF23ID3)
itkImageToImageFilterIVF23ID3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF23ID3_cast

class itkImageToImageFilterIVF23IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF23IF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IF3_cast)

# Register itkImageToImageFilterIVF23IF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IF3_swigregister(itkImageToImageFilterIVF23IF3)
itkImageToImageFilterIVF23IF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF23IF3_cast

class itkImageToImageFilterIVF23ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF23ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ISS3_cast)

# Register itkImageToImageFilterIVF23ISS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF23ISS3_swigregister(itkImageToImageFilterIVF23ISS3)
itkImageToImageFilterIVF23ISS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF23ISS3_cast

class itkImageToImageFilterIVF23IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF23IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUC3_cast)

# Register itkImageToImageFilterIVF23IUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUC3_swigregister(itkImageToImageFilterIVF23IUC3)
itkImageToImageFilterIVF23IUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUC3_cast

class itkImageToImageFilterIVF23IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF23IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUS3_cast)

# Register itkImageToImageFilterIVF23IUS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUS3_swigregister(itkImageToImageFilterIVF23IUS3)
itkImageToImageFilterIVF23IUS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF23IUS3_cast

class itkImageToImageFilterIVF32ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF32ID2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ID2_cast)

# Register itkImageToImageFilterIVF32ID2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ID2_swigregister(itkImageToImageFilterIVF32ID2)
itkImageToImageFilterIVF32ID2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF32ID2_cast

class itkImageToImageFilterIVF32IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF32IF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IF2_cast)

# Register itkImageToImageFilterIVF32IF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IF2_swigregister(itkImageToImageFilterIVF32IF2)
itkImageToImageFilterIVF32IF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF32IF2_cast

class itkImageToImageFilterIVF32ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF32ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ISS2_cast)

# Register itkImageToImageFilterIVF32ISS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF32ISS2_swigregister(itkImageToImageFilterIVF32ISS2)
itkImageToImageFilterIVF32ISS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF32ISS2_cast

class itkImageToImageFilterIVF32IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF32IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUC2_cast)

# Register itkImageToImageFilterIVF32IUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUC2_swigregister(itkImageToImageFilterIVF32IUC2)
itkImageToImageFilterIVF32IUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUC2_cast

class itkImageToImageFilterIVF32IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF32IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUS2_cast)

# Register itkImageToImageFilterIVF32IUS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUS2_swigregister(itkImageToImageFilterIVF32IUS2)
itkImageToImageFilterIVF32IUS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF32IUS2_cast

class itkImageToImageFilterIVF33ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF33ID3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ID3_cast)

# Register itkImageToImageFilterIVF33ID3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ID3_swigregister(itkImageToImageFilterIVF33ID3)
itkImageToImageFilterIVF33ID3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF33ID3_cast

class itkImageToImageFilterIVF33IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF33IF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IF3_cast)

# Register itkImageToImageFilterIVF33IF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IF3_swigregister(itkImageToImageFilterIVF33IF3)
itkImageToImageFilterIVF33IF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF33IF3_cast

class itkImageToImageFilterIVF33ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF33ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ISS3_cast)

# Register itkImageToImageFilterIVF33ISS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF33ISS3_swigregister(itkImageToImageFilterIVF33ISS3)
itkImageToImageFilterIVF33ISS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF33ISS3_cast

class itkImageToImageFilterIVF33IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF33IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUC3_cast)

# Register itkImageToImageFilterIVF33IUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUC3_swigregister(itkImageToImageFilterIVF33IUC3)
itkImageToImageFilterIVF33IUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUC3_cast

class itkImageToImageFilterIVF33IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF33IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUS3_cast)

# Register itkImageToImageFilterIVF33IUS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUS3_swigregister(itkImageToImageFilterIVF33IUS3)
itkImageToImageFilterIVF33IUS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF33IUS3_cast

class itkImageToImageFilterIVF42ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF42ID2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ID2_cast)

# Register itkImageToImageFilterIVF42ID2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ID2_swigregister(itkImageToImageFilterIVF42ID2)
itkImageToImageFilterIVF42ID2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF42ID2_cast

class itkImageToImageFilterIVF42IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF42IF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IF2_cast)

# Register itkImageToImageFilterIVF42IF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IF2_swigregister(itkImageToImageFilterIVF42IF2)
itkImageToImageFilterIVF42IF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF42IF2_cast

class itkImageToImageFilterIVF42ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF42ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ISS2_cast)

# Register itkImageToImageFilterIVF42ISS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF42ISS2_swigregister(itkImageToImageFilterIVF42ISS2)
itkImageToImageFilterIVF42ISS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF42ISS2_cast

class itkImageToImageFilterIVF42IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF42IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUC2_cast)

# Register itkImageToImageFilterIVF42IUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUC2_swigregister(itkImageToImageFilterIVF42IUC2)
itkImageToImageFilterIVF42IUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUC2_cast

class itkImageToImageFilterIVF42IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF42IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUS2_cast)

# Register itkImageToImageFilterIVF42IUS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUS2_swigregister(itkImageToImageFilterIVF42IUS2)
itkImageToImageFilterIVF42IUS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF42IUS2_cast

class itkImageToImageFilterIVF43ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF43ID3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ID3_cast)

# Register itkImageToImageFilterIVF43ID3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ID3_swigregister(itkImageToImageFilterIVF43ID3)
itkImageToImageFilterIVF43ID3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF43ID3_cast

class itkImageToImageFilterIVF43IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF43IF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IF3_cast)

# Register itkImageToImageFilterIVF43IF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IF3_swigregister(itkImageToImageFilterIVF43IF3)
itkImageToImageFilterIVF43IF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF43IF3_cast

class itkImageToImageFilterIVF43ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF43ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ISS3_cast)

# Register itkImageToImageFilterIVF43ISS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF43ISS3_swigregister(itkImageToImageFilterIVF43ISS3)
itkImageToImageFilterIVF43ISS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF43ISS3_cast

class itkImageToImageFilterIVF43IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF43IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUC3_cast)

# Register itkImageToImageFilterIVF43IUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUC3_swigregister(itkImageToImageFilterIVF43IUC3)
itkImageToImageFilterIVF43IUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUC3_cast

class itkImageToImageFilterIVF43IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterIVF43IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUS3_cast)

# Register itkImageToImageFilterIVF43IUS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUS3_swigregister(itkImageToImageFilterIVF43IUS3)
itkImageToImageFilterIVF43IUS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterIVF43IUS3_cast

class itkImageToImageFilterVID2ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVID2ID2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2ID2_cast)

# Register itkImageToImageFilterVID2ID2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVID2ID2_swigregister(itkImageToImageFilterVID2ID2)
itkImageToImageFilterVID2ID2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVID2ID2_cast

class itkImageToImageFilterVID2IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVID2IF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IF2_cast)

# Register itkImageToImageFilterVID2IF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVID2IF2_swigregister(itkImageToImageFilterVID2IF2)
itkImageToImageFilterVID2IF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVID2IF2_cast

class itkImageToImageFilterVID2ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVID2ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2ISS2_cast)

# Register itkImageToImageFilterVID2ISS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVID2ISS2_swigregister(itkImageToImageFilterVID2ISS2)
itkImageToImageFilterVID2ISS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVID2ISS2_cast

class itkImageToImageFilterVID2IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVID2IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUC2_cast)

# Register itkImageToImageFilterVID2IUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUC2_swigregister(itkImageToImageFilterVID2IUC2)
itkImageToImageFilterVID2IUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVID2IUC2_cast

class itkImageToImageFilterVID2IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVID2IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUS2_cast)

# Register itkImageToImageFilterVID2IUS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVID2IUS2_swigregister(itkImageToImageFilterVID2IUS2)
itkImageToImageFilterVID2IUS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVID2IUS2_cast

class itkImageToImageFilterVID3ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVID3ID3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3ID3_cast)

# Register itkImageToImageFilterVID3ID3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVID3ID3_swigregister(itkImageToImageFilterVID3ID3)
itkImageToImageFilterVID3ID3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVID3ID3_cast

class itkImageToImageFilterVID3IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVID3IF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IF3_cast)

# Register itkImageToImageFilterVID3IF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVID3IF3_swigregister(itkImageToImageFilterVID3IF3)
itkImageToImageFilterVID3IF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVID3IF3_cast

class itkImageToImageFilterVID3ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVID3ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3ISS3_cast)

# Register itkImageToImageFilterVID3ISS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVID3ISS3_swigregister(itkImageToImageFilterVID3ISS3)
itkImageToImageFilterVID3ISS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVID3ISS3_cast

class itkImageToImageFilterVID3IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVID3IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUC3_cast)

# Register itkImageToImageFilterVID3IUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUC3_swigregister(itkImageToImageFilterVID3IUC3)
itkImageToImageFilterVID3IUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVID3IUC3_cast

class itkImageToImageFilterVID3IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVID3IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUS3_cast)

# Register itkImageToImageFilterVID3IUS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVID3IUS3_swigregister(itkImageToImageFilterVID3IUS3)
itkImageToImageFilterVID3IUS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVID3IUS3_cast

class itkImageToImageFilterVIF2ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIF2ID2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ID2_cast)

# Register itkImageToImageFilterVIF2ID2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ID2_swigregister(itkImageToImageFilterVIF2ID2)
itkImageToImageFilterVIF2ID2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIF2ID2_cast

class itkImageToImageFilterVIF2IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIF2IF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IF2_cast)

# Register itkImageToImageFilterVIF2IF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IF2_swigregister(itkImageToImageFilterVIF2IF2)
itkImageToImageFilterVIF2IF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIF2IF2_cast

class itkImageToImageFilterVIF2ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIF2ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ISS2_cast)

# Register itkImageToImageFilterVIF2ISS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIF2ISS2_swigregister(itkImageToImageFilterVIF2ISS2)
itkImageToImageFilterVIF2ISS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIF2ISS2_cast

class itkImageToImageFilterVIF2IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIF2IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUC2_cast)

# Register itkImageToImageFilterVIF2IUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUC2_swigregister(itkImageToImageFilterVIF2IUC2)
itkImageToImageFilterVIF2IUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUC2_cast

class itkImageToImageFilterVIF2IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIF2IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUS2_cast)

# Register itkImageToImageFilterVIF2IUS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUS2_swigregister(itkImageToImageFilterVIF2IUS2)
itkImageToImageFilterVIF2IUS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIF2IUS2_cast

class itkImageToImageFilterVIF3ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIF3ID3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ID3_cast)

# Register itkImageToImageFilterVIF3ID3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ID3_swigregister(itkImageToImageFilterVIF3ID3)
itkImageToImageFilterVIF3ID3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIF3ID3_cast

class itkImageToImageFilterVIF3IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIF3IF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IF3_cast)

# Register itkImageToImageFilterVIF3IF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IF3_swigregister(itkImageToImageFilterVIF3IF3)
itkImageToImageFilterVIF3IF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIF3IF3_cast

class itkImageToImageFilterVIF3ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIF3ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ISS3_cast)

# Register itkImageToImageFilterVIF3ISS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIF3ISS3_swigregister(itkImageToImageFilterVIF3ISS3)
itkImageToImageFilterVIF3ISS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIF3ISS3_cast

class itkImageToImageFilterVIF3IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIF3IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUC3_cast)

# Register itkImageToImageFilterVIF3IUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUC3_swigregister(itkImageToImageFilterVIF3IUC3)
itkImageToImageFilterVIF3IUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUC3_cast

class itkImageToImageFilterVIF3IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIF3IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUS3_cast)

# Register itkImageToImageFilterVIF3IUS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUS3_swigregister(itkImageToImageFilterVIF3IUS3)
itkImageToImageFilterVIF3IUS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIF3IUS3_cast

class itkImageToImageFilterVISS2ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVISS2ID2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ID2_cast)

# Register itkImageToImageFilterVISS2ID2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ID2_swigregister(itkImageToImageFilterVISS2ID2)
itkImageToImageFilterVISS2ID2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVISS2ID2_cast

class itkImageToImageFilterVISS2IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVISS2IF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IF2_cast)

# Register itkImageToImageFilterVISS2IF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IF2_swigregister(itkImageToImageFilterVISS2IF2)
itkImageToImageFilterVISS2IF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVISS2IF2_cast

class itkImageToImageFilterVISS2ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVISS2ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ISS2_cast)

# Register itkImageToImageFilterVISS2ISS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVISS2ISS2_swigregister(itkImageToImageFilterVISS2ISS2)
itkImageToImageFilterVISS2ISS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVISS2ISS2_cast

class itkImageToImageFilterVISS2IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVISS2IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUC2_cast)

# Register itkImageToImageFilterVISS2IUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUC2_swigregister(itkImageToImageFilterVISS2IUC2)
itkImageToImageFilterVISS2IUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUC2_cast

class itkImageToImageFilterVISS2IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVISS2IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUS2_cast)

# Register itkImageToImageFilterVISS2IUS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUS2_swigregister(itkImageToImageFilterVISS2IUS2)
itkImageToImageFilterVISS2IUS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVISS2IUS2_cast

class itkImageToImageFilterVISS3ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVISS3ID3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ID3_cast)

# Register itkImageToImageFilterVISS3ID3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ID3_swigregister(itkImageToImageFilterVISS3ID3)
itkImageToImageFilterVISS3ID3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVISS3ID3_cast

class itkImageToImageFilterVISS3IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVISS3IF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IF3_cast)

# Register itkImageToImageFilterVISS3IF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IF3_swigregister(itkImageToImageFilterVISS3IF3)
itkImageToImageFilterVISS3IF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVISS3IF3_cast

class itkImageToImageFilterVISS3ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVISS3ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ISS3_cast)

# Register itkImageToImageFilterVISS3ISS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVISS3ISS3_swigregister(itkImageToImageFilterVISS3ISS3)
itkImageToImageFilterVISS3ISS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVISS3ISS3_cast

class itkImageToImageFilterVISS3IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVISS3IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUC3_cast)

# Register itkImageToImageFilterVISS3IUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUC3_swigregister(itkImageToImageFilterVISS3IUC3)
itkImageToImageFilterVISS3IUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUC3_cast

class itkImageToImageFilterVISS3IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVISS3IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUS3_cast)

# Register itkImageToImageFilterVISS3IUS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUS3_swigregister(itkImageToImageFilterVISS3IUS3)
itkImageToImageFilterVISS3IUS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVISS3IUS3_cast

class itkImageToImageFilterVIUC2ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIUC2ID2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ID2_cast)

# Register itkImageToImageFilterVIUC2ID2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ID2_swigregister(itkImageToImageFilterVIUC2ID2)
itkImageToImageFilterVIUC2ID2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ID2_cast

class itkImageToImageFilterVIUC2IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIUC2IF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IF2_cast)

# Register itkImageToImageFilterVIUC2IF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IF2_swigregister(itkImageToImageFilterVIUC2IF2)
itkImageToImageFilterVIUC2IF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IF2_cast

class itkImageToImageFilterVIUC2ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIUC2ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ISS2_cast)

# Register itkImageToImageFilterVIUC2ISS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ISS2_swigregister(itkImageToImageFilterVIUC2ISS2)
itkImageToImageFilterVIUC2ISS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIUC2ISS2_cast

class itkImageToImageFilterVIUC2IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIUC2IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUC2_cast)

# Register itkImageToImageFilterVIUC2IUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUC2_swigregister(itkImageToImageFilterVIUC2IUC2)
itkImageToImageFilterVIUC2IUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUC2_cast

class itkImageToImageFilterVIUC2IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIUC2IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUS2_cast)

# Register itkImageToImageFilterVIUC2IUS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUS2_swigregister(itkImageToImageFilterVIUC2IUS2)
itkImageToImageFilterVIUC2IUS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIUC2IUS2_cast

class itkImageToImageFilterVIUC3ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIUC3ID3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ID3_cast)

# Register itkImageToImageFilterVIUC3ID3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ID3_swigregister(itkImageToImageFilterVIUC3ID3)
itkImageToImageFilterVIUC3ID3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ID3_cast

class itkImageToImageFilterVIUC3IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIUC3IF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IF3_cast)

# Register itkImageToImageFilterVIUC3IF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IF3_swigregister(itkImageToImageFilterVIUC3IF3)
itkImageToImageFilterVIUC3IF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IF3_cast

class itkImageToImageFilterVIUC3ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIUC3ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ISS3_cast)

# Register itkImageToImageFilterVIUC3ISS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ISS3_swigregister(itkImageToImageFilterVIUC3ISS3)
itkImageToImageFilterVIUC3ISS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIUC3ISS3_cast

class itkImageToImageFilterVIUC3IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIUC3IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUC3_cast)

# Register itkImageToImageFilterVIUC3IUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUC3_swigregister(itkImageToImageFilterVIUC3IUC3)
itkImageToImageFilterVIUC3IUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUC3_cast

class itkImageToImageFilterVIUC3IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIUC3IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUS3_cast)

# Register itkImageToImageFilterVIUC3IUS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUS3_swigregister(itkImageToImageFilterVIUC3IUS3)
itkImageToImageFilterVIUC3IUS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIUC3IUS3_cast

class itkImageToImageFilterVIUS2ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIUS2ID2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ID2_cast)

# Register itkImageToImageFilterVIUS2ID2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ID2_swigregister(itkImageToImageFilterVIUS2ID2)
itkImageToImageFilterVIUS2ID2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ID2_cast

class itkImageToImageFilterVIUS2IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIUS2IF2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IF2_cast)

# Register itkImageToImageFilterVIUS2IF2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IF2_swigregister(itkImageToImageFilterVIUS2IF2)
itkImageToImageFilterVIUS2IF2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IF2_cast

class itkImageToImageFilterVIUS2ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIUS2ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ISS2_cast)

# Register itkImageToImageFilterVIUS2ISS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ISS2_swigregister(itkImageToImageFilterVIUS2ISS2)
itkImageToImageFilterVIUS2ISS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIUS2ISS2_cast

class itkImageToImageFilterVIUS2IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIUS2IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUC2_cast)

# Register itkImageToImageFilterVIUS2IUC2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUC2_swigregister(itkImageToImageFilterVIUS2IUC2)
itkImageToImageFilterVIUS2IUC2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUC2_cast

class itkImageToImageFilterVIUS2IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIUS2IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUS2_cast)

# Register itkImageToImageFilterVIUS2IUS2 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUS2_swigregister(itkImageToImageFilterVIUS2IUS2)
itkImageToImageFilterVIUS2IUS2_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIUS2IUS2_cast

class itkImageToImageFilterVIUS3ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIUS3ID3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ID3_cast)

# Register itkImageToImageFilterVIUS3ID3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ID3_swigregister(itkImageToImageFilterVIUS3ID3)
itkImageToImageFilterVIUS3ID3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ID3_cast

class itkImageToImageFilterVIUS3IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIUS3IF3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IF3_cast)

# Register itkImageToImageFilterVIUS3IF3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IF3_swigregister(itkImageToImageFilterVIUS3IF3)
itkImageToImageFilterVIUS3IF3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IF3_cast

class itkImageToImageFilterVIUS3ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIUS3ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ISS3_cast)

# Register itkImageToImageFilterVIUS3ISS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ISS3_swigregister(itkImageToImageFilterVIUS3ISS3)
itkImageToImageFilterVIUS3ISS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIUS3ISS3_cast

class itkImageToImageFilterVIUS3IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIUS3IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUC3_cast)

# Register itkImageToImageFilterVIUS3IUC3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUC3_swigregister(itkImageToImageFilterVIUS3IUC3)
itkImageToImageFilterVIUS3IUC3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUC3_cast

class itkImageToImageFilterVIUS3IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterBPython.delete_itkImageToImageFilterVIUS3IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUS3_cast)

# Register itkImageToImageFilterVIUS3IUS3 in _itkImageToImageFilterBPython:
_itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUS3_swigregister(itkImageToImageFilterVIUS3IUS3)
itkImageToImageFilterVIUS3IUS3_cast = _itkImageToImageFilterBPython.itkImageToImageFilterVIUS3IUS3_cast


import itkHelpers
@itkHelpers.accept_numpy_array_like_xarray
def image_to_image_filter(*args, **kwargs):
    """Procedural interface for ImageToImageFilter"""
    import itk
    instance = itk.ImageToImageFilter.New(*args, **kwargs)
    return instance.__internal_call__()

def image_to_image_filter_init_docstring():
    import itk
    import itkTemplate
    import itkHelpers
    if isinstance(itk.ImageToImageFilter, itkTemplate.itkTemplate):
        filter_object = itk.ImageToImageFilter.values()[0]
    else:
        filter_object = itk.ImageToImageFilter

    image_to_image_filter.__doc__ = filter_object.__doc__
    image_to_image_filter.__doc__ += "\n Args are Input(s) to the filter.\n"
    image_to_image_filter.__doc__ += "\n Available Keyword Arguments:\n"
    if isinstance(itk.ImageToImageFilter, itkTemplate.itkTemplate):
        image_to_image_filter.__doc__ += itkHelpers.filter_args(filter_object)[0]
        image_to_image_filter.__doc__ += "\n"
        image_to_image_filter.__doc__ += itkHelpers.filter_args(filter_object)[1]
    else:
        image_to_image_filter.__doc__ += "".join([
            "  " + itkHelpers.camel_to_snake_case(item[3:]) + "\n"
            for item in dir(filter_object)
            if item.startswith("Set")])



