# This file was automatically generated by SWIG (http://www.swig.org).
# Version 4.0.1
#
# Do not make changes to this file unless you know what you are doing--modify
# the SWIG interface file instead.


from . import _ITKCommonPython



from sys import version_info as _swig_python_version_info
if _swig_python_version_info < (2, 7, 0):
    raise RuntimeError("Python 2.7 or later required")

# Import the low-level C/C++ module
if __package__ or "." in __name__:
    from . import _itkImageToImageFilterAPython
else:
    import _itkImageToImageFilterAPython

try:
    import builtins as __builtin__
except ImportError:
    import __builtin__

_swig_new_instance_method = _itkImageToImageFilterAPython.SWIG_PyInstanceMethod_New
_swig_new_static_method = _itkImageToImageFilterAPython.SWIG_PyStaticMethod_New

def _swig_repr(self):
    try:
        strthis = "proxy of " + self.this.__repr__()
    except __builtin__.Exception:
        strthis = ""
    return "<%s.%s; %s >" % (self.__class__.__module__, self.__class__.__name__, strthis,)


def _swig_setattr_nondynamic_instance_variable(set):
    def set_instance_attr(self, name, value):
        if name == "thisown":
            self.this.own(value)
        elif name == "this":
            set(self, name, value)
        elif hasattr(self, name) and isinstance(getattr(type(self), name), property):
            set(self, name, value)
        else:
            raise AttributeError("You cannot add instance attributes to %s" % self)
    return set_instance_attr


def _swig_setattr_nondynamic_class_variable(set):
    def set_class_attr(cls, name, value):
        if hasattr(cls, name) and not isinstance(getattr(cls, name), property):
            set(cls, name, value)
        else:
            raise AttributeError("You cannot add class attributes to %s" % cls)
    return set_class_attr


def _swig_add_metaclass(metaclass):
    """Class decorator for adding a metaclass to a SWIG wrapped class - a slimmed down version of six.add_metaclass"""
    def wrapper(cls):
        return metaclass(cls.__name__, cls.__bases__, cls.__dict__.copy())
    return wrapper


class _SwigNonDynamicMeta(type):
    """Meta class to enforce nondynamic attributes (no new attributes) for a class"""
    __setattr__ = _swig_setattr_nondynamic_class_variable(type.__setattr__)


import itk.itkImageRegionPython
import itk.itkIndexPython
import itk.itkOffsetPython
import itk.itkSizePython
import itk.pyBasePython
import itk.ITKCommonBasePython
import itk.itkImageSourcePython
import itk.itkImagePython
import itk.itkRGBPixelPython
import itk.itkFixedArrayPython
import itk.stdcomplexPython
import itk.itkRGBAPixelPython
import itk.itkPointPython
import itk.vnl_vector_refPython
import itk.vnl_vectorPython
import itk.vnl_matrixPython
import itk.itkVectorPython
import itk.itkCovariantVectorPython
import itk.itkMatrixPython
import itk.vnl_matrix_fixedPython
import itk.itkSymmetricSecondRankTensorPython
import itk.itkImageSourceCommonPython
import itk.itkVectorImagePython
import itk.itkVariableLengthVectorPython
import itk.itkImageToImageFilterCommonPython
class itkImageToImageFilterICVF22ICVF22(itk.itkImageSourcePython.itkImageSourceICVF22):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF22ICVF22_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF22ICVF22_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF22ICVF22_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF22ICVF22_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF22ICVF22_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF22ICVF22_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF22ICVF22_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF22ICVF22_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF22ICVF22_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF22ICVF22_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterICVF22ICVF22
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF22ICVF22_cast)

# Register itkImageToImageFilterICVF22ICVF22 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterICVF22ICVF22_swigregister(itkImageToImageFilterICVF22ICVF22)
itkImageToImageFilterICVF22ICVF22_cast = _itkImageToImageFilterAPython.itkImageToImageFilterICVF22ICVF22_cast

class itkImageToImageFilterICVF22IVF22(itk.itkImageSourcePython.itkImageSourceIVF22):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF22IVF22_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF22IVF22_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF22IVF22_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF22IVF22_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF22IVF22_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF22IVF22_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF22IVF22_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF22IVF22_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF22IVF22_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF22IVF22_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterICVF22IVF22
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF22IVF22_cast)

# Register itkImageToImageFilterICVF22IVF22 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterICVF22IVF22_swigregister(itkImageToImageFilterICVF22IVF22)
itkImageToImageFilterICVF22IVF22_cast = _itkImageToImageFilterAPython.itkImageToImageFilterICVF22IVF22_cast

class itkImageToImageFilterICVF23ICVF23(itk.itkImageSourcePython.itkImageSourceICVF23):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF23ICVF23_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF23ICVF23_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF23ICVF23_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF23ICVF23_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF23ICVF23_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF23ICVF23_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF23ICVF23_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF23ICVF23_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF23ICVF23_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF23ICVF23_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterICVF23ICVF23
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF23ICVF23_cast)

# Register itkImageToImageFilterICVF23ICVF23 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterICVF23ICVF23_swigregister(itkImageToImageFilterICVF23ICVF23)
itkImageToImageFilterICVF23ICVF23_cast = _itkImageToImageFilterAPython.itkImageToImageFilterICVF23ICVF23_cast

class itkImageToImageFilterICVF23IVF23(itk.itkImageSourcePython.itkImageSourceIVF23):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF23IVF23_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF23IVF23_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF23IVF23_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF23IVF23_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF23IVF23_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF23IVF23_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF23IVF23_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF23IVF23_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF23IVF23_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF23IVF23_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterICVF23IVF23
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF23IVF23_cast)

# Register itkImageToImageFilterICVF23IVF23 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterICVF23IVF23_swigregister(itkImageToImageFilterICVF23IVF23)
itkImageToImageFilterICVF23IVF23_cast = _itkImageToImageFilterAPython.itkImageToImageFilterICVF23IVF23_cast

class itkImageToImageFilterICVF32ICVF32(itk.itkImageSourcePython.itkImageSourceICVF32):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF32ICVF32_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF32ICVF32_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF32ICVF32_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF32ICVF32_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF32ICVF32_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF32ICVF32_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF32ICVF32_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF32ICVF32_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF32ICVF32_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF32ICVF32_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterICVF32ICVF32
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF32ICVF32_cast)

# Register itkImageToImageFilterICVF32ICVF32 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterICVF32ICVF32_swigregister(itkImageToImageFilterICVF32ICVF32)
itkImageToImageFilterICVF32ICVF32_cast = _itkImageToImageFilterAPython.itkImageToImageFilterICVF32ICVF32_cast

class itkImageToImageFilterICVF32IVF32(itk.itkImageSourcePython.itkImageSourceIVF32):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF32IVF32_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF32IVF32_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF32IVF32_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF32IVF32_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF32IVF32_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF32IVF32_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF32IVF32_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF32IVF32_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF32IVF32_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF32IVF32_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterICVF32IVF32
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF32IVF32_cast)

# Register itkImageToImageFilterICVF32IVF32 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterICVF32IVF32_swigregister(itkImageToImageFilterICVF32IVF32)
itkImageToImageFilterICVF32IVF32_cast = _itkImageToImageFilterAPython.itkImageToImageFilterICVF32IVF32_cast

class itkImageToImageFilterICVF33ICVF33(itk.itkImageSourcePython.itkImageSourceICVF33):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF33ICVF33_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF33ICVF33_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF33ICVF33_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF33ICVF33_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF33ICVF33_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF33ICVF33_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF33ICVF33_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF33ICVF33_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF33ICVF33_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF33ICVF33_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterICVF33ICVF33
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF33ICVF33_cast)

# Register itkImageToImageFilterICVF33ICVF33 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterICVF33ICVF33_swigregister(itkImageToImageFilterICVF33ICVF33)
itkImageToImageFilterICVF33ICVF33_cast = _itkImageToImageFilterAPython.itkImageToImageFilterICVF33ICVF33_cast

class itkImageToImageFilterICVF33IVF33(itk.itkImageSourcePython.itkImageSourceIVF33):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF33IVF33_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF33IVF33_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF33IVF33_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF33IVF33_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF33IVF33_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF33IVF33_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF33IVF33_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF33IVF33_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF33IVF33_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF33IVF33_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterICVF33IVF33
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF33IVF33_cast)

# Register itkImageToImageFilterICVF33IVF33 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterICVF33IVF33_swigregister(itkImageToImageFilterICVF33IVF33)
itkImageToImageFilterICVF33IVF33_cast = _itkImageToImageFilterAPython.itkImageToImageFilterICVF33IVF33_cast

class itkImageToImageFilterICVF42ICVF42(itk.itkImageSourcePython.itkImageSourceICVF42):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF42ICVF42_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF42ICVF42_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF42ICVF42_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF42ICVF42_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF42ICVF42_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF42ICVF42_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF42ICVF42_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF42ICVF42_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF42ICVF42_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF42ICVF42_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterICVF42ICVF42
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF42ICVF42_cast)

# Register itkImageToImageFilterICVF42ICVF42 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterICVF42ICVF42_swigregister(itkImageToImageFilterICVF42ICVF42)
itkImageToImageFilterICVF42ICVF42_cast = _itkImageToImageFilterAPython.itkImageToImageFilterICVF42ICVF42_cast

class itkImageToImageFilterICVF42IVF42(itk.itkImageSourcePython.itkImageSourceIVF42):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF42IVF42_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF42IVF42_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF42IVF42_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF42IVF42_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF42IVF42_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF42IVF42_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF42IVF42_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF42IVF42_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF42IVF42_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF42IVF42_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterICVF42IVF42
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF42IVF42_cast)

# Register itkImageToImageFilterICVF42IVF42 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterICVF42IVF42_swigregister(itkImageToImageFilterICVF42IVF42)
itkImageToImageFilterICVF42IVF42_cast = _itkImageToImageFilterAPython.itkImageToImageFilterICVF42IVF42_cast

class itkImageToImageFilterICVF43ICVF43(itk.itkImageSourcePython.itkImageSourceICVF43):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF43ICVF43_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF43ICVF43_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF43ICVF43_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF43ICVF43_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF43ICVF43_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF43ICVF43_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF43ICVF43_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF43ICVF43_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF43ICVF43_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF43ICVF43_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterICVF43ICVF43
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF43ICVF43_cast)

# Register itkImageToImageFilterICVF43ICVF43 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterICVF43ICVF43_swigregister(itkImageToImageFilterICVF43ICVF43)
itkImageToImageFilterICVF43ICVF43_cast = _itkImageToImageFilterAPython.itkImageToImageFilterICVF43ICVF43_cast

class itkImageToImageFilterICVF43IVF43(itk.itkImageSourcePython.itkImageSourceIVF43):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF43IVF43_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF43IVF43_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF43IVF43_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF43IVF43_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF43IVF43_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF43IVF43_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF43IVF43_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF43IVF43_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF43IVF43_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF43IVF43_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterICVF43IVF43
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterICVF43IVF43_cast)

# Register itkImageToImageFilterICVF43IVF43 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterICVF43IVF43_swigregister(itkImageToImageFilterICVF43IVF43)
itkImageToImageFilterICVF43IVF43_cast = _itkImageToImageFilterAPython.itkImageToImageFilterICVF43IVF43_cast

class itkImageToImageFilterID2ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterID2ID2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2ID2_cast)

# Register itkImageToImageFilterID2ID2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterID2ID2_swigregister(itkImageToImageFilterID2ID2)
itkImageToImageFilterID2ID2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterID2ID2_cast

class itkImageToImageFilterID2IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterID2IF2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IF2_cast)

# Register itkImageToImageFilterID2IF2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterID2IF2_swigregister(itkImageToImageFilterID2IF2)
itkImageToImageFilterID2IF2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterID2IF2_cast

class itkImageToImageFilterID2ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterID2ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2ISS2_cast)

# Register itkImageToImageFilterID2ISS2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterID2ISS2_swigregister(itkImageToImageFilterID2ISS2)
itkImageToImageFilterID2ISS2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterID2ISS2_cast

class itkImageToImageFilterID2IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterID2IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUC2_cast)

# Register itkImageToImageFilterID2IUC2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterID2IUC2_swigregister(itkImageToImageFilterID2IUC2)
itkImageToImageFilterID2IUC2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterID2IUC2_cast

class itkImageToImageFilterID2IUL2(itk.itkImageSourcePython.itkImageSourceIUL2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUL2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUL2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUL2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUL2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUL2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUL2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUL2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUL2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUL2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUL2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterID2IUL2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUL2_cast)

# Register itkImageToImageFilterID2IUL2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterID2IUL2_swigregister(itkImageToImageFilterID2IUL2)
itkImageToImageFilterID2IUL2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterID2IUL2_cast

class itkImageToImageFilterID2IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterID2IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterID2IUS2_cast)

# Register itkImageToImageFilterID2IUS2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterID2IUS2_swigregister(itkImageToImageFilterID2IUS2)
itkImageToImageFilterID2IUS2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterID2IUS2_cast

class itkImageToImageFilterID3ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterID3ID3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3ID3_cast)

# Register itkImageToImageFilterID3ID3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterID3ID3_swigregister(itkImageToImageFilterID3ID3)
itkImageToImageFilterID3ID3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterID3ID3_cast

class itkImageToImageFilterID3IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterID3IF3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IF3_cast)

# Register itkImageToImageFilterID3IF3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterID3IF3_swigregister(itkImageToImageFilterID3IF3)
itkImageToImageFilterID3IF3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterID3IF3_cast

class itkImageToImageFilterID3ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterID3ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3ISS3_cast)

# Register itkImageToImageFilterID3ISS3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterID3ISS3_swigregister(itkImageToImageFilterID3ISS3)
itkImageToImageFilterID3ISS3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterID3ISS3_cast

class itkImageToImageFilterID3IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterID3IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUC3_cast)

# Register itkImageToImageFilterID3IUC3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterID3IUC3_swigregister(itkImageToImageFilterID3IUC3)
itkImageToImageFilterID3IUC3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterID3IUC3_cast

class itkImageToImageFilterID3IUL3(itk.itkImageSourcePython.itkImageSourceIUL3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUL3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUL3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUL3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUL3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUL3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUL3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUL3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUL3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUL3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUL3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterID3IUL3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUL3_cast)

# Register itkImageToImageFilterID3IUL3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterID3IUL3_swigregister(itkImageToImageFilterID3IUL3)
itkImageToImageFilterID3IUL3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterID3IUL3_cast

class itkImageToImageFilterID3IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterID3IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterID3IUS3_cast)

# Register itkImageToImageFilterID3IUS3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterID3IUS3_swigregister(itkImageToImageFilterID3IUS3)
itkImageToImageFilterID3IUS3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterID3IUS3_cast

class itkImageToImageFilterIF2ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIF2ID2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2ID2_cast)

# Register itkImageToImageFilterIF2ID2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIF2ID2_swigregister(itkImageToImageFilterIF2ID2)
itkImageToImageFilterIF2ID2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIF2ID2_cast

class itkImageToImageFilterIF2IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIF2IF2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IF2_cast)

# Register itkImageToImageFilterIF2IF2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIF2IF2_swigregister(itkImageToImageFilterIF2IF2)
itkImageToImageFilterIF2IF2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIF2IF2_cast

class itkImageToImageFilterIF2ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIF2ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2ISS2_cast)

# Register itkImageToImageFilterIF2ISS2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIF2ISS2_swigregister(itkImageToImageFilterIF2ISS2)
itkImageToImageFilterIF2ISS2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIF2ISS2_cast

class itkImageToImageFilterIF2IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIF2IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUC2_cast)

# Register itkImageToImageFilterIF2IUC2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUC2_swigregister(itkImageToImageFilterIF2IUC2)
itkImageToImageFilterIF2IUC2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIF2IUC2_cast

class itkImageToImageFilterIF2IUL2(itk.itkImageSourcePython.itkImageSourceIUL2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUL2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUL2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUL2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUL2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUL2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUL2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUL2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUL2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUL2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUL2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIF2IUL2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUL2_cast)

# Register itkImageToImageFilterIF2IUL2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUL2_swigregister(itkImageToImageFilterIF2IUL2)
itkImageToImageFilterIF2IUL2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIF2IUL2_cast

class itkImageToImageFilterIF2IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIF2IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUS2_cast)

# Register itkImageToImageFilterIF2IUS2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIF2IUS2_swigregister(itkImageToImageFilterIF2IUS2)
itkImageToImageFilterIF2IUS2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIF2IUS2_cast

class itkImageToImageFilterIF3ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIF3ID3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3ID3_cast)

# Register itkImageToImageFilterIF3ID3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIF3ID3_swigregister(itkImageToImageFilterIF3ID3)
itkImageToImageFilterIF3ID3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIF3ID3_cast

class itkImageToImageFilterIF3IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIF3IF3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IF3_cast)

# Register itkImageToImageFilterIF3IF3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIF3IF3_swigregister(itkImageToImageFilterIF3IF3)
itkImageToImageFilterIF3IF3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIF3IF3_cast

class itkImageToImageFilterIF3ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIF3ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3ISS3_cast)

# Register itkImageToImageFilterIF3ISS3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIF3ISS3_swigregister(itkImageToImageFilterIF3ISS3)
itkImageToImageFilterIF3ISS3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIF3ISS3_cast

class itkImageToImageFilterIF3IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIF3IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUC3_cast)

# Register itkImageToImageFilterIF3IUC3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUC3_swigregister(itkImageToImageFilterIF3IUC3)
itkImageToImageFilterIF3IUC3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIF3IUC3_cast

class itkImageToImageFilterIF3IUL3(itk.itkImageSourcePython.itkImageSourceIUL3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUL3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUL3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUL3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUL3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUL3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUL3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUL3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUL3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUL3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUL3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIF3IUL3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUL3_cast)

# Register itkImageToImageFilterIF3IUL3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUL3_swigregister(itkImageToImageFilterIF3IUL3)
itkImageToImageFilterIF3IUL3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIF3IUL3_cast

class itkImageToImageFilterIF3IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIF3IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUS3_cast)

# Register itkImageToImageFilterIF3IUS3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIF3IUS3_swigregister(itkImageToImageFilterIF3IUS3)
itkImageToImageFilterIF3IUS3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIF3IUS3_cast

class itkImageToImageFilterIRGBAUC2IRGBAUC2(itk.itkImageSourcePython.itkImageSourceIRGBAUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC2IRGBAUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC2IRGBAUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC2IRGBAUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC2IRGBAUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC2IRGBAUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC2IRGBAUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC2IRGBAUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC2IRGBAUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC2IRGBAUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC2IRGBAUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIRGBAUC2IRGBAUC2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC2IRGBAUC2_cast)

# Register itkImageToImageFilterIRGBAUC2IRGBAUC2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC2IRGBAUC2_swigregister(itkImageToImageFilterIRGBAUC2IRGBAUC2)
itkImageToImageFilterIRGBAUC2IRGBAUC2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC2IRGBAUC2_cast

class itkImageToImageFilterIRGBAUC3IRGBAUC3(itk.itkImageSourcePython.itkImageSourceIRGBAUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC3IRGBAUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC3IRGBAUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC3IRGBAUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC3IRGBAUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC3IRGBAUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC3IRGBAUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC3IRGBAUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC3IRGBAUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC3IRGBAUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC3IRGBAUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIRGBAUC3IRGBAUC3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC3IRGBAUC3_cast)

# Register itkImageToImageFilterIRGBAUC3IRGBAUC3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC3IRGBAUC3_swigregister(itkImageToImageFilterIRGBAUC3IRGBAUC3)
itkImageToImageFilterIRGBAUC3IRGBAUC3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIRGBAUC3IRGBAUC3_cast

class itkImageToImageFilterIRGBUC2IRGBUC2(itk.itkImageSourcePython.itkImageSourceIRGBUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC2IRGBUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC2IRGBUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC2IRGBUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC2IRGBUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC2IRGBUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC2IRGBUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC2IRGBUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC2IRGBUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC2IRGBUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC2IRGBUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIRGBUC2IRGBUC2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC2IRGBUC2_cast)

# Register itkImageToImageFilterIRGBUC2IRGBUC2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC2IRGBUC2_swigregister(itkImageToImageFilterIRGBUC2IRGBUC2)
itkImageToImageFilterIRGBUC2IRGBUC2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC2IRGBUC2_cast

class itkImageToImageFilterIRGBUC3IRGBUC3(itk.itkImageSourcePython.itkImageSourceIRGBUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC3IRGBUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC3IRGBUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC3IRGBUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC3IRGBUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC3IRGBUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC3IRGBUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC3IRGBUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC3IRGBUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC3IRGBUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC3IRGBUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIRGBUC3IRGBUC3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC3IRGBUC3_cast)

# Register itkImageToImageFilterIRGBUC3IRGBUC3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC3IRGBUC3_swigregister(itkImageToImageFilterIRGBUC3IRGBUC3)
itkImageToImageFilterIRGBUC3IRGBUC3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIRGBUC3IRGBUC3_cast

class itkImageToImageFilterISS2ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterISS2ID2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2ID2_cast)

# Register itkImageToImageFilterISS2ID2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterISS2ID2_swigregister(itkImageToImageFilterISS2ID2)
itkImageToImageFilterISS2ID2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterISS2ID2_cast

class itkImageToImageFilterISS2IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterISS2IF2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IF2_cast)

# Register itkImageToImageFilterISS2IF2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterISS2IF2_swigregister(itkImageToImageFilterISS2IF2)
itkImageToImageFilterISS2IF2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterISS2IF2_cast

class itkImageToImageFilterISS2ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterISS2ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2ISS2_cast)

# Register itkImageToImageFilterISS2ISS2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterISS2ISS2_swigregister(itkImageToImageFilterISS2ISS2)
itkImageToImageFilterISS2ISS2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterISS2ISS2_cast

class itkImageToImageFilterISS2IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterISS2IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUC2_cast)

# Register itkImageToImageFilterISS2IUC2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUC2_swigregister(itkImageToImageFilterISS2IUC2)
itkImageToImageFilterISS2IUC2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterISS2IUC2_cast

class itkImageToImageFilterISS2IUL2(itk.itkImageSourcePython.itkImageSourceIUL2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUL2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUL2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUL2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUL2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUL2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUL2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUL2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUL2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUL2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUL2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterISS2IUL2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUL2_cast)

# Register itkImageToImageFilterISS2IUL2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUL2_swigregister(itkImageToImageFilterISS2IUL2)
itkImageToImageFilterISS2IUL2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterISS2IUL2_cast

class itkImageToImageFilterISS2IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterISS2IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUS2_cast)

# Register itkImageToImageFilterISS2IUS2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterISS2IUS2_swigregister(itkImageToImageFilterISS2IUS2)
itkImageToImageFilterISS2IUS2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterISS2IUS2_cast

class itkImageToImageFilterISS3ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterISS3ID3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3ID3_cast)

# Register itkImageToImageFilterISS3ID3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterISS3ID3_swigregister(itkImageToImageFilterISS3ID3)
itkImageToImageFilterISS3ID3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterISS3ID3_cast

class itkImageToImageFilterISS3IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterISS3IF3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IF3_cast)

# Register itkImageToImageFilterISS3IF3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterISS3IF3_swigregister(itkImageToImageFilterISS3IF3)
itkImageToImageFilterISS3IF3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterISS3IF3_cast

class itkImageToImageFilterISS3ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterISS3ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3ISS3_cast)

# Register itkImageToImageFilterISS3ISS3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterISS3ISS3_swigregister(itkImageToImageFilterISS3ISS3)
itkImageToImageFilterISS3ISS3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterISS3ISS3_cast

class itkImageToImageFilterISS3IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterISS3IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUC3_cast)

# Register itkImageToImageFilterISS3IUC3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUC3_swigregister(itkImageToImageFilterISS3IUC3)
itkImageToImageFilterISS3IUC3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterISS3IUC3_cast

class itkImageToImageFilterISS3IUL3(itk.itkImageSourcePython.itkImageSourceIUL3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUL3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUL3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUL3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUL3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUL3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUL3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUL3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUL3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUL3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUL3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterISS3IUL3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUL3_cast)

# Register itkImageToImageFilterISS3IUL3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUL3_swigregister(itkImageToImageFilterISS3IUL3)
itkImageToImageFilterISS3IUL3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterISS3IUL3_cast

class itkImageToImageFilterISS3IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterISS3IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUS3_cast)

# Register itkImageToImageFilterISS3IUS3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterISS3IUS3_swigregister(itkImageToImageFilterISS3IUS3)
itkImageToImageFilterISS3IUS3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterISS3IUS3_cast

class itkImageToImageFilterIUC2ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUC2ID2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ID2_cast)

# Register itkImageToImageFilterIUC2ID2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ID2_swigregister(itkImageToImageFilterIUC2ID2)
itkImageToImageFilterIUC2ID2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUC2ID2_cast

class itkImageToImageFilterIUC2IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUC2IF2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IF2_cast)

# Register itkImageToImageFilterIUC2IF2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IF2_swigregister(itkImageToImageFilterIUC2IF2)
itkImageToImageFilterIUC2IF2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUC2IF2_cast

class itkImageToImageFilterIUC2ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUC2ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ISS2_cast)

# Register itkImageToImageFilterIUC2ISS2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUC2ISS2_swigregister(itkImageToImageFilterIUC2ISS2)
itkImageToImageFilterIUC2ISS2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUC2ISS2_cast

class itkImageToImageFilterIUC2IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUC2IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUC2_cast)

# Register itkImageToImageFilterIUC2IUC2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUC2_swigregister(itkImageToImageFilterIUC2IUC2)
itkImageToImageFilterIUC2IUC2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUC2_cast

class itkImageToImageFilterIUC2IUL2(itk.itkImageSourcePython.itkImageSourceIUL2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUL2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUL2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUL2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUL2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUL2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUL2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUL2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUL2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUL2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUL2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUC2IUL2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUL2_cast)

# Register itkImageToImageFilterIUC2IUL2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUL2_swigregister(itkImageToImageFilterIUC2IUL2)
itkImageToImageFilterIUC2IUL2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUL2_cast

class itkImageToImageFilterIUC2IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUC2IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUS2_cast)

# Register itkImageToImageFilterIUC2IUS2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUS2_swigregister(itkImageToImageFilterIUC2IUS2)
itkImageToImageFilterIUC2IUS2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUS2_cast

class itkImageToImageFilterIUC3ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUC3ID3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ID3_cast)

# Register itkImageToImageFilterIUC3ID3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ID3_swigregister(itkImageToImageFilterIUC3ID3)
itkImageToImageFilterIUC3ID3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUC3ID3_cast

class itkImageToImageFilterIUC3IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUC3IF3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IF3_cast)

# Register itkImageToImageFilterIUC3IF3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IF3_swigregister(itkImageToImageFilterIUC3IF3)
itkImageToImageFilterIUC3IF3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUC3IF3_cast

class itkImageToImageFilterIUC3ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUC3ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ISS3_cast)

# Register itkImageToImageFilterIUC3ISS3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUC3ISS3_swigregister(itkImageToImageFilterIUC3ISS3)
itkImageToImageFilterIUC3ISS3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUC3ISS3_cast

class itkImageToImageFilterIUC3IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUC3IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUC3_cast)

# Register itkImageToImageFilterIUC3IUC3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUC3_swigregister(itkImageToImageFilterIUC3IUC3)
itkImageToImageFilterIUC3IUC3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUC3_cast

class itkImageToImageFilterIUC3IUL3(itk.itkImageSourcePython.itkImageSourceIUL3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUL3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUL3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUL3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUL3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUL3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUL3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUL3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUL3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUL3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUL3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUC3IUL3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUL3_cast)

# Register itkImageToImageFilterIUC3IUL3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUL3_swigregister(itkImageToImageFilterIUC3IUL3)
itkImageToImageFilterIUC3IUL3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUL3_cast

class itkImageToImageFilterIUC3IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUC3IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUS3_cast)

# Register itkImageToImageFilterIUC3IUS3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUS3_swigregister(itkImageToImageFilterIUC3IUS3)
itkImageToImageFilterIUC3IUS3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUS3_cast

class itkImageToImageFilterIUL2ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUL2ID2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ID2_cast)

# Register itkImageToImageFilterIUL2ID2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ID2_swigregister(itkImageToImageFilterIUL2ID2)
itkImageToImageFilterIUL2ID2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUL2ID2_cast

class itkImageToImageFilterIUL2IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUL2IF2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IF2_cast)

# Register itkImageToImageFilterIUL2IF2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IF2_swigregister(itkImageToImageFilterIUL2IF2)
itkImageToImageFilterIUL2IF2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUL2IF2_cast

class itkImageToImageFilterIUL2ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUL2ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ISS2_cast)

# Register itkImageToImageFilterIUL2ISS2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUL2ISS2_swigregister(itkImageToImageFilterIUL2ISS2)
itkImageToImageFilterIUL2ISS2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUL2ISS2_cast

class itkImageToImageFilterIUL2IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUL2IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUC2_cast)

# Register itkImageToImageFilterIUL2IUC2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUC2_swigregister(itkImageToImageFilterIUL2IUC2)
itkImageToImageFilterIUL2IUC2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUC2_cast

class itkImageToImageFilterIUL2IUL2(itk.itkImageSourcePython.itkImageSourceIUL2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUL2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUL2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUL2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUL2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUL2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUL2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUL2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUL2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUL2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUL2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUL2IUL2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUL2_cast)

# Register itkImageToImageFilterIUL2IUL2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUL2_swigregister(itkImageToImageFilterIUL2IUL2)
itkImageToImageFilterIUL2IUL2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUL2_cast

class itkImageToImageFilterIUL2IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUL2IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUS2_cast)

# Register itkImageToImageFilterIUL2IUS2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUS2_swigregister(itkImageToImageFilterIUL2IUS2)
itkImageToImageFilterIUL2IUS2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUL2IUS2_cast

class itkImageToImageFilterIUL3ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUL3ID3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ID3_cast)

# Register itkImageToImageFilterIUL3ID3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ID3_swigregister(itkImageToImageFilterIUL3ID3)
itkImageToImageFilterIUL3ID3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUL3ID3_cast

class itkImageToImageFilterIUL3IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUL3IF3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IF3_cast)

# Register itkImageToImageFilterIUL3IF3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IF3_swigregister(itkImageToImageFilterIUL3IF3)
itkImageToImageFilterIUL3IF3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUL3IF3_cast

class itkImageToImageFilterIUL3ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUL3ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ISS3_cast)

# Register itkImageToImageFilterIUL3ISS3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUL3ISS3_swigregister(itkImageToImageFilterIUL3ISS3)
itkImageToImageFilterIUL3ISS3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUL3ISS3_cast

class itkImageToImageFilterIUL3IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUL3IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUC3_cast)

# Register itkImageToImageFilterIUL3IUC3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUC3_swigregister(itkImageToImageFilterIUL3IUC3)
itkImageToImageFilterIUL3IUC3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUC3_cast

class itkImageToImageFilterIUL3IUL3(itk.itkImageSourcePython.itkImageSourceIUL3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUL3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUL3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUL3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUL3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUL3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUL3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUL3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUL3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUL3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUL3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUL3IUL3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUL3_cast)

# Register itkImageToImageFilterIUL3IUL3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUL3_swigregister(itkImageToImageFilterIUL3IUL3)
itkImageToImageFilterIUL3IUL3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUL3_cast

class itkImageToImageFilterIUL3IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUL3IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUS3_cast)

# Register itkImageToImageFilterIUL3IUS3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUS3_swigregister(itkImageToImageFilterIUL3IUS3)
itkImageToImageFilterIUL3IUS3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUL3IUS3_cast

class itkImageToImageFilterIULL2ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIULL2ID2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ID2_cast)

# Register itkImageToImageFilterIULL2ID2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ID2_swigregister(itkImageToImageFilterIULL2ID2)
itkImageToImageFilterIULL2ID2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIULL2ID2_cast

class itkImageToImageFilterIULL2IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIULL2IF2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IF2_cast)

# Register itkImageToImageFilterIULL2IF2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IF2_swigregister(itkImageToImageFilterIULL2IF2)
itkImageToImageFilterIULL2IF2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIULL2IF2_cast

class itkImageToImageFilterIULL2ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIULL2ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ISS2_cast)

# Register itkImageToImageFilterIULL2ISS2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIULL2ISS2_swigregister(itkImageToImageFilterIULL2ISS2)
itkImageToImageFilterIULL2ISS2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIULL2ISS2_cast

class itkImageToImageFilterIULL2IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIULL2IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUC2_cast)

# Register itkImageToImageFilterIULL2IUC2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUC2_swigregister(itkImageToImageFilterIULL2IUC2)
itkImageToImageFilterIULL2IUC2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUC2_cast

class itkImageToImageFilterIULL2IUL2(itk.itkImageSourcePython.itkImageSourceIUL2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUL2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUL2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUL2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUL2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUL2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUL2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUL2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUL2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUL2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUL2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIULL2IUL2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUL2_cast)

# Register itkImageToImageFilterIULL2IUL2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUL2_swigregister(itkImageToImageFilterIULL2IUL2)
itkImageToImageFilterIULL2IUL2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUL2_cast

class itkImageToImageFilterIULL2IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIULL2IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUS2_cast)

# Register itkImageToImageFilterIULL2IUS2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUS2_swigregister(itkImageToImageFilterIULL2IUS2)
itkImageToImageFilterIULL2IUS2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIULL2IUS2_cast

class itkImageToImageFilterIULL3ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIULL3ID3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ID3_cast)

# Register itkImageToImageFilterIULL3ID3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ID3_swigregister(itkImageToImageFilterIULL3ID3)
itkImageToImageFilterIULL3ID3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIULL3ID3_cast

class itkImageToImageFilterIULL3IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIULL3IF3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IF3_cast)

# Register itkImageToImageFilterIULL3IF3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IF3_swigregister(itkImageToImageFilterIULL3IF3)
itkImageToImageFilterIULL3IF3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIULL3IF3_cast

class itkImageToImageFilterIULL3ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIULL3ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ISS3_cast)

# Register itkImageToImageFilterIULL3ISS3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIULL3ISS3_swigregister(itkImageToImageFilterIULL3ISS3)
itkImageToImageFilterIULL3ISS3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIULL3ISS3_cast

class itkImageToImageFilterIULL3IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIULL3IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUC3_cast)

# Register itkImageToImageFilterIULL3IUC3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUC3_swigregister(itkImageToImageFilterIULL3IUC3)
itkImageToImageFilterIULL3IUC3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUC3_cast

class itkImageToImageFilterIULL3IUL3(itk.itkImageSourcePython.itkImageSourceIUL3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUL3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUL3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUL3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUL3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUL3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUL3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUL3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUL3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUL3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUL3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIULL3IUL3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUL3_cast)

# Register itkImageToImageFilterIULL3IUL3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUL3_swigregister(itkImageToImageFilterIULL3IUL3)
itkImageToImageFilterIULL3IUL3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUL3_cast

class itkImageToImageFilterIULL3IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIULL3IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUS3_cast)

# Register itkImageToImageFilterIULL3IUS3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUS3_swigregister(itkImageToImageFilterIULL3IUS3)
itkImageToImageFilterIULL3IUS3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIULL3IUS3_cast

class itkImageToImageFilterIUS2ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUS2ID2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ID2_cast)

# Register itkImageToImageFilterIUS2ID2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ID2_swigregister(itkImageToImageFilterIUS2ID2)
itkImageToImageFilterIUS2ID2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUS2ID2_cast

class itkImageToImageFilterIUS2IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUS2IF2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IF2_cast)

# Register itkImageToImageFilterIUS2IF2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IF2_swigregister(itkImageToImageFilterIUS2IF2)
itkImageToImageFilterIUS2IF2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUS2IF2_cast

class itkImageToImageFilterIUS2ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUS2ISS2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ISS2_cast)

# Register itkImageToImageFilterIUS2ISS2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUS2ISS2_swigregister(itkImageToImageFilterIUS2ISS2)
itkImageToImageFilterIUS2ISS2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUS2ISS2_cast

class itkImageToImageFilterIUS2IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUS2IUC2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUC2_cast)

# Register itkImageToImageFilterIUS2IUC2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUC2_swigregister(itkImageToImageFilterIUS2IUC2)
itkImageToImageFilterIUS2IUC2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUC2_cast

class itkImageToImageFilterIUS2IUL2(itk.itkImageSourcePython.itkImageSourceIUL2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUL2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUL2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUL2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUL2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUL2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUL2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUL2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUL2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUL2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUL2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUS2IUL2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUL2_cast)

# Register itkImageToImageFilterIUS2IUL2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUL2_swigregister(itkImageToImageFilterIUS2IUL2)
itkImageToImageFilterIUS2IUL2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUL2_cast

class itkImageToImageFilterIUS2IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUS2IUS2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUS2_cast)

# Register itkImageToImageFilterIUS2IUS2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUS2_swigregister(itkImageToImageFilterIUS2IUS2)
itkImageToImageFilterIUS2IUS2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUS2_cast

class itkImageToImageFilterIUS3ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUS3ID3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ID3_cast)

# Register itkImageToImageFilterIUS3ID3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ID3_swigregister(itkImageToImageFilterIUS3ID3)
itkImageToImageFilterIUS3ID3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUS3ID3_cast

class itkImageToImageFilterIUS3IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUS3IF3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IF3_cast)

# Register itkImageToImageFilterIUS3IF3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IF3_swigregister(itkImageToImageFilterIUS3IF3)
itkImageToImageFilterIUS3IF3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUS3IF3_cast

class itkImageToImageFilterIUS3ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUS3ISS3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ISS3_cast)

# Register itkImageToImageFilterIUS3ISS3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUS3ISS3_swigregister(itkImageToImageFilterIUS3ISS3)
itkImageToImageFilterIUS3ISS3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUS3ISS3_cast

class itkImageToImageFilterIUS3IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUS3IUC3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUC3_cast)

# Register itkImageToImageFilterIUS3IUC3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUC3_swigregister(itkImageToImageFilterIUS3IUC3)
itkImageToImageFilterIUS3IUC3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUC3_cast

class itkImageToImageFilterIUS3IUL3(itk.itkImageSourcePython.itkImageSourceIUL3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUL3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUL3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUL3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUL3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUL3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUL3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUL3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUL3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUL3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUL3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUS3IUL3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUL3_cast)

# Register itkImageToImageFilterIUS3IUL3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUL3_swigregister(itkImageToImageFilterIUS3IUL3)
itkImageToImageFilterIUS3IUL3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUL3_cast

class itkImageToImageFilterIUS3IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIUS3IUS3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUS3_cast)

# Register itkImageToImageFilterIUS3IUS3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUS3_swigregister(itkImageToImageFilterIUS3IUS3)
itkImageToImageFilterIUS3IUS3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUS3_cast

class itkImageToImageFilterIVF22ICVF22(itk.itkImageSourcePython.itkImageSourceICVF22):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF22_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF22_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF22_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF22_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF22_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF22_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF22_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF22_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF22_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF22_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIVF22ICVF22
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF22_cast)

# Register itkImageToImageFilterIVF22ICVF22 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF22_swigregister(itkImageToImageFilterIVF22ICVF22)
itkImageToImageFilterIVF22ICVF22_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF22_cast

class itkImageToImageFilterIVF22ICVF42(itk.itkImageSourcePython.itkImageSourceICVF42):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF42_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF42_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF42_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF42_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF42_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF42_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF42_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF42_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF42_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF42_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIVF22ICVF42
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF42_cast)

# Register itkImageToImageFilterIVF22ICVF42 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF42_swigregister(itkImageToImageFilterIVF22ICVF42)
itkImageToImageFilterIVF22ICVF42_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIVF22ICVF42_cast

class itkImageToImageFilterIVF22IVF22(itk.itkImageSourcePython.itkImageSourceIVF22):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22IVF22_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22IVF22_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22IVF22_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22IVF22_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22IVF22_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22IVF22_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22IVF22_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22IVF22_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22IVF22_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22IVF22_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIVF22IVF22
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF22IVF22_cast)

# Register itkImageToImageFilterIVF22IVF22 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIVF22IVF22_swigregister(itkImageToImageFilterIVF22IVF22)
itkImageToImageFilterIVF22IVF22_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIVF22IVF22_cast

class itkImageToImageFilterIVF23ICVF23(itk.itkImageSourcePython.itkImageSourceICVF23):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF23_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF23_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF23_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF23_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF23_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF23_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF23_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF23_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF23_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF23_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIVF23ICVF23
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF23_cast)

# Register itkImageToImageFilterIVF23ICVF23 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF23_swigregister(itkImageToImageFilterIVF23ICVF23)
itkImageToImageFilterIVF23ICVF23_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF23_cast

class itkImageToImageFilterIVF23ICVF43(itk.itkImageSourcePython.itkImageSourceICVF43):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF43_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF43_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF43_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF43_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF43_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF43_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF43_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF43_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF43_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF43_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIVF23ICVF43
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF43_cast)

# Register itkImageToImageFilterIVF23ICVF43 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF43_swigregister(itkImageToImageFilterIVF23ICVF43)
itkImageToImageFilterIVF23ICVF43_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIVF23ICVF43_cast

class itkImageToImageFilterIVF23IVF23(itk.itkImageSourcePython.itkImageSourceIVF23):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23IVF23_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23IVF23_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23IVF23_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23IVF23_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23IVF23_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23IVF23_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23IVF23_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23IVF23_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23IVF23_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23IVF23_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIVF23IVF23
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF23IVF23_cast)

# Register itkImageToImageFilterIVF23IVF23 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIVF23IVF23_swigregister(itkImageToImageFilterIVF23IVF23)
itkImageToImageFilterIVF23IVF23_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIVF23IVF23_cast

class itkImageToImageFilterIVF32ICVF32(itk.itkImageSourcePython.itkImageSourceICVF32):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF32ICVF32_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF32ICVF32_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF32ICVF32_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF32ICVF32_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF32ICVF32_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF32ICVF32_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF32ICVF32_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF32ICVF32_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF32ICVF32_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF32ICVF32_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIVF32ICVF32
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF32ICVF32_cast)

# Register itkImageToImageFilterIVF32ICVF32 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIVF32ICVF32_swigregister(itkImageToImageFilterIVF32ICVF32)
itkImageToImageFilterIVF32ICVF32_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIVF32ICVF32_cast

class itkImageToImageFilterIVF32IVF32(itk.itkImageSourcePython.itkImageSourceIVF32):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF32IVF32_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF32IVF32_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF32IVF32_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF32IVF32_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF32IVF32_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF32IVF32_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF32IVF32_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF32IVF32_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF32IVF32_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF32IVF32_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIVF32IVF32
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF32IVF32_cast)

# Register itkImageToImageFilterIVF32IVF32 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIVF32IVF32_swigregister(itkImageToImageFilterIVF32IVF32)
itkImageToImageFilterIVF32IVF32_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIVF32IVF32_cast

class itkImageToImageFilterIVF33ICVF33(itk.itkImageSourcePython.itkImageSourceICVF33):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF33ICVF33_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF33ICVF33_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF33ICVF33_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF33ICVF33_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF33ICVF33_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF33ICVF33_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF33ICVF33_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF33ICVF33_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF33ICVF33_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF33ICVF33_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIVF33ICVF33
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF33ICVF33_cast)

# Register itkImageToImageFilterIVF33ICVF33 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIVF33ICVF33_swigregister(itkImageToImageFilterIVF33ICVF33)
itkImageToImageFilterIVF33ICVF33_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIVF33ICVF33_cast

class itkImageToImageFilterIVF33IVF33(itk.itkImageSourcePython.itkImageSourceIVF33):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF33IVF33_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF33IVF33_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF33IVF33_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF33IVF33_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF33IVF33_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF33IVF33_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF33IVF33_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF33IVF33_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF33IVF33_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF33IVF33_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIVF33IVF33
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF33IVF33_cast)

# Register itkImageToImageFilterIVF33IVF33 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIVF33IVF33_swigregister(itkImageToImageFilterIVF33IVF33)
itkImageToImageFilterIVF33IVF33_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIVF33IVF33_cast

class itkImageToImageFilterIVF42ICVF42(itk.itkImageSourcePython.itkImageSourceICVF42):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF42ICVF42_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF42ICVF42_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF42ICVF42_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF42ICVF42_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF42ICVF42_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF42ICVF42_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF42ICVF42_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF42ICVF42_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF42ICVF42_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF42ICVF42_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIVF42ICVF42
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF42ICVF42_cast)

# Register itkImageToImageFilterIVF42ICVF42 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIVF42ICVF42_swigregister(itkImageToImageFilterIVF42ICVF42)
itkImageToImageFilterIVF42ICVF42_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIVF42ICVF42_cast

class itkImageToImageFilterIVF42IVF42(itk.itkImageSourcePython.itkImageSourceIVF42):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF42IVF42_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF42IVF42_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF42IVF42_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF42IVF42_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF42IVF42_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF42IVF42_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF42IVF42_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF42IVF42_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF42IVF42_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF42IVF42_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIVF42IVF42
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF42IVF42_cast)

# Register itkImageToImageFilterIVF42IVF42 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIVF42IVF42_swigregister(itkImageToImageFilterIVF42IVF42)
itkImageToImageFilterIVF42IVF42_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIVF42IVF42_cast

class itkImageToImageFilterIVF43ICVF43(itk.itkImageSourcePython.itkImageSourceICVF43):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF43ICVF43_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF43ICVF43_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF43ICVF43_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF43ICVF43_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF43ICVF43_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF43ICVF43_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF43ICVF43_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF43ICVF43_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF43ICVF43_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF43ICVF43_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIVF43ICVF43
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF43ICVF43_cast)

# Register itkImageToImageFilterIVF43ICVF43 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIVF43ICVF43_swigregister(itkImageToImageFilterIVF43ICVF43)
itkImageToImageFilterIVF43ICVF43_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIVF43ICVF43_cast

class itkImageToImageFilterIVF43IVF43(itk.itkImageSourcePython.itkImageSourceIVF43):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF43IVF43_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF43IVF43_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF43IVF43_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF43IVF43_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF43IVF43_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF43IVF43_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF43IVF43_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF43IVF43_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF43IVF43_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF43IVF43_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterIVF43IVF43
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterIVF43IVF43_cast)

# Register itkImageToImageFilterIVF43IVF43 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterIVF43IVF43_swigregister(itkImageToImageFilterIVF43IVF43)
itkImageToImageFilterIVF43IVF43_cast = _itkImageToImageFilterAPython.itkImageToImageFilterIVF43IVF43_cast

class itkImageToImageFilterVID2VID2(itk.itkImageSourcePython.itkImageSourceVID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVID2VID2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVID2VID2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVID2VID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVID2VID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVID2VID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVID2VID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVID2VID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVID2VID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVID2VID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVID2VID2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterVID2VID2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterVID2VID2_cast)

# Register itkImageToImageFilterVID2VID2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterVID2VID2_swigregister(itkImageToImageFilterVID2VID2)
itkImageToImageFilterVID2VID2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterVID2VID2_cast

class itkImageToImageFilterVID3VID3(itk.itkImageSourcePython.itkImageSourceVID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVID3VID3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVID3VID3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVID3VID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVID3VID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVID3VID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVID3VID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVID3VID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVID3VID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVID3VID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVID3VID3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterVID3VID3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterVID3VID3_cast)

# Register itkImageToImageFilterVID3VID3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterVID3VID3_swigregister(itkImageToImageFilterVID3VID3)
itkImageToImageFilterVID3VID3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterVID3VID3_cast

class itkImageToImageFilterVIF2VIF2(itk.itkImageSourcePython.itkImageSourceVIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIF2VIF2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIF2VIF2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIF2VIF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIF2VIF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIF2VIF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIF2VIF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIF2VIF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIF2VIF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIF2VIF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIF2VIF2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterVIF2VIF2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIF2VIF2_cast)

# Register itkImageToImageFilterVIF2VIF2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterVIF2VIF2_swigregister(itkImageToImageFilterVIF2VIF2)
itkImageToImageFilterVIF2VIF2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterVIF2VIF2_cast

class itkImageToImageFilterVIF3VIF3(itk.itkImageSourcePython.itkImageSourceVIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIF3VIF3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIF3VIF3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIF3VIF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIF3VIF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIF3VIF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIF3VIF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIF3VIF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIF3VIF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIF3VIF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIF3VIF3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterVIF3VIF3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIF3VIF3_cast)

# Register itkImageToImageFilterVIF3VIF3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterVIF3VIF3_swigregister(itkImageToImageFilterVIF3VIF3)
itkImageToImageFilterVIF3VIF3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterVIF3VIF3_cast

class itkImageToImageFilterVISS2VISS2(itk.itkImageSourcePython.itkImageSourceVISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVISS2VISS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVISS2VISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVISS2VISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVISS2VISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVISS2VISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVISS2VISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVISS2VISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVISS2VISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVISS2VISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVISS2VISS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterVISS2VISS2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterVISS2VISS2_cast)

# Register itkImageToImageFilterVISS2VISS2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterVISS2VISS2_swigregister(itkImageToImageFilterVISS2VISS2)
itkImageToImageFilterVISS2VISS2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterVISS2VISS2_cast

class itkImageToImageFilterVISS3VISS3(itk.itkImageSourcePython.itkImageSourceVISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVISS3VISS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVISS3VISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVISS3VISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVISS3VISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVISS3VISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVISS3VISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVISS3VISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVISS3VISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVISS3VISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVISS3VISS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterVISS3VISS3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterVISS3VISS3_cast)

# Register itkImageToImageFilterVISS3VISS3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterVISS3VISS3_swigregister(itkImageToImageFilterVISS3VISS3)
itkImageToImageFilterVISS3VISS3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterVISS3VISS3_cast

class itkImageToImageFilterVIUC2VIUC2(itk.itkImageSourcePython.itkImageSourceVIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUC2VIUC2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUC2VIUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUC2VIUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUC2VIUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUC2VIUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUC2VIUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUC2VIUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUC2VIUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUC2VIUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUC2VIUC2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterVIUC2VIUC2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUC2VIUC2_cast)

# Register itkImageToImageFilterVIUC2VIUC2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterVIUC2VIUC2_swigregister(itkImageToImageFilterVIUC2VIUC2)
itkImageToImageFilterVIUC2VIUC2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterVIUC2VIUC2_cast

class itkImageToImageFilterVIUC3VIUC3(itk.itkImageSourcePython.itkImageSourceVIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUC3VIUC3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUC3VIUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUC3VIUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUC3VIUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUC3VIUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUC3VIUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUC3VIUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUC3VIUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUC3VIUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUC3VIUC3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterVIUC3VIUC3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUC3VIUC3_cast)

# Register itkImageToImageFilterVIUC3VIUC3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterVIUC3VIUC3_swigregister(itkImageToImageFilterVIUC3VIUC3)
itkImageToImageFilterVIUC3VIUC3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterVIUC3VIUC3_cast

class itkImageToImageFilterVIUS2VIUS2(itk.itkImageSourcePython.itkImageSourceVIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUS2VIUS2_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUS2VIUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUS2VIUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUS2VIUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUS2VIUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUS2VIUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUS2VIUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUS2VIUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUS2VIUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUS2VIUS2_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterVIUS2VIUS2
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUS2VIUS2_cast)

# Register itkImageToImageFilterVIUS2VIUS2 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterVIUS2VIUS2_swigregister(itkImageToImageFilterVIUS2VIUS2)
itkImageToImageFilterVIUS2VIUS2_cast = _itkImageToImageFilterAPython.itkImageToImageFilterVIUS2VIUS2_cast

class itkImageToImageFilterVIUS3VIUS3(itk.itkImageSourcePython.itkImageSourceVIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some precondition,
    in which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUS3VIUS3_SetInput)
    GetInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUS3VIUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUS3VIUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUS3VIUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUS3VIUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUS3VIUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUS3VIUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUS3VIUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUS3VIUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUS3VIUS3_GetDirectionTolerance)
    __swig_destroy__ = _itkImageToImageFilterAPython.delete_itkImageToImageFilterVIUS3VIUS3
    cast = _swig_new_static_method(_itkImageToImageFilterAPython.itkImageToImageFilterVIUS3VIUS3_cast)

# Register itkImageToImageFilterVIUS3VIUS3 in _itkImageToImageFilterAPython:
_itkImageToImageFilterAPython.itkImageToImageFilterVIUS3VIUS3_swigregister(itkImageToImageFilterVIUS3VIUS3)
itkImageToImageFilterVIUS3VIUS3_cast = _itkImageToImageFilterAPython.itkImageToImageFilterVIUS3VIUS3_cast


import itkHelpers
@itkHelpers.accept_numpy_array_like_xarray
def image_to_image_filter(*args, **kwargs):
    """Procedural interface for ImageToImageFilter"""
    import itk
    instance = itk.ImageToImageFilter.New(*args, **kwargs)
    return instance.__internal_call__()

def image_to_image_filter_init_docstring():
    import itk
    import itkTemplate
    import itkHelpers
    if isinstance(itk.ImageToImageFilter, itkTemplate.itkTemplate):
        filter_object = itk.ImageToImageFilter.values()[0]
    else:
        filter_object = itk.ImageToImageFilter

    image_to_image_filter.__doc__ = filter_object.__doc__
    image_to_image_filter.__doc__ += "\n Args are Input(s) to the filter.\n"
    image_to_image_filter.__doc__ += "\n Available Keyword Arguments:\n"
    if isinstance(itk.ImageToImageFilter, itkTemplate.itkTemplate):
        image_to_image_filter.__doc__ += itkHelpers.filter_args(filter_object)[0]
        image_to_image_filter.__doc__ += "\n"
        image_to_image_filter.__doc__ += itkHelpers.filter_args(filter_object)[1]
    else:
        image_to_image_filter.__doc__ += "".join([
            "  " + itkHelpers.camel_to_snake_case(item[3:]) + "\n"
            for item in dir(filter_object)
            if item.startswith("Set")])



