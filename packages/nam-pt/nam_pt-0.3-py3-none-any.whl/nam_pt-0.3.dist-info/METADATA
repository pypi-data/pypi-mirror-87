Metadata-Version: 2.1
Name: nam-pt
Version: 0.3
Summary: Neural Additive Models (PyTorch): Intepretable ML with Neural Nets
Home-page: https://github.com/kherud/neural-additive-models-pt
Author: Konstantin Herud
License: Apache 2.0
Keywords: nam,interpretability,machine,learning,research
Platform: UNKNOWN
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.5
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Scientific/Engineering :: Mathematics
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development
Classifier: Topic :: Software Development :: Libraries
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Description-Content-Type: text/markdown
Requires-Dist: torch (==1.7.0)
Requires-Dist: fsspec (==0.8.4)
Requires-Dist: pandas (==1.1.4)
Requires-Dist: tqdm (==4.54.0)
Requires-Dist: sklearn (==0.0)
Requires-Dist: absl-py (==0.11.0)
Requires-Dist: gcsfs (==0.7.1)

# [Neural Additive Models (PyTorch)](https://github.com/google-research/google-research/tree/master/neural_additive_models)

This is a PyTorch re-implementation for neural additive models, check out:

- [Neural Additive Models: Interpretable Machine Learning with Neural Nets](https://arxiv.org/abs/2004.13912).
- [TensorFlow OG Implementation](https://github.com/google-research/google-research/tree/master/neural_additive_models)

<img src="https://i.imgur.com/Hvb7sb2.jpg" width="50%" alt="Neural Additive Model" >

## Install Package



## Dependencies

- torch==1.7.0
- fsspec==0.8.4
- pandas==1.1.4
- tqdm==4.54.0
- sklearn==0.0
- absl-py==0.11.0
- gcsfs==0.7.1

## Usage

```
conda env create -f environment.yml
conda activate nam-pt
python run.py
```

Citing
------
If you use this code in your research, please cite the following paper:

> Agarwal, R., Frosst, N., Zhang, X., Caruana, R., & Hinton, G. E. (2020).
> Neural additive models: Interpretable machine learning with neural nets.
> arXiv preprint arXiv:2004.13912


      @article{agarwal2020neural,
        title={Neural additive models: Interpretable machine learning with neural nets},
        author={Agarwal, Rishabh and Frosst, Nicholas and Zhang, Xuezhou and
        Caruana, Rich and Hinton, Geoffrey E},
        journal={arXiv preprint arXiv:2004.13912},
        year={2020}
      }

---

*Disclaimer about COMPAS dataset: It is important to note that
developing a machine learning model to predict pre-trial detention has a
number of important ethical considerations. You can learn more about these
issues in the Partnership on AI
[Report on Algorithmic Risk Assessment Tools in the U.S. Criminal Justice System](https://www.partnershiponai.org/report-on-machine-learning-in-risk-assessment-tools-in-the-u-s-criminal-justice-system/).
The Partnership on AI is a multi-stakeholder organization -- of which Google
is a member -- that creates guidelines around AI.*

*Weâ€™re using the COMPAS dataset only as an example of how to identify and
remediate fairness concerns in data. This dataset is canonical in the
algorithmic fairness literature.*

*Disclaimer: This is not an official Google product.*


