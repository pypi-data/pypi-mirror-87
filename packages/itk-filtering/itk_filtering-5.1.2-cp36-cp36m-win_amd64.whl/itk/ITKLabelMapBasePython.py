# This file was automatically generated by SWIG (http://www.swig.org).
# Version 4.0.1
#
# Do not make changes to this file unless you know what you are doing--modify
# the SWIG interface file instead.


from . import _ITKLabelMapPython


from . import _ITKLabelMapPython


from . import _ITKLabelMapPython


from . import _ITKLabelMapPython



from sys import version_info as _swig_python_version_info
if _swig_python_version_info < (2, 7, 0):
    raise RuntimeError("Python 2.7 or later required")

# Import the low-level C/C++ module
if __package__ or "." in __name__:
    from . import _ITKLabelMapBasePython
else:
    import _ITKLabelMapBasePython

try:
    import builtins as __builtin__
except ImportError:
    import __builtin__

_swig_new_instance_method = _ITKLabelMapBasePython.SWIG_PyInstanceMethod_New
_swig_new_static_method = _ITKLabelMapBasePython.SWIG_PyStaticMethod_New

def _swig_repr(self):
    try:
        strthis = "proxy of " + self.this.__repr__()
    except __builtin__.Exception:
        strthis = ""
    return "<%s.%s; %s >" % (self.__class__.__module__, self.__class__.__name__, strthis,)


def _swig_setattr_nondynamic_instance_variable(set):
    def set_instance_attr(self, name, value):
        if name == "thisown":
            self.this.own(value)
        elif name == "this":
            set(self, name, value)
        elif hasattr(self, name) and isinstance(getattr(type(self), name), property):
            set(self, name, value)
        else:
            raise AttributeError("You cannot add instance attributes to %s" % self)
    return set_instance_attr


def _swig_setattr_nondynamic_class_variable(set):
    def set_class_attr(cls, name, value):
        if hasattr(cls, name) and not isinstance(getattr(cls, name), property):
            set(cls, name, value)
        else:
            raise AttributeError("You cannot add class attributes to %s" % cls)
    return set_class_attr


def _swig_add_metaclass(metaclass):
    """Class decorator for adding a metaclass to a SWIG wrapped class - a slimmed down version of six.add_metaclass"""
    def wrapper(cls):
        return metaclass(cls.__name__, cls.__bases__, cls.__dict__.copy())
    return wrapper


class _SwigNonDynamicMeta(type):
    """Meta class to enforce nondynamic attributes (no new attributes) for a class"""
    __setattr__ = _swig_setattr_nondynamic_class_variable(type.__setattr__)


import itk.itkImageSourceCommonPython
import itk.ITKCommonBasePython
import itk.pyBasePython
import itk.itkImageToImageFilterCommonPython
import itk.itkStatisticsLabelObjectPython
import itk.itkHistogramPython
import itk.itkSamplePython
import itk.itkArrayPython
import itk.vnl_vectorPython
import itk.stdcomplexPython
import itk.vnl_matrixPython
import itk.itkFixedArrayPython
import itk.itkVectorPython
import itk.vnl_vector_refPython
import itk.itkMatrixPython
import itk.vnl_matrix_fixedPython
import itk.itkPointPython
import itk.itkCovariantVectorPython
import itk.itkShapeLabelObjectPython
import itk.itkLabelObjectPython
import itk.itkOffsetPython
import itk.itkSizePython
import itk.itkIndexPython
import itk.itkLabelObjectLinePython
import itk.itkAffineTransformPython
import itk.itkMatrixOffsetTransformBasePython
import itk.itkVariableLengthVectorPython
import itk.itkSymmetricSecondRankTensorPython
import itk.itkDiffusionTensor3DPython
import itk.itkArray2DPython
import itk.itkOptimizerParametersPython
import itk.itkTransformBasePython
import itk.itkImageRegionPython
import itk.itkImagePython
import itk.itkRGBPixelPython
import itk.itkRGBAPixelPython
import itk.itkImageSourcePython
import itk.itkVectorImagePython
class itkImageSourceLM2(itk.ITKCommonBasePython.itkProcessObject):
    r"""


    Base class for all process objects that output image data.

    ImageSource is the base class for all process objects that output
    image data. Specifically, this class defines the GetOutput() method
    that returns a pointer to the output image. The class also defines
    some internal private data members that are used to manage streaming
    of data.

    Memory management in an ImageSource is slightly different than a
    standard ProcessObject. ProcessObject's always release the bulk data
    associated with their output prior to GenerateData() being called.
    ImageSources default to not releasing the bulk data incase that
    particular memory block is large enough to hold the new output values.
    This avoids unnecessary deallocation/allocation sequences.
    ImageSource's can be forced to use a memory management model similar
    to the default ProcessObject behaviour by calling
    ProcessObject::ReleaseDataBeforeUpdateFlagOn(). A user may want to set
    this flag to limit peak memory usage during a pipeline update.

    {Core/Common/ProduceImageProgrammatically,Produce Image
    Programmatically} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    GetOutput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageSourceLM2_GetOutput)
    GraftOutput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageSourceLM2_GraftOutput)
    GraftNthOutput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageSourceLM2_GraftNthOutput)
    MakeOutput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageSourceLM2_MakeOutput)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageSourceLM2
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageSourceLM2_cast)

# Register itkImageSourceLM2 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageSourceLM2_swigregister(itkImageSourceLM2)
itkImageSourceLM2_cast = _ITKLabelMapBasePython.itkImageSourceLM2_cast

class itkImageSourceLM3(itk.ITKCommonBasePython.itkProcessObject):
    r"""


    Base class for all process objects that output image data.

    ImageSource is the base class for all process objects that output
    image data. Specifically, this class defines the GetOutput() method
    that returns a pointer to the output image. The class also defines
    some internal private data members that are used to manage streaming
    of data.

    Memory management in an ImageSource is slightly different than a
    standard ProcessObject. ProcessObject's always release the bulk data
    associated with their output prior to GenerateData() being called.
    ImageSources default to not releasing the bulk data incase that
    particular memory block is large enough to hold the new output values.
    This avoids unnecessary deallocation/allocation sequences.
    ImageSource's can be forced to use a memory management model similar
    to the default ProcessObject behaviour by calling
    ProcessObject::ReleaseDataBeforeUpdateFlagOn(). A user may want to set
    this flag to limit peak memory usage during a pipeline update.

    {Core/Common/ProduceImageProgrammatically,Produce Image
    Programmatically} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    GetOutput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageSourceLM3_GetOutput)
    GraftOutput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageSourceLM3_GraftOutput)
    GraftNthOutput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageSourceLM3_GraftNthOutput)
    MakeOutput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageSourceLM3_MakeOutput)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageSourceLM3
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageSourceLM3_cast)

# Register itkImageSourceLM3 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageSourceLM3_swigregister(itkImageSourceLM3)
itkImageSourceLM3_cast = _ITKLabelMapBasePython.itkImageSourceLM3_cast

class itkImageToImageFilterID2LM2(itkImageSourceLM2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterID2LM2_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterID2LM2_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterID2LM2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterID2LM2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterID2LM2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterID2LM2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterID2LM2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterID2LM2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterID2LM2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterID2LM2_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterID2LM2
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterID2LM2_cast)

# Register itkImageToImageFilterID2LM2 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterID2LM2_swigregister(itkImageToImageFilterID2LM2)
itkImageToImageFilterID2LM2_cast = _ITKLabelMapBasePython.itkImageToImageFilterID2LM2_cast

class itkImageToImageFilterID3LM3(itkImageSourceLM3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterID3LM3_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterID3LM3_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterID3LM3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterID3LM3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterID3LM3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterID3LM3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterID3LM3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterID3LM3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterID3LM3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterID3LM3_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterID3LM3
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterID3LM3_cast)

# Register itkImageToImageFilterID3LM3 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterID3LM3_swigregister(itkImageToImageFilterID3LM3)
itkImageToImageFilterID3LM3_cast = _ITKLabelMapBasePython.itkImageToImageFilterID3LM3_cast

class itkImageToImageFilterIF2LM2(itkImageSourceLM2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIF2LM2_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIF2LM2_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIF2LM2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIF2LM2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIF2LM2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIF2LM2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIF2LM2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIF2LM2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIF2LM2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIF2LM2_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterIF2LM2
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterIF2LM2_cast)

# Register itkImageToImageFilterIF2LM2 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterIF2LM2_swigregister(itkImageToImageFilterIF2LM2)
itkImageToImageFilterIF2LM2_cast = _ITKLabelMapBasePython.itkImageToImageFilterIF2LM2_cast

class itkImageToImageFilterIF3LM3(itkImageSourceLM3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIF3LM3_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIF3LM3_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIF3LM3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIF3LM3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIF3LM3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIF3LM3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIF3LM3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIF3LM3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIF3LM3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIF3LM3_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterIF3LM3
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterIF3LM3_cast)

# Register itkImageToImageFilterIF3LM3 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterIF3LM3_swigregister(itkImageToImageFilterIF3LM3)
itkImageToImageFilterIF3LM3_cast = _ITKLabelMapBasePython.itkImageToImageFilterIF3LM3_cast

class itkImageToImageFilterISS2LM2(itkImageSourceLM2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterISS2LM2_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterISS2LM2_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterISS2LM2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterISS2LM2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterISS2LM2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterISS2LM2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterISS2LM2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterISS2LM2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterISS2LM2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterISS2LM2_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterISS2LM2
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterISS2LM2_cast)

# Register itkImageToImageFilterISS2LM2 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterISS2LM2_swigregister(itkImageToImageFilterISS2LM2)
itkImageToImageFilterISS2LM2_cast = _ITKLabelMapBasePython.itkImageToImageFilterISS2LM2_cast

class itkImageToImageFilterISS3LM3(itkImageSourceLM3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterISS3LM3_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterISS3LM3_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterISS3LM3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterISS3LM3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterISS3LM3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterISS3LM3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterISS3LM3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterISS3LM3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterISS3LM3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterISS3LM3_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterISS3LM3
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterISS3LM3_cast)

# Register itkImageToImageFilterISS3LM3 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterISS3LM3_swigregister(itkImageToImageFilterISS3LM3)
itkImageToImageFilterISS3LM3_cast = _ITKLabelMapBasePython.itkImageToImageFilterISS3LM3_cast

class itkImageToImageFilterIUC2LM2(itkImageSourceLM2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUC2LM2_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUC2LM2_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUC2LM2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUC2LM2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUC2LM2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUC2LM2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUC2LM2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUC2LM2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUC2LM2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUC2LM2_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterIUC2LM2
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterIUC2LM2_cast)

# Register itkImageToImageFilterIUC2LM2 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterIUC2LM2_swigregister(itkImageToImageFilterIUC2LM2)
itkImageToImageFilterIUC2LM2_cast = _ITKLabelMapBasePython.itkImageToImageFilterIUC2LM2_cast

class itkImageToImageFilterIUC3LM3(itkImageSourceLM3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUC3LM3_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUC3LM3_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUC3LM3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUC3LM3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUC3LM3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUC3LM3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUC3LM3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUC3LM3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUC3LM3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUC3LM3_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterIUC3LM3
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterIUC3LM3_cast)

# Register itkImageToImageFilterIUC3LM3 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterIUC3LM3_swigregister(itkImageToImageFilterIUC3LM3)
itkImageToImageFilterIUC3LM3_cast = _ITKLabelMapBasePython.itkImageToImageFilterIUC3LM3_cast

class itkImageToImageFilterIUS2LM2(itkImageSourceLM2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUS2LM2_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUS2LM2_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUS2LM2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUS2LM2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUS2LM2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUS2LM2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUS2LM2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUS2LM2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUS2LM2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUS2LM2_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterIUS2LM2
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterIUS2LM2_cast)

# Register itkImageToImageFilterIUS2LM2 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterIUS2LM2_swigregister(itkImageToImageFilterIUS2LM2)
itkImageToImageFilterIUS2LM2_cast = _ITKLabelMapBasePython.itkImageToImageFilterIUS2LM2_cast

class itkImageToImageFilterIUS3LM3(itkImageSourceLM3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUS3LM3_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUS3LM3_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUS3LM3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUS3LM3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUS3LM3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUS3LM3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUS3LM3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUS3LM3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUS3LM3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterIUS3LM3_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterIUS3LM3
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterIUS3LM3_cast)

# Register itkImageToImageFilterIUS3LM3 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterIUS3LM3_swigregister(itkImageToImageFilterIUS3LM3)
itkImageToImageFilterIUS3LM3_cast = _ITKLabelMapBasePython.itkImageToImageFilterIUS3LM3_cast

class itkImageToImageFilterLM2ID2(itk.itkImageSourcePython.itkImageSourceID2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2ID2_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2ID2_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2ID2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2ID2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2ID2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2ID2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2ID2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2ID2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2ID2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2ID2_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterLM2ID2
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2ID2_cast)

# Register itkImageToImageFilterLM2ID2 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterLM2ID2_swigregister(itkImageToImageFilterLM2ID2)
itkImageToImageFilterLM2ID2_cast = _ITKLabelMapBasePython.itkImageToImageFilterLM2ID2_cast

class itkImageToImageFilterLM2IF2(itk.itkImageSourcePython.itkImageSourceIF2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IF2_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IF2_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IF2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IF2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IF2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IF2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IF2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IF2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IF2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IF2_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterLM2IF2
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IF2_cast)

# Register itkImageToImageFilterLM2IF2 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterLM2IF2_swigregister(itkImageToImageFilterLM2IF2)
itkImageToImageFilterLM2IF2_cast = _ITKLabelMapBasePython.itkImageToImageFilterLM2IF2_cast

class itkImageToImageFilterLM2IRGBUC2(itk.itkImageSourcePython.itkImageSourceIRGBUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IRGBUC2_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IRGBUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IRGBUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IRGBUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IRGBUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IRGBUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IRGBUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IRGBUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IRGBUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IRGBUC2_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterLM2IRGBUC2
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IRGBUC2_cast)

# Register itkImageToImageFilterLM2IRGBUC2 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterLM2IRGBUC2_swigregister(itkImageToImageFilterLM2IRGBUC2)
itkImageToImageFilterLM2IRGBUC2_cast = _ITKLabelMapBasePython.itkImageToImageFilterLM2IRGBUC2_cast

class itkImageToImageFilterLM2ISS2(itk.itkImageSourcePython.itkImageSourceISS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2ISS2_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2ISS2_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2ISS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2ISS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2ISS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2ISS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2ISS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2ISS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2ISS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2ISS2_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterLM2ISS2
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2ISS2_cast)

# Register itkImageToImageFilterLM2ISS2 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterLM2ISS2_swigregister(itkImageToImageFilterLM2ISS2)
itkImageToImageFilterLM2ISS2_cast = _ITKLabelMapBasePython.itkImageToImageFilterLM2ISS2_cast

class itkImageToImageFilterLM2IUC2(itk.itkImageSourcePython.itkImageSourceIUC2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IUC2_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IUC2_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IUC2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IUC2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IUC2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IUC2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IUC2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IUC2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IUC2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IUC2_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterLM2IUC2
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IUC2_cast)

# Register itkImageToImageFilterLM2IUC2 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterLM2IUC2_swigregister(itkImageToImageFilterLM2IUC2)
itkImageToImageFilterLM2IUC2_cast = _ITKLabelMapBasePython.itkImageToImageFilterLM2IUC2_cast

class itkImageToImageFilterLM2IUS2(itk.itkImageSourcePython.itkImageSourceIUS2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IUS2_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IUS2_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IUS2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IUS2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IUS2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IUS2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IUS2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IUS2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IUS2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IUS2_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterLM2IUS2
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2IUS2_cast)

# Register itkImageToImageFilterLM2IUS2 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterLM2IUS2_swigregister(itkImageToImageFilterLM2IUS2)
itkImageToImageFilterLM2IUS2_cast = _ITKLabelMapBasePython.itkImageToImageFilterLM2IUS2_cast

class itkImageToImageFilterLM2LM2(itkImageSourceLM2):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2LM2_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2LM2_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2LM2_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2LM2_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2LM2_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2LM2_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2LM2_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2LM2_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2LM2_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2LM2_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterLM2LM2
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterLM2LM2_cast)

# Register itkImageToImageFilterLM2LM2 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterLM2LM2_swigregister(itkImageToImageFilterLM2LM2)
itkImageToImageFilterLM2LM2_cast = _ITKLabelMapBasePython.itkImageToImageFilterLM2LM2_cast

class itkImageToImageFilterLM3ID3(itk.itkImageSourcePython.itkImageSourceID3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3ID3_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3ID3_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3ID3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3ID3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3ID3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3ID3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3ID3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3ID3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3ID3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3ID3_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterLM3ID3
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3ID3_cast)

# Register itkImageToImageFilterLM3ID3 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterLM3ID3_swigregister(itkImageToImageFilterLM3ID3)
itkImageToImageFilterLM3ID3_cast = _ITKLabelMapBasePython.itkImageToImageFilterLM3ID3_cast

class itkImageToImageFilterLM3IF3(itk.itkImageSourcePython.itkImageSourceIF3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IF3_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IF3_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IF3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IF3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IF3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IF3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IF3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IF3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IF3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IF3_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterLM3IF3
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IF3_cast)

# Register itkImageToImageFilterLM3IF3 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterLM3IF3_swigregister(itkImageToImageFilterLM3IF3)
itkImageToImageFilterLM3IF3_cast = _ITKLabelMapBasePython.itkImageToImageFilterLM3IF3_cast

class itkImageToImageFilterLM3IRGBUC3(itk.itkImageSourcePython.itkImageSourceIRGBUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IRGBUC3_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IRGBUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IRGBUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IRGBUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IRGBUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IRGBUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IRGBUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IRGBUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IRGBUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IRGBUC3_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterLM3IRGBUC3
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IRGBUC3_cast)

# Register itkImageToImageFilterLM3IRGBUC3 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterLM3IRGBUC3_swigregister(itkImageToImageFilterLM3IRGBUC3)
itkImageToImageFilterLM3IRGBUC3_cast = _ITKLabelMapBasePython.itkImageToImageFilterLM3IRGBUC3_cast

class itkImageToImageFilterLM3ISS3(itk.itkImageSourcePython.itkImageSourceISS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3ISS3_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3ISS3_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3ISS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3ISS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3ISS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3ISS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3ISS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3ISS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3ISS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3ISS3_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterLM3ISS3
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3ISS3_cast)

# Register itkImageToImageFilterLM3ISS3 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterLM3ISS3_swigregister(itkImageToImageFilterLM3ISS3)
itkImageToImageFilterLM3ISS3_cast = _ITKLabelMapBasePython.itkImageToImageFilterLM3ISS3_cast

class itkImageToImageFilterLM3IUC3(itk.itkImageSourcePython.itkImageSourceIUC3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IUC3_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IUC3_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IUC3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IUC3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IUC3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IUC3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IUC3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IUC3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IUC3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IUC3_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterLM3IUC3
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IUC3_cast)

# Register itkImageToImageFilterLM3IUC3 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterLM3IUC3_swigregister(itkImageToImageFilterLM3IUC3)
itkImageToImageFilterLM3IUC3_cast = _ITKLabelMapBasePython.itkImageToImageFilterLM3IUC3_cast

class itkImageToImageFilterLM3IUS3(itk.itkImageSourcePython.itkImageSourceIUS3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IUS3_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IUS3_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IUS3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IUS3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IUS3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IUS3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IUS3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IUS3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IUS3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IUS3_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterLM3IUS3
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3IUS3_cast)

# Register itkImageToImageFilterLM3IUS3 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterLM3IUS3_swigregister(itkImageToImageFilterLM3IUS3)
itkImageToImageFilterLM3IUS3_cast = _ITKLabelMapBasePython.itkImageToImageFilterLM3IUS3_cast

class itkImageToImageFilterLM3LM3(itkImageSourceLM3):
    r"""


    Base class for filters that take an image as input and produce an
    image as output.

    ImageToImageFilter is the base class for all process objects that
    output image data and require image data as input. Specifically, this
    class defines the SetInput() method for defining the input to a
    filter.

    This class provides the infrastructure for supporting multithreaded
    processing of images. If a filter provides an implementation of
    GenerateData(), the image processing will run in a single thread and
    the implementation is responsible for allocating its output data. If a
    filter provides an implementation of ThreadedGenerateData() instead,
    the image will be divided into a number of work units, a number of
    threads will be spawned, and ThreadedGenerateData() will be called in
    each thread. Here, the output memory will be allocated by this
    superclass prior to calling ThreadedGenerateData().

    ImageToImageFilter provides an implementation of
    GenerateInputRequestedRegion(). The base assumption to this point in
    the hierarchy is that a process object would ask for the largest
    possible region on input in order to produce any output. Imaging
    filters, however, can usually answer this question more precisely. The
    default implementation of GenerateInputRequestedRegion() in this class
    is to request an input that matches the size of the requested output.
    If a filter requires more input (say a filter that uses neighborhood
    information) or less input (for instance a magnify filter), then these
    filters will have to provide another implementation of this method. By
    convention, such implementations should call the Superclass' method
    first.

    All inputs to ImageToImageFilter (if there is more than one) are
    checked in the VerifyInputInformation method to verify that they
    occupy the same physical space. If the input images are in the same
    physical space, then the location of each voxel is identical, and the
    filter can operate voxel-by-voxel in index space. Some filters
    registration filters, for example will violate this precondition, in
    which case they should redefine VerifyInputInformation to relax or
    eliminate this requirement.

    Access methods Set/GetCoordinateTolerance and
    Set/GetDirectionTolerance are provided for cases where the default
    spatial-congruency tolerances are too fine, and images that are almost
    in the same space should be regard as being in the same space. This
    has come up, for example when comparing different on-disk image
    formats with differing digits of precision in the position, spacing,
    and orientation.

    The default tolerance is govern by the
    GlobalDefaultCoordinateTolerance and the
    GlobalDefaultDirectionTolerance properties, defaulting to 1.0e-6. The
    default tolerance for spatial comparison is then scaled by the
    voxelSpacing for coordinates (i.e. the coordinates must be the same to
    within one part per million). For the direction cosines the values
    must be within the current absolute tolerance.

    {Core/Common/FilterImage,Filter Image}
    {Core/Common/MultipleInputsOfSameType,Multiple Inputs Of Same Type}
    {Core/Common/MultipleInputsOfDifferentType,Multiple Inputs Of
    Different Type} {Core/Common/MultipleOutputsOfSameType,Multiple
    Outputs Of Same Type} {Core/Common/MultThreadOilPainting,Mult-thread
    Oil Painting} {Core/Common/MultipleOutputsOfDifferentType,Multiple
    Outputs Of Different Type}
    {Core/Common/FilterImageUsingMultipleThreads,Filter Image Using
    Multiple Threads} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    SetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3LM3_SetInput)
    GetInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3LM3_GetInput)
    PushBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3LM3_PushBackInput)
    PopBackInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3LM3_PopBackInput)
    PushFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3LM3_PushFrontInput)
    PopFrontInput = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3LM3_PopFrontInput)
    SetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3LM3_SetCoordinateTolerance)
    GetCoordinateTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3LM3_GetCoordinateTolerance)
    SetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3LM3_SetDirectionTolerance)
    GetDirectionTolerance = _swig_new_instance_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3LM3_GetDirectionTolerance)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkImageToImageFilterLM3LM3
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkImageToImageFilterLM3LM3_cast)

# Register itkImageToImageFilterLM3LM3 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkImageToImageFilterLM3LM3_swigregister(itkImageToImageFilterLM3LM3)
itkImageToImageFilterLM3LM3_cast = _ITKLabelMapBasePython.itkImageToImageFilterLM3LM3_cast


def itkLabelMap2_New():
    return itkLabelMap2.New()

class itkLabelMap2(itk.itkImagePython.itkImageBase2):
    r"""


    Templated n-dimensional image to store labeled objects.

    LabelMap is an image class specialized in storing the labeled images.
    It represent the image in a different way than itk::Image. Instead of
    storing the content of the image in an array of pixels values, it
    store the a collection of labeled objects, and a background value.
    This way of storing the content of the image allow an easy and
    efficient manipulation of the objects in the image.

    The LabelMap shares a lot of methods with the itk::Image class. it
    make it usable as input or output of the itk::ImageToImageFilter for
    example. However the methods don't have the same complexity in the 2
    classes, because of the different way to store the data. GetPixel() is
    run in constant time for example in itk::Image, but have a worst case
    complexity of O(L), where L is the number of lines in the image
    (imageSize[1] * imageSize[2] for a 3D image).

    To iterate over the LabelObjects in the map, use:

    Gaetan Lehmann. Biologie du Developpement et de la Reproduction, INRA
    de Jouy-en-Josas, France.  This implementation was taken from the
    Insight Journal paper:https://hdl.handle.net/1926/584
    orhttp://www.insight-journal.org/browse/publication/176

    {Filtering/LabelMap/RemoveLabelsFromLabelMa,Remove Labels From Label
    Map} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKLabelMapBasePython.itkLabelMap2___New_orig__)
    Clone = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_Clone)
    Allocate = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_Allocate)
    Graft = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_Graft)
    HasLabel = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_HasLabel)
    GetNthLabelObject = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_GetNthLabelObject)
    GetPixel = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_GetPixel)
    SetPixel = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_SetPixel)
    AddPixel = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_AddPixel)
    RemovePixel = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_RemovePixel)
    SetLine = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_SetLine)
    GetLabelObject = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_GetLabelObject)
    AddLabelObject = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_AddLabelObject)
    PushLabelObject = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_PushLabelObject)
    RemoveLabelObject = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_RemoveLabelObject)
    RemoveLabel = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_RemoveLabel)
    ClearLabels = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_ClearLabels)
    GetNumberOfLabelObjects = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_GetNumberOfLabelObjects)
    GetLabels = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_GetLabels)
    GetLabelObjects = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_GetLabelObjects)
    GetBackgroundValue = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_GetBackgroundValue)
    SetBackgroundValue = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_SetBackgroundValue)
    PrintLabelObjects = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_PrintLabelObjects)
    Optimize = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap2_Optimize)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkLabelMap2
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkLabelMap2_cast)

    def __len__(self):
        return self.GetNumberOfLabelObjects()
    def __getitem__(self, label):
        return self.GetLabelObject(label)
    def __iter__(self):
        labels = self.GetLabels()
        for label in labels:
            yield self.GetLabelObject(label)


    def __len__(self):
        return self.GetNumberOfLabelObjects()
    def __getitem__(self, label):
        return self.GetLabelObject(label)
    def __iter__(self):
        labels = self.GetLabels()
        for label in labels:
            yield self.GetLabelObject(label)


    def New(*args, **kargs):
        """New() -> itkLabelMap2

        Create a new object of the class itkLabelMap2 and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkLabelMap2.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkLabelMap2.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkLabelMap2.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkLabelMap2 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkLabelMap2_swigregister(itkLabelMap2)
itkLabelMap2___New_orig__ = _ITKLabelMapBasePython.itkLabelMap2___New_orig__
itkLabelMap2_cast = _ITKLabelMapBasePython.itkLabelMap2_cast


def itkLabelMap3_New():
    return itkLabelMap3.New()

class itkLabelMap3(itk.itkImagePython.itkImageBase3):
    r"""


    Templated n-dimensional image to store labeled objects.

    LabelMap is an image class specialized in storing the labeled images.
    It represent the image in a different way than itk::Image. Instead of
    storing the content of the image in an array of pixels values, it
    store the a collection of labeled objects, and a background value.
    This way of storing the content of the image allow an easy and
    efficient manipulation of the objects in the image.

    The LabelMap shares a lot of methods with the itk::Image class. it
    make it usable as input or output of the itk::ImageToImageFilter for
    example. However the methods don't have the same complexity in the 2
    classes, because of the different way to store the data. GetPixel() is
    run in constant time for example in itk::Image, but have a worst case
    complexity of O(L), where L is the number of lines in the image
    (imageSize[1] * imageSize[2] for a 3D image).

    To iterate over the LabelObjects in the map, use:

    Gaetan Lehmann. Biologie du Developpement et de la Reproduction, INRA
    de Jouy-en-Josas, France.  This implementation was taken from the
    Insight Journal paper:https://hdl.handle.net/1926/584
    orhttp://www.insight-journal.org/browse/publication/176

    {Filtering/LabelMap/RemoveLabelsFromLabelMa,Remove Labels From Label
    Map} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKLabelMapBasePython.itkLabelMap3___New_orig__)
    Clone = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_Clone)
    Allocate = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_Allocate)
    Graft = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_Graft)
    HasLabel = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_HasLabel)
    GetNthLabelObject = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_GetNthLabelObject)
    GetPixel = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_GetPixel)
    SetPixel = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_SetPixel)
    AddPixel = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_AddPixel)
    RemovePixel = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_RemovePixel)
    SetLine = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_SetLine)
    GetLabelObject = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_GetLabelObject)
    AddLabelObject = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_AddLabelObject)
    PushLabelObject = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_PushLabelObject)
    RemoveLabelObject = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_RemoveLabelObject)
    RemoveLabel = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_RemoveLabel)
    ClearLabels = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_ClearLabels)
    GetNumberOfLabelObjects = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_GetNumberOfLabelObjects)
    GetLabels = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_GetLabels)
    GetLabelObjects = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_GetLabelObjects)
    GetBackgroundValue = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_GetBackgroundValue)
    SetBackgroundValue = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_SetBackgroundValue)
    PrintLabelObjects = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_PrintLabelObjects)
    Optimize = _swig_new_instance_method(_ITKLabelMapBasePython.itkLabelMap3_Optimize)
    __swig_destroy__ = _ITKLabelMapBasePython.delete_itkLabelMap3
    cast = _swig_new_static_method(_ITKLabelMapBasePython.itkLabelMap3_cast)

    def __len__(self):
        return self.GetNumberOfLabelObjects()
    def __getitem__(self, label):
        return self.GetLabelObject(label)
    def __iter__(self):
        labels = self.GetLabels()
        for label in labels:
            yield self.GetLabelObject(label)


    def New(*args, **kargs):
        """New() -> itkLabelMap3

        Create a new object of the class itkLabelMap3 and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkLabelMap3.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkLabelMap3.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkLabelMap3.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkLabelMap3 in _ITKLabelMapBasePython:
_ITKLabelMapBasePython.itkLabelMap3_swigregister(itkLabelMap3)
itkLabelMap3___New_orig__ = _ITKLabelMapBasePython.itkLabelMap3___New_orig__
itkLabelMap3_cast = _ITKLabelMapBasePython.itkLabelMap3_cast


import itkHelpers
@itkHelpers.accept_numpy_array_like_xarray
def image_source(*args, **kwargs):
    """Procedural interface for ImageSource"""
    import itk
    instance = itk.ImageSource.New(*args, **kwargs)
    return instance.__internal_call__()

def image_source_init_docstring():
    import itk
    import itkTemplate
    import itkHelpers
    if isinstance(itk.ImageSource, itkTemplate.itkTemplate):
        filter_object = itk.ImageSource.values()[0]
    else:
        filter_object = itk.ImageSource

    image_source.__doc__ = filter_object.__doc__
    image_source.__doc__ += "\n Args are Input(s) to the filter.\n"
    image_source.__doc__ += "\n Available Keyword Arguments:\n"
    if isinstance(itk.ImageSource, itkTemplate.itkTemplate):
        image_source.__doc__ += itkHelpers.filter_args(filter_object)[0]
        image_source.__doc__ += "\n"
        image_source.__doc__ += itkHelpers.filter_args(filter_object)[1]
    else:
        image_source.__doc__ += "".join([
            "  " + itkHelpers.camel_to_snake_case(item[3:]) + "\n"
            for item in dir(filter_object)
            if item.startswith("Set")])
import itkHelpers
@itkHelpers.accept_numpy_array_like_xarray
def image_to_image_filter(*args, **kwargs):
    """Procedural interface for ImageToImageFilter"""
    import itk
    instance = itk.ImageToImageFilter.New(*args, **kwargs)
    return instance.__internal_call__()

def image_to_image_filter_init_docstring():
    import itk
    import itkTemplate
    import itkHelpers
    if isinstance(itk.ImageToImageFilter, itkTemplate.itkTemplate):
        filter_object = itk.ImageToImageFilter.values()[0]
    else:
        filter_object = itk.ImageToImageFilter

    image_to_image_filter.__doc__ = filter_object.__doc__
    image_to_image_filter.__doc__ += "\n Args are Input(s) to the filter.\n"
    image_to_image_filter.__doc__ += "\n Available Keyword Arguments:\n"
    if isinstance(itk.ImageToImageFilter, itkTemplate.itkTemplate):
        image_to_image_filter.__doc__ += itkHelpers.filter_args(filter_object)[0]
        image_to_image_filter.__doc__ += "\n"
        image_to_image_filter.__doc__ += itkHelpers.filter_args(filter_object)[1]
    else:
        image_to_image_filter.__doc__ += "".join([
            "  " + itkHelpers.camel_to_snake_case(item[3:]) + "\n"
            for item in dir(filter_object)
            if item.startswith("Set")])



