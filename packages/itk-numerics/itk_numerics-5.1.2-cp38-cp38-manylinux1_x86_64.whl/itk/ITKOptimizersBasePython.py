# This file was automatically generated by SWIG (http://www.swig.org).
# Version 4.0.1
#
# Do not make changes to this file unless you know what you are doing--modify
# the SWIG interface file instead.


from . import _ITKOptimizersPython



from sys import version_info as _swig_python_version_info
if _swig_python_version_info < (2, 7, 0):
    raise RuntimeError("Python 2.7 or later required")

# Import the low-level C/C++ module
if __package__ or "." in __name__:
    from . import _ITKOptimizersBasePython
else:
    import _ITKOptimizersBasePython

try:
    import builtins as __builtin__
except ImportError:
    import __builtin__

_swig_new_instance_method = _ITKOptimizersBasePython.SWIG_PyInstanceMethod_New
_swig_new_static_method = _ITKOptimizersBasePython.SWIG_PyStaticMethod_New

def _swig_repr(self):
    try:
        strthis = "proxy of " + self.this.__repr__()
    except __builtin__.Exception:
        strthis = ""
    return "<%s.%s; %s >" % (self.__class__.__module__, self.__class__.__name__, strthis,)


def _swig_setattr_nondynamic_instance_variable(set):
    def set_instance_attr(self, name, value):
        if name == "thisown":
            self.this.own(value)
        elif name == "this":
            set(self, name, value)
        elif hasattr(self, name) and isinstance(getattr(type(self), name), property):
            set(self, name, value)
        else:
            raise AttributeError("You cannot add instance attributes to %s" % self)
    return set_instance_attr


def _swig_setattr_nondynamic_class_variable(set):
    def set_class_attr(cls, name, value):
        if hasattr(cls, name) and not isinstance(getattr(cls, name), property):
            set(cls, name, value)
        else:
            raise AttributeError("You cannot add class attributes to %s" % cls)
    return set_class_attr


def _swig_add_metaclass(metaclass):
    """Class decorator for adding a metaclass to a SWIG wrapped class - a slimmed down version of six.add_metaclass"""
    def wrapper(cls):
        return metaclass(cls.__name__, cls.__bases__, cls.__dict__.copy())
    return wrapper


class _SwigNonDynamicMeta(type):
    """Meta class to enforce nondynamic attributes (no new attributes) for a class"""
    __setattr__ = _swig_setattr_nondynamic_class_variable(type.__setattr__)


import itk.itkArrayPython
import itk.vnl_vectorPython
import itk.vnl_matrixPython
import itk.stdcomplexPython
import itk.pyBasePython
import itk.itkOptimizerParametersPython
import itk.ITKCommonBasePython
import itk.ITKCostFunctionsPython
import itk.vnl_least_squares_functionPython
import itk.itkArray2DPython
import itk.itkCostFunctionPython
import itk.vnl_cost_functionPython
import itk.vnl_unary_functionPython
class itkFRPROptimizerEnums(object):
    r"""Proxy of C++ itkFRPROptimizerEnums class."""

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr
    Optimization_FletchReeves = _ITKOptimizersBasePython.itkFRPROptimizerEnums_Optimization_FletchReeves
    
    Optimization_PolakRibiere = _ITKOptimizersBasePython.itkFRPROptimizerEnums_Optimization_PolakRibiere
    

    def __init__(self, *args):
        r"""
        __init__(itkFRPROptimizerEnums self) -> itkFRPROptimizerEnums
        __init__(itkFRPROptimizerEnums self, itkFRPROptimizerEnums arg0) -> itkFRPROptimizerEnums
        """
        _ITKOptimizersBasePython.itkFRPROptimizerEnums_swiginit(self, _ITKOptimizersBasePython.new_itkFRPROptimizerEnums(*args))
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkFRPROptimizerEnums

# Register itkFRPROptimizerEnums in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkFRPROptimizerEnums_swigregister(itkFRPROptimizerEnums)

class itkGradientDescentOptimizerEnums(object):
    r"""Proxy of C++ itkGradientDescentOptimizerEnums class."""

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr
    StopConditionGradientDescentOptimizer_MaximumNumberOfIterations = _ITKOptimizersBasePython.itkGradientDescentOptimizerEnums_StopConditionGradientDescentOptimizer_MaximumNumberOfIterations
    
    StopConditionGradientDescentOptimizer_MetricError = _ITKOptimizersBasePython.itkGradientDescentOptimizerEnums_StopConditionGradientDescentOptimizer_MetricError
    

    def __init__(self, *args):
        r"""
        __init__(itkGradientDescentOptimizerEnums self) -> itkGradientDescentOptimizerEnums
        __init__(itkGradientDescentOptimizerEnums self, itkGradientDescentOptimizerEnums arg0) -> itkGradientDescentOptimizerEnums
        """
        _ITKOptimizersBasePython.itkGradientDescentOptimizerEnums_swiginit(self, _ITKOptimizersBasePython.new_itkGradientDescentOptimizerEnums(*args))
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkGradientDescentOptimizerEnums

# Register itkGradientDescentOptimizerEnums in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkGradientDescentOptimizerEnums_swigregister(itkGradientDescentOptimizerEnums)


def itkOptimizer_New():
    return itkOptimizer.New()

class itkOptimizer(itk.ITKCommonBasePython.itkObject):
    r"""


    Generic representation for an optimization method.

    This class is a base for a hierarchy of optimizers. It is not intended
    to be instantiated. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkOptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkOptimizer_Clone)
    SetInitialPosition = _swig_new_instance_method(_ITKOptimizersBasePython.itkOptimizer_SetInitialPosition)
    GetInitialPosition = _swig_new_instance_method(_ITKOptimizersBasePython.itkOptimizer_GetInitialPosition)
    SetScales = _swig_new_instance_method(_ITKOptimizersBasePython.itkOptimizer_SetScales)
    GetScales = _swig_new_instance_method(_ITKOptimizersBasePython.itkOptimizer_GetScales)
    GetInverseScales = _swig_new_instance_method(_ITKOptimizersBasePython.itkOptimizer_GetInverseScales)
    GetCurrentPosition = _swig_new_instance_method(_ITKOptimizersBasePython.itkOptimizer_GetCurrentPosition)
    StartOptimization = _swig_new_instance_method(_ITKOptimizersBasePython.itkOptimizer_StartOptimization)
    GetStopConditionDescription = _swig_new_instance_method(_ITKOptimizersBasePython.itkOptimizer_GetStopConditionDescription)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkOptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkOptimizer

        Create a new object of the class itkOptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkOptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkOptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkOptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkOptimizer_swigregister(itkOptimizer)
itkOptimizer___New_orig__ = _ITKOptimizersBasePython.itkOptimizer___New_orig__
itkOptimizer_cast = _ITKOptimizersBasePython.itkOptimizer_cast

class itkRegularStepGradientDescentBaseOptimizerEnums(object):
    r"""Proxy of C++ itkRegularStepGradientDescentBaseOptimizerEnums class."""

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr
    StopCondition_GradientMagnitudeTolerance = _ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizerEnums_StopCondition_GradientMagnitudeTolerance
    
    StopCondition_StepTooSmall = _ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizerEnums_StopCondition_StepTooSmall
    
    StopCondition_ImageNotAvailable = _ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizerEnums_StopCondition_ImageNotAvailable
    
    StopCondition_CostFunctionError = _ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizerEnums_StopCondition_CostFunctionError
    
    StopCondition_MaximumNumberOfIterations = _ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizerEnums_StopCondition_MaximumNumberOfIterations
    
    StopCondition_Unknown = _ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizerEnums_StopCondition_Unknown
    

    def __init__(self, *args):
        r"""
        __init__(itkRegularStepGradientDescentBaseOptimizerEnums self) -> itkRegularStepGradientDescentBaseOptimizerEnums
        __init__(itkRegularStepGradientDescentBaseOptimizerEnums self, itkRegularStepGradientDescentBaseOptimizerEnums arg0) -> itkRegularStepGradientDescentBaseOptimizerEnums
        """
        _ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizerEnums_swiginit(self, _ITKOptimizersBasePython.new_itkRegularStepGradientDescentBaseOptimizerEnums(*args))
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkRegularStepGradientDescentBaseOptimizerEnums

# Register itkRegularStepGradientDescentBaseOptimizerEnums in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizerEnums_swigregister(itkRegularStepGradientDescentBaseOptimizerEnums)

class itkSPSAOptimizerEnums(object):
    r"""Proxy of C++ itkSPSAOptimizerEnums class."""

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr
    StopConditionSPSAOptimizer_Unknown = _ITKOptimizersBasePython.itkSPSAOptimizerEnums_StopConditionSPSAOptimizer_Unknown
    
    StopConditionSPSAOptimizer_MaximumNumberOfIterations = _ITKOptimizersBasePython.itkSPSAOptimizerEnums_StopConditionSPSAOptimizer_MaximumNumberOfIterations
    
    StopConditionSPSAOptimizer_BelowTolerance = _ITKOptimizersBasePython.itkSPSAOptimizerEnums_StopConditionSPSAOptimizer_BelowTolerance
    
    StopConditionSPSAOptimizer_MetricError = _ITKOptimizersBasePython.itkSPSAOptimizerEnums_StopConditionSPSAOptimizer_MetricError
    

    def __init__(self, *args):
        r"""
        __init__(itkSPSAOptimizerEnums self) -> itkSPSAOptimizerEnums
        __init__(itkSPSAOptimizerEnums self, itkSPSAOptimizerEnums arg0) -> itkSPSAOptimizerEnums
        """
        _ITKOptimizersBasePython.itkSPSAOptimizerEnums_swiginit(self, _ITKOptimizersBasePython.new_itkSPSAOptimizerEnums(*args))
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkSPSAOptimizerEnums

# Register itkSPSAOptimizerEnums in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkSPSAOptimizerEnums_swigregister(itkSPSAOptimizerEnums)


def itkNonLinearOptimizer_New():
    return itkNonLinearOptimizer.New()

class itkNonLinearOptimizer(itkOptimizer):
    r"""


    Wrap of the vnl_nonlinear_minimizer to be adapted.

    This class is provided to support the structure of an Optimizers
    Hierarchy. It is not intended to be instantiated. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkNonLinearOptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkNonLinearOptimizer_Clone)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkNonLinearOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkNonLinearOptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkNonLinearOptimizer

        Create a new object of the class itkNonLinearOptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkNonLinearOptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkNonLinearOptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkNonLinearOptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkNonLinearOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkNonLinearOptimizer_swigregister(itkNonLinearOptimizer)
itkNonLinearOptimizer___New_orig__ = _ITKOptimizersBasePython.itkNonLinearOptimizer___New_orig__
itkNonLinearOptimizer_cast = _ITKOptimizersBasePython.itkNonLinearOptimizer_cast


def itkSingleValuedNonLinearOptimizer_New():
    return itkSingleValuedNonLinearOptimizer.New()

class itkSingleValuedNonLinearOptimizer(itkNonLinearOptimizer):
    r"""


    This class is a base for the Optimization methods that optimize a
    single valued function. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkSingleValuedNonLinearOptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkSingleValuedNonLinearOptimizer_Clone)
    SetCostFunction = _swig_new_instance_method(_ITKOptimizersBasePython.itkSingleValuedNonLinearOptimizer_SetCostFunction)
    GetModifiableCostFunction = _swig_new_instance_method(_ITKOptimizersBasePython.itkSingleValuedNonLinearOptimizer_GetModifiableCostFunction)
    GetCostFunction = _swig_new_instance_method(_ITKOptimizersBasePython.itkSingleValuedNonLinearOptimizer_GetCostFunction)
    GetValue = _swig_new_instance_method(_ITKOptimizersBasePython.itkSingleValuedNonLinearOptimizer_GetValue)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkSingleValuedNonLinearOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkSingleValuedNonLinearOptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkSingleValuedNonLinearOptimizer

        Create a new object of the class itkSingleValuedNonLinearOptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkSingleValuedNonLinearOptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkSingleValuedNonLinearOptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkSingleValuedNonLinearOptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkSingleValuedNonLinearOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkSingleValuedNonLinearOptimizer_swigregister(itkSingleValuedNonLinearOptimizer)
itkSingleValuedNonLinearOptimizer___New_orig__ = _ITKOptimizersBasePython.itkSingleValuedNonLinearOptimizer___New_orig__
itkSingleValuedNonLinearOptimizer_cast = _ITKOptimizersBasePython.itkSingleValuedNonLinearOptimizer_cast

class itkSingleValuedNonLinearVnlOptimizer(itkSingleValuedNonLinearOptimizer):
    r"""


    This class is a base for the Optimization methods that optimize a
    single valued function.

    It is an Adaptor class for optimizers provided by the vnl library 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    GetMaximize = _swig_new_instance_method(_ITKOptimizersBasePython.itkSingleValuedNonLinearVnlOptimizer_GetMaximize)
    SetMaximize = _swig_new_instance_method(_ITKOptimizersBasePython.itkSingleValuedNonLinearVnlOptimizer_SetMaximize)
    MaximizeOn = _swig_new_instance_method(_ITKOptimizersBasePython.itkSingleValuedNonLinearVnlOptimizer_MaximizeOn)
    MaximizeOff = _swig_new_instance_method(_ITKOptimizersBasePython.itkSingleValuedNonLinearVnlOptimizer_MaximizeOff)
    GetMinimize = _swig_new_instance_method(_ITKOptimizersBasePython.itkSingleValuedNonLinearVnlOptimizer_GetMinimize)
    SetMinimize = _swig_new_instance_method(_ITKOptimizersBasePython.itkSingleValuedNonLinearVnlOptimizer_SetMinimize)
    MinimizeOn = _swig_new_instance_method(_ITKOptimizersBasePython.itkSingleValuedNonLinearVnlOptimizer_MinimizeOn)
    MinimizeOff = _swig_new_instance_method(_ITKOptimizersBasePython.itkSingleValuedNonLinearVnlOptimizer_MinimizeOff)
    GetCachedValue = _swig_new_instance_method(_ITKOptimizersBasePython.itkSingleValuedNonLinearVnlOptimizer_GetCachedValue)
    GetCachedDerivative = _swig_new_instance_method(_ITKOptimizersBasePython.itkSingleValuedNonLinearVnlOptimizer_GetCachedDerivative)
    GetCachedCurrentPosition = _swig_new_instance_method(_ITKOptimizersBasePython.itkSingleValuedNonLinearVnlOptimizer_GetCachedCurrentPosition)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkSingleValuedNonLinearVnlOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkSingleValuedNonLinearVnlOptimizer_cast)

# Register itkSingleValuedNonLinearVnlOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkSingleValuedNonLinearVnlOptimizer_swigregister(itkSingleValuedNonLinearVnlOptimizer)
itkSingleValuedNonLinearVnlOptimizer_cast = _ITKOptimizersBasePython.itkSingleValuedNonLinearVnlOptimizer_cast


def itkAmoebaOptimizer_New():
    return itkAmoebaOptimizer.New()

class itkAmoebaOptimizer(itkSingleValuedNonLinearVnlOptimizer):
    r"""


    Wrap of the vnl_amoeba algorithm.

    AmoebaOptimizer is a wrapper around the vnl_amoeba algorithm which is
    an implementation of the Nelder-Meade downhill simplex problem. For
    most problems, it is a few times slower than a Levenberg-Marquardt
    algorithm but does not require derivatives of its cost function. It
    works by creating a simplex (n+1 points in ND space). The cost
    function is evaluated at each corner of the simplex. The simplex is
    then modified (by reflecting a corner about the opposite edge, by
    shrinking the entire simplex, by contracting one edge of the simplex,
    or by expanding the simplex) in searching for the minimum of the cost
    function.

    The methods AutomaticInitialSimplex() and SetInitialSimplexDelta()
    control whether the optimizer defines the initial simplex
    automatically (by constructing a very small simplex around the initial
    position) or uses a user supplied simplex size.

    The method SetOptimizeWithRestarts() indicates that the amoeabe
    algorithm should be rerun after if converges. This heuristic increases
    the chances of escaping from a local optimum. Each time the simplex is
    initialized with the best solution obtained by the previous runs. The
    edge length is half of that from the previous iteration. The heuristic
    is terminated if the total number of iterations is greater-equal than
    the maximal number of iterations (SetMaximumNumberOfIterations) or the
    difference between the current function value and the best function
    value is less than a threshold (SetFunctionConvergenceTolerance) and
    max(|best_parameters_i - current_parameters_i|) is less than a
    threshold (SetParametersConvergenceTolerance). 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkAmoebaOptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkAmoebaOptimizer_Clone)
    SetMaximumNumberOfIterations = _swig_new_instance_method(_ITKOptimizersBasePython.itkAmoebaOptimizer_SetMaximumNumberOfIterations)
    GetMaximumNumberOfIterations = _swig_new_instance_method(_ITKOptimizersBasePython.itkAmoebaOptimizer_GetMaximumNumberOfIterations)
    SetAutomaticInitialSimplex = _swig_new_instance_method(_ITKOptimizersBasePython.itkAmoebaOptimizer_SetAutomaticInitialSimplex)
    AutomaticInitialSimplexOn = _swig_new_instance_method(_ITKOptimizersBasePython.itkAmoebaOptimizer_AutomaticInitialSimplexOn)
    AutomaticInitialSimplexOff = _swig_new_instance_method(_ITKOptimizersBasePython.itkAmoebaOptimizer_AutomaticInitialSimplexOff)
    GetAutomaticInitialSimplex = _swig_new_instance_method(_ITKOptimizersBasePython.itkAmoebaOptimizer_GetAutomaticInitialSimplex)
    SetOptimizeWithRestarts = _swig_new_instance_method(_ITKOptimizersBasePython.itkAmoebaOptimizer_SetOptimizeWithRestarts)
    OptimizeWithRestartsOn = _swig_new_instance_method(_ITKOptimizersBasePython.itkAmoebaOptimizer_OptimizeWithRestartsOn)
    OptimizeWithRestartsOff = _swig_new_instance_method(_ITKOptimizersBasePython.itkAmoebaOptimizer_OptimizeWithRestartsOff)
    GetOptimizeWithRestarts = _swig_new_instance_method(_ITKOptimizersBasePython.itkAmoebaOptimizer_GetOptimizeWithRestarts)
    SetInitialSimplexDelta = _swig_new_instance_method(_ITKOptimizersBasePython.itkAmoebaOptimizer_SetInitialSimplexDelta)
    GetInitialSimplexDelta = _swig_new_instance_method(_ITKOptimizersBasePython.itkAmoebaOptimizer_GetInitialSimplexDelta)
    SetParametersConvergenceTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkAmoebaOptimizer_SetParametersConvergenceTolerance)
    GetParametersConvergenceTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkAmoebaOptimizer_GetParametersConvergenceTolerance)
    SetFunctionConvergenceTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkAmoebaOptimizer_SetFunctionConvergenceTolerance)
    GetFunctionConvergenceTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkAmoebaOptimizer_GetFunctionConvergenceTolerance)
    GetValue = _swig_new_instance_method(_ITKOptimizersBasePython.itkAmoebaOptimizer_GetValue)
    GetOptimizer = _swig_new_instance_method(_ITKOptimizersBasePython.itkAmoebaOptimizer_GetOptimizer)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkAmoebaOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkAmoebaOptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkAmoebaOptimizer

        Create a new object of the class itkAmoebaOptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkAmoebaOptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkAmoebaOptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkAmoebaOptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkAmoebaOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkAmoebaOptimizer_swigregister(itkAmoebaOptimizer)
itkAmoebaOptimizer___New_orig__ = _ITKOptimizersBasePython.itkAmoebaOptimizer___New_orig__
itkAmoebaOptimizer_cast = _ITKOptimizersBasePython.itkAmoebaOptimizer_cast


def itkConjugateGradientOptimizer_New():
    return itkConjugateGradientOptimizer.New()

class itkConjugateGradientOptimizer(itkSingleValuedNonLinearVnlOptimizer):
    r"""


    Wrap of the vnl_conjugate_gradient. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkConjugateGradientOptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkConjugateGradientOptimizer_Clone)
    GetOptimizer = _swig_new_instance_method(_ITKOptimizersBasePython.itkConjugateGradientOptimizer_GetOptimizer)
    GetNumberOfIterations = _swig_new_instance_method(_ITKOptimizersBasePython.itkConjugateGradientOptimizer_GetNumberOfIterations)
    GetCurrentIteration = _swig_new_instance_method(_ITKOptimizersBasePython.itkConjugateGradientOptimizer_GetCurrentIteration)
    GetValue = _swig_new_instance_method(_ITKOptimizersBasePython.itkConjugateGradientOptimizer_GetValue)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkConjugateGradientOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkConjugateGradientOptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkConjugateGradientOptimizer

        Create a new object of the class itkConjugateGradientOptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkConjugateGradientOptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkConjugateGradientOptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkConjugateGradientOptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkConjugateGradientOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkConjugateGradientOptimizer_swigregister(itkConjugateGradientOptimizer)
itkConjugateGradientOptimizer___New_orig__ = _ITKOptimizersBasePython.itkConjugateGradientOptimizer___New_orig__
itkConjugateGradientOptimizer_cast = _ITKOptimizersBasePython.itkConjugateGradientOptimizer_cast


def itkExhaustiveOptimizer_New():
    return itkExhaustiveOptimizer.New()

class itkExhaustiveOptimizer(itkSingleValuedNonLinearOptimizer):
    r"""


    Optimizer that fully samples a grid on the parametric space.

    This optimizer is equivalent to an exhaustive search in a discrete
    grid defined over the parametric space. The grid is centered on the
    initial position. The subdivisions of the grid along each one of the
    dimensions of the parametric space is defined by an array of number of
    steps.

    A typical use is to plot the metric space to get an idea of how noisy
    it space with respect to translations along x, y and z in a 3D
    registration application: Here it is assumed that the transform is
    Euler3DTransform.

    The optimizer throws IterationEvents after every iteration. We use
    this to plot the metric space in an image as follows:

    The image size is expected to be 11 x 11 x 11.

    If you wish to use different step lengths along each parametric axis,
    you can use the SetScales() method. This accepts an array, each
    element represents the number of subdivisions per step length. For
    instance scales of [0.5 1 4] along with a step length of 2 will cause
    the optimizer to search the metric space on a grid with x,y,z spacing
    of [1 2 8].

    Physical dimensions of the grid are influenced by both the scales and
    the number of steps along each dimension, a side of the region is
    stepLength*(2*numberOfSteps[d]+1)*scaling[d]. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkExhaustiveOptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkExhaustiveOptimizer_Clone)
    StartWalking = _swig_new_instance_method(_ITKOptimizersBasePython.itkExhaustiveOptimizer_StartWalking)
    ResumeWalking = _swig_new_instance_method(_ITKOptimizersBasePython.itkExhaustiveOptimizer_ResumeWalking)
    StopWalking = _swig_new_instance_method(_ITKOptimizersBasePython.itkExhaustiveOptimizer_StopWalking)
    SetStepLength = _swig_new_instance_method(_ITKOptimizersBasePython.itkExhaustiveOptimizer_SetStepLength)
    SetNumberOfSteps = _swig_new_instance_method(_ITKOptimizersBasePython.itkExhaustiveOptimizer_SetNumberOfSteps)
    GetStepLength = _swig_new_instance_method(_ITKOptimizersBasePython.itkExhaustiveOptimizer_GetStepLength)
    GetNumberOfSteps = _swig_new_instance_method(_ITKOptimizersBasePython.itkExhaustiveOptimizer_GetNumberOfSteps)
    GetCurrentValue = _swig_new_instance_method(_ITKOptimizersBasePython.itkExhaustiveOptimizer_GetCurrentValue)
    GetMaximumMetricValue = _swig_new_instance_method(_ITKOptimizersBasePython.itkExhaustiveOptimizer_GetMaximumMetricValue)
    GetMinimumMetricValue = _swig_new_instance_method(_ITKOptimizersBasePython.itkExhaustiveOptimizer_GetMinimumMetricValue)
    GetMinimumMetricValuePosition = _swig_new_instance_method(_ITKOptimizersBasePython.itkExhaustiveOptimizer_GetMinimumMetricValuePosition)
    GetMaximumMetricValuePosition = _swig_new_instance_method(_ITKOptimizersBasePython.itkExhaustiveOptimizer_GetMaximumMetricValuePosition)
    GetCurrentIndex = _swig_new_instance_method(_ITKOptimizersBasePython.itkExhaustiveOptimizer_GetCurrentIndex)
    GetMaximumNumberOfIterations = _swig_new_instance_method(_ITKOptimizersBasePython.itkExhaustiveOptimizer_GetMaximumNumberOfIterations)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkExhaustiveOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkExhaustiveOptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkExhaustiveOptimizer

        Create a new object of the class itkExhaustiveOptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkExhaustiveOptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkExhaustiveOptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkExhaustiveOptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkExhaustiveOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkExhaustiveOptimizer_swigregister(itkExhaustiveOptimizer)
itkExhaustiveOptimizer___New_orig__ = _ITKOptimizersBasePython.itkExhaustiveOptimizer___New_orig__
itkExhaustiveOptimizer_cast = _ITKOptimizersBasePython.itkExhaustiveOptimizer_cast


def itkGradientDescentOptimizer_New():
    return itkGradientDescentOptimizer.New()

class itkGradientDescentOptimizer(itkSingleValuedNonLinearOptimizer):
    r"""


    Implement a gradient descent optimizer.

    GradientDescentOptimizer implements a simple gradient descent
    optimizer. At each iteration the current position is updated according
    to

    \\[ p_{n+1} = p_n + \\mbox{learningRate} \\,
    \\frac{\\partial f(p_n) }{\\partial p_n} \\]

    The learning rate is a fixed scalar defined via SetLearningRate(). The
    optimizer steps through a user defined number of iterations; no
    convergence checking is done.

    Additionally, user can scale each component, $ \\partial f /
    \\partial p $, by setting a scaling vector using method SetScale().

    See:   RegularStepGradientDescentOptimizer 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkGradientDescentOptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkGradientDescentOptimizer_Clone)
    GetMaximize = _swig_new_instance_method(_ITKOptimizersBasePython.itkGradientDescentOptimizer_GetMaximize)
    SetMaximize = _swig_new_instance_method(_ITKOptimizersBasePython.itkGradientDescentOptimizer_SetMaximize)
    MaximizeOn = _swig_new_instance_method(_ITKOptimizersBasePython.itkGradientDescentOptimizer_MaximizeOn)
    MaximizeOff = _swig_new_instance_method(_ITKOptimizersBasePython.itkGradientDescentOptimizer_MaximizeOff)
    GetMinimize = _swig_new_instance_method(_ITKOptimizersBasePython.itkGradientDescentOptimizer_GetMinimize)
    SetMinimize = _swig_new_instance_method(_ITKOptimizersBasePython.itkGradientDescentOptimizer_SetMinimize)
    MinimizeOn = _swig_new_instance_method(_ITKOptimizersBasePython.itkGradientDescentOptimizer_MinimizeOn)
    MinimizeOff = _swig_new_instance_method(_ITKOptimizersBasePython.itkGradientDescentOptimizer_MinimizeOff)
    AdvanceOneStep = _swig_new_instance_method(_ITKOptimizersBasePython.itkGradientDescentOptimizer_AdvanceOneStep)
    ResumeOptimization = _swig_new_instance_method(_ITKOptimizersBasePython.itkGradientDescentOptimizer_ResumeOptimization)
    StopOptimization = _swig_new_instance_method(_ITKOptimizersBasePython.itkGradientDescentOptimizer_StopOptimization)
    SetLearningRate = _swig_new_instance_method(_ITKOptimizersBasePython.itkGradientDescentOptimizer_SetLearningRate)
    GetLearningRate = _swig_new_instance_method(_ITKOptimizersBasePython.itkGradientDescentOptimizer_GetLearningRate)
    SetNumberOfIterations = _swig_new_instance_method(_ITKOptimizersBasePython.itkGradientDescentOptimizer_SetNumberOfIterations)
    GetNumberOfIterations = _swig_new_instance_method(_ITKOptimizersBasePython.itkGradientDescentOptimizer_GetNumberOfIterations)
    GetCurrentIteration = _swig_new_instance_method(_ITKOptimizersBasePython.itkGradientDescentOptimizer_GetCurrentIteration)
    GetValue = _swig_new_instance_method(_ITKOptimizersBasePython.itkGradientDescentOptimizer_GetValue)
    GetStopCondition = _swig_new_instance_method(_ITKOptimizersBasePython.itkGradientDescentOptimizer_GetStopCondition)
    GetGradient = _swig_new_instance_method(_ITKOptimizersBasePython.itkGradientDescentOptimizer_GetGradient)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkGradientDescentOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkGradientDescentOptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkGradientDescentOptimizer

        Create a new object of the class itkGradientDescentOptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkGradientDescentOptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkGradientDescentOptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkGradientDescentOptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkGradientDescentOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkGradientDescentOptimizer_swigregister(itkGradientDescentOptimizer)
itkGradientDescentOptimizer___New_orig__ = _ITKOptimizersBasePython.itkGradientDescentOptimizer___New_orig__
itkGradientDescentOptimizer_cast = _ITKOptimizersBasePython.itkGradientDescentOptimizer_cast


def itkLBFGSBOptimizer_New():
    return itkLBFGSBOptimizer.New()

class itkLBFGSBOptimizer(itkSingleValuedNonLinearVnlOptimizer):
    r"""


    Limited memory Broyden Fletcher Goldfarb Shannon minimization with
    simple bounds.

    This class is a wrapper for converted Fortran code for performing
    limited memory Broyden Fletcher Goldfarb Shannon minimization with
    simple bounds. The algorithm mininizes a nonlinear function f(x) of n
    variables subject to simple bound constraints of l <= x <= u.

    See also the documentation in Numerics/lbfgsb.c

    References:

    [1] R. H. Byrd, P. Lu and J. Nocedal. A Limited Memory Algorithm for
    Bound Constrained Optimization, (1995), SIAM Journal on Scientific and
    Statistical Computing , 16, 5, pp. 1190-1208.

    [2] C. Zhu, R. H. Byrd and J. Nocedal. L-BFGS-B: Algorithm 778:
    L-BFGS-B, FORTRAN routines for large scale bound constrained
    optimization (1997), ACM Transactions on Mathematical Software, Vol
    23, Num. 4, pp. 550 - 560. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_Clone)
    SetTrace = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_SetTrace)
    GetTrace = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_GetTrace)
    TraceOn = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_TraceOn)
    TraceOff = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_TraceOff)
    SetLowerBound = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_SetLowerBound)
    GetLowerBound = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_GetLowerBound)
    SetUpperBound = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_SetUpperBound)
    GetUpperBound = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_GetUpperBound)
    SetBoundSelection = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_SetBoundSelection)
    GetBoundSelection = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_GetBoundSelection)
    SetCostFunctionConvergenceFactor = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_SetCostFunctionConvergenceFactor)
    GetCostFunctionConvergenceFactor = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_GetCostFunctionConvergenceFactor)
    SetProjectedGradientTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_SetProjectedGradientTolerance)
    GetProjectedGradientTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_GetProjectedGradientTolerance)
    SetMaximumNumberOfIterations = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_SetMaximumNumberOfIterations)
    GetMaximumNumberOfIterations = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_GetMaximumNumberOfIterations)
    SetMaximumNumberOfEvaluations = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_SetMaximumNumberOfEvaluations)
    GetMaximumNumberOfEvaluations = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_GetMaximumNumberOfEvaluations)
    SetMaximumNumberOfCorrections = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_SetMaximumNumberOfCorrections)
    GetMaximumNumberOfCorrections = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_GetMaximumNumberOfCorrections)
    SetScales = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_SetScales)
    GetCurrentIteration = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_GetCurrentIteration)
    GetValue = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_GetValue)
    GetInfinityNormOfProjectedGradient = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_GetInfinityNormOfProjectedGradient)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkLBFGSBOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkLBFGSBOptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkLBFGSBOptimizer

        Create a new object of the class itkLBFGSBOptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkLBFGSBOptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkLBFGSBOptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkLBFGSBOptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkLBFGSBOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkLBFGSBOptimizer_swigregister(itkLBFGSBOptimizer)
itkLBFGSBOptimizer___New_orig__ = _ITKOptimizersBasePython.itkLBFGSBOptimizer___New_orig__
itkLBFGSBOptimizer_cast = _ITKOptimizersBasePython.itkLBFGSBOptimizer_cast


def itkLBFGSOptimizer_New():
    return itkLBFGSOptimizer.New()

class itkLBFGSOptimizer(itkSingleValuedNonLinearVnlOptimizer):
    r"""


    Wrap of the vnl_lbfgs algorithm for use in ITKv4 registration
    framework. The vnl_lbfgs is a wrapper for the NETLIB fortran code by
    Nocedal [1].

    LBFGS is a quasi-Newton method. Quasi-Newton methods use an
    approximate estimate of the inverse Hessian $ (\\nabla^2 f(x) )^{-1}
    $ to scale the gradient step: \\[ x_{n+1} = x_n - s (\\nabla^2
    f(x_n) )^{-1} \\nabla f(x) \\] with $ s $ the step size.

    The inverse Hessian is approximated from the gradients of previous
    iteration and thus only the gradient of the objective function is
    required.

    The step size $ s $ is determined through line search with the
    approach by More and Thuente [4]. This line search approach finds a
    step size such that \\[ \\lVert \\nabla f(x + s (\\nabla^2
    f(x_n) )^{-1} \\nabla f(x) ) \\rVert \\le \\nu \\lVert
    \\nabla f(x) \\rVert \\] The parameter $ \\nu $ is set through
    SetLineSearchAccuracy() (default 0.9) The default step length, i.e.
    starting step length for the line search, is set through
    SetDefaultStepLength() (default 1.0).

    The optimization stops when either the gradient satisfies the
    condition \\[ \\lVert \\nabla f(x) \\rVert \\le \\epsilon
    \\max(1, \\lVert X \\rVert) \\] or a maximum number of
    function evaluations has been reached. The tolerance $\\epsilon$ is
    set through SetGradientConvergenceTolerance() (default 1e-5) and the
    maximum number of function evaluations is set through
    SetMaximumNumberOfFunctionEvaluations() (default 2000).

    Note: The scales set through SetScales should be set or left at one.
    Otherwise the Hessian approximation will be disturbed and the
    optimizer is unlikely to find a minima.

    References:

    [1]NETLIB lbfgs

    [2] Jorge Nocedal. Updating Quasi-Newton Matrices with Limited
    Storage. Mathematics of Computation, Vol. 35, No. 151, pp. 773-782,
    1980.

    [3] Dong C. Liu and Jorge Nocedal. On the limited memory BFGS method
    for large scale optimization. Mathematical Programming B, Vol. 45, No.
    3, pp. 503-528, 1989.

    [4] More, J. J. and D. J. Thuente. Line Search Algorithms with
    Guaranteed Sufficient Decrease. ACM Transactions on Mathematical
    Software 20, no. 3 (1994): 286-307. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkLBFGSOptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSOptimizer_Clone)
    GetOptimizer = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSOptimizer_GetOptimizer)
    SetTrace = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSOptimizer_SetTrace)
    GetTrace = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSOptimizer_GetTrace)
    TraceOn = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSOptimizer_TraceOn)
    TraceOff = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSOptimizer_TraceOff)
    SetMaximumNumberOfFunctionEvaluations = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSOptimizer_SetMaximumNumberOfFunctionEvaluations)
    GetMaximumNumberOfFunctionEvaluations = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSOptimizer_GetMaximumNumberOfFunctionEvaluations)
    SetGradientConvergenceTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSOptimizer_SetGradientConvergenceTolerance)
    GetGradientConvergenceTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSOptimizer_GetGradientConvergenceTolerance)
    SetLineSearchAccuracy = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSOptimizer_SetLineSearchAccuracy)
    GetLineSearchAccuracy = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSOptimizer_GetLineSearchAccuracy)
    SetDefaultStepLength = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSOptimizer_SetDefaultStepLength)
    GetDefaultStepLength = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSOptimizer_GetDefaultStepLength)
    GetValue = _swig_new_instance_method(_ITKOptimizersBasePython.itkLBFGSOptimizer_GetValue)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkLBFGSOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkLBFGSOptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkLBFGSOptimizer

        Create a new object of the class itkLBFGSOptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkLBFGSOptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkLBFGSOptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkLBFGSOptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkLBFGSOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkLBFGSOptimizer_swigregister(itkLBFGSOptimizer)
itkLBFGSOptimizer___New_orig__ = _ITKOptimizersBasePython.itkLBFGSOptimizer___New_orig__
itkLBFGSOptimizer_cast = _ITKOptimizersBasePython.itkLBFGSOptimizer_cast


def itkMultipleValuedNonLinearOptimizer_New():
    return itkMultipleValuedNonLinearOptimizer.New()

class itkMultipleValuedNonLinearOptimizer(itkNonLinearOptimizer):
    r"""


    This class is a base for the Optimization methods that optimize a
    multiple valued function. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkMultipleValuedNonLinearOptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkMultipleValuedNonLinearOptimizer_Clone)
    SetCostFunction = _swig_new_instance_method(_ITKOptimizersBasePython.itkMultipleValuedNonLinearOptimizer_SetCostFunction)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkMultipleValuedNonLinearOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkMultipleValuedNonLinearOptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkMultipleValuedNonLinearOptimizer

        Create a new object of the class itkMultipleValuedNonLinearOptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkMultipleValuedNonLinearOptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkMultipleValuedNonLinearOptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkMultipleValuedNonLinearOptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkMultipleValuedNonLinearOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkMultipleValuedNonLinearOptimizer_swigregister(itkMultipleValuedNonLinearOptimizer)
itkMultipleValuedNonLinearOptimizer___New_orig__ = _ITKOptimizersBasePython.itkMultipleValuedNonLinearOptimizer___New_orig__
itkMultipleValuedNonLinearOptimizer_cast = _ITKOptimizersBasePython.itkMultipleValuedNonLinearOptimizer_cast

class itkMultipleValuedNonLinearVnlOptimizer(itkMultipleValuedNonLinearOptimizer):
    r"""


    This class is a base for the Optimization methods that optimize a
    multi-valued function.

    It is an Adaptor class for optimizers provided by the vnl library 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    SetUseCostFunctionGradient = _swig_new_instance_method(_ITKOptimizersBasePython.itkMultipleValuedNonLinearVnlOptimizer_SetUseCostFunctionGradient)
    UseCostFunctionGradientOn = _swig_new_instance_method(_ITKOptimizersBasePython.itkMultipleValuedNonLinearVnlOptimizer_UseCostFunctionGradientOn)
    UseCostFunctionGradientOff = _swig_new_instance_method(_ITKOptimizersBasePython.itkMultipleValuedNonLinearVnlOptimizer_UseCostFunctionGradientOff)
    GetUseCostFunctionGradient = _swig_new_instance_method(_ITKOptimizersBasePython.itkMultipleValuedNonLinearVnlOptimizer_GetUseCostFunctionGradient)
    GetCachedValue = _swig_new_instance_method(_ITKOptimizersBasePython.itkMultipleValuedNonLinearVnlOptimizer_GetCachedValue)
    GetCachedDerivative = _swig_new_instance_method(_ITKOptimizersBasePython.itkMultipleValuedNonLinearVnlOptimizer_GetCachedDerivative)
    GetCachedCurrentPosition = _swig_new_instance_method(_ITKOptimizersBasePython.itkMultipleValuedNonLinearVnlOptimizer_GetCachedCurrentPosition)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkMultipleValuedNonLinearVnlOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkMultipleValuedNonLinearVnlOptimizer_cast)

# Register itkMultipleValuedNonLinearVnlOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkMultipleValuedNonLinearVnlOptimizer_swigregister(itkMultipleValuedNonLinearVnlOptimizer)
itkMultipleValuedNonLinearVnlOptimizer_cast = _ITKOptimizersBasePython.itkMultipleValuedNonLinearVnlOptimizer_cast


def itkOnePlusOneEvolutionaryOptimizer_New():
    return itkOnePlusOneEvolutionaryOptimizer.New()

class itkOnePlusOneEvolutionaryOptimizer(itkSingleValuedNonLinearOptimizer):
    r"""


    1+1 evolutionary strategy optimizer

    This optimizer searches for the optimal parameters. It changes its
    search radius and position using the grow factor ,shrink factor, and
    isotropic probability function (which is a random unit normal variate
    generator).

    This optimizer needs a cost function and a random unit normal variate
    generator. The cost function should return cost with new position in
    parameter space which will be generated by 1+1 evolutionary strategy.
    Users should plug-in the random unit normal variate generator using
    SetNormalVariateGenerator method.

    The SetEpsilon method is the minimum value for the frobenius_norm of
    the covariance matrix. If the fnorm is smaller than this value, the
    optimization process will stop even before it hits the maximum
    iteration.

    Another way to stop the optimization process is calling the
    StopOptimization method. At next iteration after calling it, the
    optimization process will stop.

    This optimizing scheme was initially developed and implemented by
    Martin Styner, Univ. of North Carolina at Chapel Hill, and his
    colleagues.

    For more details. refer to the following articles. "Parametric
    estimate of intensity inhomogeneities applied to MRI" Martin Styner,
    G. Gerig, Christian Brechbuehler, Gabor Szekely, IEEE TRANSACTIONS ON
    MEDICAL IMAGING; 19(3), pp. 153-165, 2000,
    (http://www.cs.unc.edu/~styner/docs/tmi00.pdf)

    "Evaluation of 2D/3D bias correction with 1+1ES-optimization" Martin
    Styner, Prof. Dr. G. Gerig (IKT, BIWI, ETH Zuerich), TR-197
    (http://www.cs.unc.edu/~styner/docs/StynerTR97.pdf)

    See:  NormalVariateGenerator 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_Clone)
    SetMaximize = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_SetMaximize)
    MaximizeOn = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_MaximizeOn)
    MaximizeOff = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_MaximizeOff)
    GetMaximize = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_GetMaximize)
    GetMinimize = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_GetMinimize)
    SetMinimize = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_SetMinimize)
    MinimizeOn = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_MinimizeOn)
    MinimizeOff = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_MinimizeOff)
    SetMaximumIteration = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_SetMaximumIteration)
    GetMaximumIteration = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_GetMaximumIteration)
    SetGrowthFactor = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_SetGrowthFactor)
    GetGrowthFactor = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_GetGrowthFactor)
    SetShrinkFactor = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_SetShrinkFactor)
    GetShrinkFactor = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_GetShrinkFactor)
    SetInitialRadius = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_SetInitialRadius)
    GetInitialRadius = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_GetInitialRadius)
    SetEpsilon = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_SetEpsilon)
    GetEpsilon = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_GetEpsilon)
    GetFrobeniusNorm = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_GetFrobeniusNorm)
    SetNormalVariateGenerator = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_SetNormalVariateGenerator)
    Initialize = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_Initialize)
    GetCurrentCost = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_GetCurrentCost)
    GetValue = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_GetValue)
    GetCurrentIteration = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_GetCurrentIteration)
    GetInitialized = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_GetInitialized)
    StopOptimization = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_StopOptimization)
    GetCatchGetValueException = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_GetCatchGetValueException)
    SetCatchGetValueException = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_SetCatchGetValueException)
    GetMetricWorstPossibleValue = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_GetMetricWorstPossibleValue)
    SetMetricWorstPossibleValue = _swig_new_instance_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_SetMetricWorstPossibleValue)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkOnePlusOneEvolutionaryOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkOnePlusOneEvolutionaryOptimizer

        Create a new object of the class itkOnePlusOneEvolutionaryOptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkOnePlusOneEvolutionaryOptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkOnePlusOneEvolutionaryOptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkOnePlusOneEvolutionaryOptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkOnePlusOneEvolutionaryOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_swigregister(itkOnePlusOneEvolutionaryOptimizer)
itkOnePlusOneEvolutionaryOptimizer___New_orig__ = _ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer___New_orig__
itkOnePlusOneEvolutionaryOptimizer_cast = _ITKOptimizersBasePython.itkOnePlusOneEvolutionaryOptimizer_cast

class itkParticleSwarmOptimizerBase(itkSingleValuedNonLinearOptimizer):
    r"""


    Abstract implementation of a Particle Swarm Optimization (PSO)
    algorithm.

    The PSO algorithm was originally presented in:  J. Kennedy, R.
    Eberhart, "Particle Swarm Optimization", Proc. IEEE Int. Neural
    Networks, 1995.

    The algorithm is a stochastic global search optimization approach.
    Optimization is performed by maintaining a swarm of particles that
    traverse the parameter space, searching for the optimal function
    value. Associated with each particle are its location and speed, in
    parameter space.

    Swarm initialization is performed within the user supplied parameter
    bounds using either a uniform distribution or a normal distribution
    centered on the initial parameter values supplied by the user. The
    search terminates when the maximal number of iterations has been
    reached or when the change in the best value in the past $g$
    generations is below a threshold and the swarm has collapsed (i.e.
    best personal particle locations are close to the swarm's best
    location in parameter space).

    The actual optimization procedure, updating the swarm, is performed in
    the subclasses, required to implement the UpdateSwarm() method.

    NOTE: This implementation only performs minimization. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    SetInitializeNormalDistribution = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_SetInitializeNormalDistribution)
    GetInitializeNormalDistribution = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_GetInitializeNormalDistribution)
    InitializeNormalDistributionOn = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_InitializeNormalDistributionOn)
    InitializeNormalDistributionOff = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_InitializeNormalDistributionOff)
    SetInitialSwarm = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_SetInitialSwarm)
    ClearSwarm = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_ClearSwarm)
    SetPrintSwarm = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_SetPrintSwarm)
    GetPrintSwarm = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_GetPrintSwarm)
    PrintSwarmOn = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_PrintSwarmOn)
    PrintSwarmOff = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_PrintSwarmOff)
    SetNumberOfParticles = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_SetNumberOfParticles)
    GetNumberOfParticles = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_GetNumberOfParticles)
    SetMaximalNumberOfIterations = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_SetMaximalNumberOfIterations)
    GetMaximalNumberOfIterations = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_GetMaximalNumberOfIterations)
    SetNumberOfGenerationsWithMinimalImprovement = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_SetNumberOfGenerationsWithMinimalImprovement)
    GetNumberOfGenerationsWithMinimalImprovement = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_GetNumberOfGenerationsWithMinimalImprovement)
    SetParameterBounds = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_SetParameterBounds)
    GetParameterBounds = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_GetParameterBounds)
    SetFunctionConvergenceTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_SetFunctionConvergenceTolerance)
    GetFunctionConvergenceTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_GetFunctionConvergenceTolerance)
    SetParametersConvergenceTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_SetParametersConvergenceTolerance)
    GetParametersConvergenceTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_GetParametersConvergenceTolerance)
    GetPercentageParticlesConverged = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_GetPercentageParticlesConverged)
    SetPercentageParticlesConverged = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_SetPercentageParticlesConverged)
    SetSeed = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_SetSeed)
    GetSeed = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_GetSeed)
    SetUseSeed = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_SetUseSeed)
    GetUseSeed = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_GetUseSeed)
    UseSeedOn = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_UseSeedOn)
    UseSeedOff = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_UseSeedOff)
    GetValue = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_GetValue)
    PrintSwarm = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_PrintSwarm)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkParticleSwarmOptimizerBase
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_cast)

# Register itkParticleSwarmOptimizerBase in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_swigregister(itkParticleSwarmOptimizerBase)
itkParticleSwarmOptimizerBase_cast = _ITKOptimizersBasePython.itkParticleSwarmOptimizerBase_cast


def itkPowellOptimizer_New():
    return itkPowellOptimizer.New()

class itkPowellOptimizer(itkSingleValuedNonLinearOptimizer):
    r"""


    Implements Powell optimization using Brent line search.

    The code in this class was adapted from the Wikipedia and the
    netlib.org zeroin function.

    http://www.netlib.org/go/zeroin.fhttp://en.wikipedia.org/wiki/Brent_me
    thodhttp://en.wikipedia.org/wiki/Golden_section_search

    This optimizer needs a cost function. Partial derivatives of that
    function are not required.

    For an N-dimensional parameter space, each iteration
    minimizes(maximizes) the function in N (initially orthogonal)
    directions. Typically only 2-5 iterations are required. If gradients
    are available, consider a conjugate gradient line search strategy.

    The SetStepLength determines the initial distance to step in a line
    direction when bounding the minimum (using bracketing triple spaced
    using a golden search strategy).

    The StepTolerance terminates optimization when the parameter values
    are known to be within this (scaled) distance of the local extreme.

    The ValueTolerance terminates optimization when the cost function
    values at the current parameters and at the local extreme are likely
    (within a second order approximation) to be within this is tolerance.

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkPowellOptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_Clone)
    SetMaximize = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_SetMaximize)
    MaximizeOn = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_MaximizeOn)
    MaximizeOff = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_MaximizeOff)
    GetMaximize = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_GetMaximize)
    SetMaximumIteration = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_SetMaximumIteration)
    GetMaximumIteration = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_GetMaximumIteration)
    SetMaximumLineIteration = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_SetMaximumLineIteration)
    GetMaximumLineIteration = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_GetMaximumLineIteration)
    SetStepLength = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_SetStepLength)
    GetStepLength = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_GetStepLength)
    SetStepTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_SetStepTolerance)
    GetStepTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_GetStepTolerance)
    SetValueTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_SetValueTolerance)
    GetValueTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_GetValueTolerance)
    GetCurrentCost = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_GetCurrentCost)
    GetValue = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_GetValue)
    GetCurrentIteration = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_GetCurrentIteration)
    GetCurrentLineIteration = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_GetCurrentLineIteration)
    StopOptimization = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_StopOptimization)
    GetCatchGetValueException = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_GetCatchGetValueException)
    SetCatchGetValueException = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_SetCatchGetValueException)
    GetMetricWorstPossibleValue = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_GetMetricWorstPossibleValue)
    SetMetricWorstPossibleValue = _swig_new_instance_method(_ITKOptimizersBasePython.itkPowellOptimizer_SetMetricWorstPossibleValue)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkPowellOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkPowellOptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkPowellOptimizer

        Create a new object of the class itkPowellOptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkPowellOptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkPowellOptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkPowellOptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkPowellOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkPowellOptimizer_swigregister(itkPowellOptimizer)
itkPowellOptimizer___New_orig__ = _ITKOptimizersBasePython.itkPowellOptimizer___New_orig__
itkPowellOptimizer_cast = _ITKOptimizersBasePython.itkPowellOptimizer_cast


def itkQuaternionRigidTransformGradientDescentOptimizer_New():
    return itkQuaternionRigidTransformGradientDescentOptimizer.New()

class itkQuaternionRigidTransformGradientDescentOptimizer(itkGradientDescentOptimizer):
    r"""


    Implement a gradient descent optimizer.

    QuaternionRigidTransformGradientDescentOptimizer is an extension to
    the simple gradient descent optimizer implemented in
    GradientDescentOptimizer. At each iteration the current position is
    updated according to

    p(n+1) = p(n) + learningRate * d f(p(n)) / d p(n)

    \\[ p_{n+1} = p_n + \\mbox{learningRate} \\,
    \\frac{\\partial f(p_n) }{\\partial p_n} \\]

    The learning rate is a fixed scalar defined via SetLearningRate(). The
    optimizer steps through a user defined number of iterations; no
    convergence checking is done. The first four components of p are
    assumed to be the four components of the quaternion. After each
    update, the quaternion is normalized to have a magnitude of one. This
    ensures the the transform is purely rigid.

    See:   GradientDescentOptimizer 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkQuaternionRigidTransformGradientDescentOptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkQuaternionRigidTransformGradientDescentOptimizer_Clone)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkQuaternionRigidTransformGradientDescentOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkQuaternionRigidTransformGradientDescentOptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkQuaternionRigidTransformGradientDescentOptimizer

        Create a new object of the class itkQuaternionRigidTransformGradientDescentOptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkQuaternionRigidTransformGradientDescentOptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkQuaternionRigidTransformGradientDescentOptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkQuaternionRigidTransformGradientDescentOptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkQuaternionRigidTransformGradientDescentOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkQuaternionRigidTransformGradientDescentOptimizer_swigregister(itkQuaternionRigidTransformGradientDescentOptimizer)
itkQuaternionRigidTransformGradientDescentOptimizer___New_orig__ = _ITKOptimizersBasePython.itkQuaternionRigidTransformGradientDescentOptimizer___New_orig__
itkQuaternionRigidTransformGradientDescentOptimizer_cast = _ITKOptimizersBasePython.itkQuaternionRigidTransformGradientDescentOptimizer_cast


def itkRegularStepGradientDescentBaseOptimizer_New():
    return itkRegularStepGradientDescentBaseOptimizer.New()

class itkRegularStepGradientDescentBaseOptimizer(itkSingleValuedNonLinearOptimizer):
    r"""


    Implement a gradient descent optimizer. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_Clone)
    SetMaximize = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_SetMaximize)
    GetMaximize = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_GetMaximize)
    MaximizeOn = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_MaximizeOn)
    MaximizeOff = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_MaximizeOff)
    GetMinimize = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_GetMinimize)
    SetMinimize = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_SetMinimize)
    MinimizeOn = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_MinimizeOn)
    MinimizeOff = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_MinimizeOff)
    ResumeOptimization = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_ResumeOptimization)
    StopOptimization = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_StopOptimization)
    SetMaximumStepLength = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_SetMaximumStepLength)
    SetMinimumStepLength = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_SetMinimumStepLength)
    SetRelaxationFactor = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_SetRelaxationFactor)
    SetNumberOfIterations = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_SetNumberOfIterations)
    SetGradientMagnitudeTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_SetGradientMagnitudeTolerance)
    GetCurrentStepLength = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_GetCurrentStepLength)
    GetMaximumStepLength = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_GetMaximumStepLength)
    GetMinimumStepLength = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_GetMinimumStepLength)
    GetRelaxationFactor = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_GetRelaxationFactor)
    GetNumberOfIterations = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_GetNumberOfIterations)
    GetGradientMagnitudeTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_GetGradientMagnitudeTolerance)
    GetCurrentIteration = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_GetCurrentIteration)
    GetStopCondition = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_GetStopCondition)
    GetValue = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_GetValue)
    GetGradient = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_GetGradient)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkRegularStepGradientDescentBaseOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkRegularStepGradientDescentBaseOptimizer

        Create a new object of the class itkRegularStepGradientDescentBaseOptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkRegularStepGradientDescentBaseOptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkRegularStepGradientDescentBaseOptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkRegularStepGradientDescentBaseOptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkRegularStepGradientDescentBaseOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_swigregister(itkRegularStepGradientDescentBaseOptimizer)
itkRegularStepGradientDescentBaseOptimizer___New_orig__ = _ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer___New_orig__
itkRegularStepGradientDescentBaseOptimizer_cast = _ITKOptimizersBasePython.itkRegularStepGradientDescentBaseOptimizer_cast


def itkRegularStepGradientDescentOptimizer_New():
    return itkRegularStepGradientDescentOptimizer.New()

class itkRegularStepGradientDescentOptimizer(itkRegularStepGradientDescentBaseOptimizer):
    r"""


    Implement a gradient descent optimizer. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentOptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentOptimizer_Clone)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkRegularStepGradientDescentOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkRegularStepGradientDescentOptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkRegularStepGradientDescentOptimizer

        Create a new object of the class itkRegularStepGradientDescentOptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkRegularStepGradientDescentOptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkRegularStepGradientDescentOptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkRegularStepGradientDescentOptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkRegularStepGradientDescentOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkRegularStepGradientDescentOptimizer_swigregister(itkRegularStepGradientDescentOptimizer)
itkRegularStepGradientDescentOptimizer___New_orig__ = _ITKOptimizersBasePython.itkRegularStepGradientDescentOptimizer___New_orig__
itkRegularStepGradientDescentOptimizer_cast = _ITKOptimizersBasePython.itkRegularStepGradientDescentOptimizer_cast


def itkSPSAOptimizer_New():
    return itkSPSAOptimizer.New()

class itkSPSAOptimizer(itkSingleValuedNonLinearOptimizer):
    r"""


    An optimizer based on simultaneous perturbation...

    This optimizer is an implementation of the Simultaneous Perturbation
    Stochastic Approximation method, described in:

    http://www.jhuapl.edu/SPSA/

    Spall, J.C. (1998), "An Overview of the Simultaneous Perturbation
    Method for Efficient Optimization," Johns Hopkins APL Technical
    Digest, vol. 19, pp. 482-492 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkSPSAOptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_Clone)
    AdvanceOneStep = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_AdvanceOneStep)
    ResumeOptimization = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_ResumeOptimization)
    StopOptimization = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_StopOptimization)
    GetValue = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_GetValue)
    GuessParameters = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_GuessParameters)
    GetCurrentIteration = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_GetCurrentIteration)
    GetStopCondition = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_GetStopCondition)
    GetLearningRate = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_GetLearningRate)
    GetGradientMagnitude = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_GetGradientMagnitude)
    GetGradient = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_GetGradient)
    SetSa = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_SetSa)
    GetSa = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_GetSa)
    Seta = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_Seta)
    Geta = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_Geta)
    SetSc = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_SetSc)
    GetSc = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_GetSc)
    Setc = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_Setc)
    Getc = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_Getc)
    SetA = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_SetA)
    GetA = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_GetA)
    SetAlpha = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_SetAlpha)
    GetAlpha = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_GetAlpha)
    SetGamma = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_SetGamma)
    GetGamma = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_GetGamma)
    GetMaximize = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_GetMaximize)
    SetMaximize = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_SetMaximize)
    MaximizeOn = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_MaximizeOn)
    MaximizeOff = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_MaximizeOff)
    GetMinimize = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_GetMinimize)
    SetMinimize = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_SetMinimize)
    MinimizeOn = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_MinimizeOn)
    MinimizeOff = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_MinimizeOff)
    SetNumberOfPerturbations = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_SetNumberOfPerturbations)
    GetNumberOfPerturbations = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_GetNumberOfPerturbations)
    GetStateOfConvergence = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_GetStateOfConvergence)
    SetStateOfConvergenceDecayRate = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_SetStateOfConvergenceDecayRate)
    GetStateOfConvergenceDecayRate = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_GetStateOfConvergenceDecayRate)
    SetMinimumNumberOfIterations = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_SetMinimumNumberOfIterations)
    GetMinimumNumberOfIterations = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_GetMinimumNumberOfIterations)
    SetMaximumNumberOfIterations = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_SetMaximumNumberOfIterations)
    GetMaximumNumberOfIterations = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_GetMaximumNumberOfIterations)
    SetTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_SetTolerance)
    GetTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkSPSAOptimizer_GetTolerance)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkSPSAOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkSPSAOptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkSPSAOptimizer

        Create a new object of the class itkSPSAOptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkSPSAOptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkSPSAOptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkSPSAOptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkSPSAOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkSPSAOptimizer_swigregister(itkSPSAOptimizer)
itkSPSAOptimizer___New_orig__ = _ITKOptimizersBasePython.itkSPSAOptimizer___New_orig__
itkSPSAOptimizer_cast = _ITKOptimizersBasePython.itkSPSAOptimizer_cast


def itkVersorRigid3DTransformOptimizer_New():
    return itkVersorRigid3DTransformOptimizer.New()

class itkVersorRigid3DTransformOptimizer(itkRegularStepGradientDescentBaseOptimizer):
    r"""


    Implement a gradient descent optimizer for the VersorRigid3DTransform
    parameter space.

    VersorRigid3DTransformOptimizer is a variant of the gradient descent
    optimizer implemented in RegularStepGradientDescentOptimizer.

    Versors are not in a vector space, for that reason, the classical
    gradient descent algorithm has to be modified in order to be
    applicable to Versors (unit quaternions) that form the group SO(3).

    The Versor space has only three degrees of freedom, even though
    Versors are represented using four values.

    This optimizer assumes that the CostFunction to be optimized has an
    itk::Versor and an itk::Vector as parameters.

    See:   RegularStepGradientDescentOptimizer

    See:  Versor

    See:  VersorRigid3DTransform 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkVersorRigid3DTransformOptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkVersorRigid3DTransformOptimizer_Clone)
    StepAlongGradient = _swig_new_instance_method(_ITKOptimizersBasePython.itkVersorRigid3DTransformOptimizer_StepAlongGradient)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkVersorRigid3DTransformOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkVersorRigid3DTransformOptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkVersorRigid3DTransformOptimizer

        Create a new object of the class itkVersorRigid3DTransformOptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkVersorRigid3DTransformOptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkVersorRigid3DTransformOptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkVersorRigid3DTransformOptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkVersorRigid3DTransformOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkVersorRigid3DTransformOptimizer_swigregister(itkVersorRigid3DTransformOptimizer)
itkVersorRigid3DTransformOptimizer___New_orig__ = _ITKOptimizersBasePython.itkVersorRigid3DTransformOptimizer___New_orig__
itkVersorRigid3DTransformOptimizer_cast = _ITKOptimizersBasePython.itkVersorRigid3DTransformOptimizer_cast


def itkVersorTransformOptimizer_New():
    return itkVersorTransformOptimizer.New()

class itkVersorTransformOptimizer(itkRegularStepGradientDescentBaseOptimizer):
    r"""


    Implement a gradient descent optimizer.

    VersorTransformOptimizer is a variant of the gradient descent
    optimizer implemented in RegularStepGradientDescentOptimizer.

    Versors are not in a vector space, for that reason, the classical
    gradient descent algorithm has to be modified in order to be
    applicable to Versors (unit quaternions) that form the group SO(3).

    The Versor space has only three degrees of freedom, even though
    Versors are represented using four values.

    This optimizer assumes that the CostFunction to be optimized has an
    itk::Versor as parameter.

    See:   RegularStepGradientDescentOptimizer

    See:  Versor

    See:  VersorTransform 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkVersorTransformOptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkVersorTransformOptimizer_Clone)
    StepAlongGradient = _swig_new_instance_method(_ITKOptimizersBasePython.itkVersorTransformOptimizer_StepAlongGradient)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkVersorTransformOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkVersorTransformOptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkVersorTransformOptimizer

        Create a new object of the class itkVersorTransformOptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkVersorTransformOptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkVersorTransformOptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkVersorTransformOptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkVersorTransformOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkVersorTransformOptimizer_swigregister(itkVersorTransformOptimizer)
itkVersorTransformOptimizer___New_orig__ = _ITKOptimizersBasePython.itkVersorTransformOptimizer___New_orig__
itkVersorTransformOptimizer_cast = _ITKOptimizersBasePython.itkVersorTransformOptimizer_cast


def itkCumulativeGaussianOptimizer_New():
    return itkCumulativeGaussianOptimizer.New()

class itkCumulativeGaussianOptimizer(itkMultipleValuedNonLinearOptimizer):
    r"""


    This is an optimizer specific to estimating the parameters of
    Cumulative Gaussian sampled data.

    This optimizer will only work if the data array is sampled from a
    Cumulative Gaussian curve. It's more of a curve fitter than an
    optimizer, with the advantage of being fast and specific. It works by
    taking the derivative of the Cumulative Gaussian sample then
    repeatedly extending the tails of the Gaussian and recalculating the
    Gaussian parameters until the change in iterations is within tolerance
    or very small. The Gaussian is then integrated to reproduce the
    Cumulative Gaussian and the asymptotes are estimated by using least
    squares fit to estimate the constant from integration. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkCumulativeGaussianOptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkCumulativeGaussianOptimizer_Clone)
    SetDifferenceTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkCumulativeGaussianOptimizer_SetDifferenceTolerance)
    GetDifferenceTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkCumulativeGaussianOptimizer_GetDifferenceTolerance)
    SetVerbose = _swig_new_instance_method(_ITKOptimizersBasePython.itkCumulativeGaussianOptimizer_SetVerbose)
    GetVerbose = _swig_new_instance_method(_ITKOptimizersBasePython.itkCumulativeGaussianOptimizer_GetVerbose)
    GetComputedMean = _swig_new_instance_method(_ITKOptimizersBasePython.itkCumulativeGaussianOptimizer_GetComputedMean)
    GetComputedStandardDeviation = _swig_new_instance_method(_ITKOptimizersBasePython.itkCumulativeGaussianOptimizer_GetComputedStandardDeviation)
    GetUpperAsymptote = _swig_new_instance_method(_ITKOptimizersBasePython.itkCumulativeGaussianOptimizer_GetUpperAsymptote)
    GetLowerAsymptote = _swig_new_instance_method(_ITKOptimizersBasePython.itkCumulativeGaussianOptimizer_GetLowerAsymptote)
    GetFinalSampledArray = _swig_new_instance_method(_ITKOptimizersBasePython.itkCumulativeGaussianOptimizer_GetFinalSampledArray)
    GetFitError = _swig_new_instance_method(_ITKOptimizersBasePython.itkCumulativeGaussianOptimizer_GetFitError)
    SetDataArray = _swig_new_instance_method(_ITKOptimizersBasePython.itkCumulativeGaussianOptimizer_SetDataArray)
    PrintArray = _swig_new_instance_method(_ITKOptimizersBasePython.itkCumulativeGaussianOptimizer_PrintArray)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkCumulativeGaussianOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkCumulativeGaussianOptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkCumulativeGaussianOptimizer

        Create a new object of the class itkCumulativeGaussianOptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkCumulativeGaussianOptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkCumulativeGaussianOptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkCumulativeGaussianOptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkCumulativeGaussianOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkCumulativeGaussianOptimizer_swigregister(itkCumulativeGaussianOptimizer)
itkCumulativeGaussianOptimizer___New_orig__ = _ITKOptimizersBasePython.itkCumulativeGaussianOptimizer___New_orig__
itkCumulativeGaussianOptimizer_cast = _ITKOptimizersBasePython.itkCumulativeGaussianOptimizer_cast


def itkFRPROptimizer_New():
    return itkFRPROptimizer.New()

class itkFRPROptimizer(itkPowellOptimizer):
    r"""


    Implements Fletch-Reeves & Polak-Ribiere optimization using dBrent
    line search.

    This optimizer needs a cost function. This optimizer needs to be able
    to compute partial derivatives of the cost function with respect to
    each parameter.

    The SetStepLength determines the initial distance to step in a line
    direction when bounding the minimum (using bracketing triple spaced
    using a derivative-based search strategy).

    The StepTolerance terminates optimization when the parameter values
    are known to be within this (scaled) distance of the local extreme.

    The ValueTolerance terminates optimization when the cost function
    values at the current parameters and at the local extreme are likely
    (within a second order approximation) to be within this is tolerance.

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkFRPROptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkFRPROptimizer_Clone)
    SetUseUnitLengthGradient = _swig_new_instance_method(_ITKOptimizersBasePython.itkFRPROptimizer_SetUseUnitLengthGradient)
    GetUseUnitLengthGradient = _swig_new_instance_method(_ITKOptimizersBasePython.itkFRPROptimizer_GetUseUnitLengthGradient)
    SetToFletchReeves = _swig_new_instance_method(_ITKOptimizersBasePython.itkFRPROptimizer_SetToFletchReeves)
    SetToPolakRibiere = _swig_new_instance_method(_ITKOptimizersBasePython.itkFRPROptimizer_SetToPolakRibiere)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkFRPROptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkFRPROptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkFRPROptimizer

        Create a new object of the class itkFRPROptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkFRPROptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkFRPROptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkFRPROptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkFRPROptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkFRPROptimizer_swigregister(itkFRPROptimizer)
itkFRPROptimizer___New_orig__ = _ITKOptimizersBasePython.itkFRPROptimizer___New_orig__
itkFRPROptimizer_cast = _ITKOptimizersBasePython.itkFRPROptimizer_cast


def itkInitializationBiasedParticleSwarmOptimizer_New():
    return itkInitializationBiasedParticleSwarmOptimizer.New()

class itkInitializationBiasedParticleSwarmOptimizer(itkParticleSwarmOptimizerBase):
    r"""


    Implementation of a biased/regularized Particle Swarm Optimization
    (PSO) algorithm.

    This PSO algorithm was originally described in: M. P. Wachowiak, R.
    Smolikova, Y. Zheng, J. M. Zurada, A. S. Elmaghraby, "An approach to
    multimodal biomedical image registration utilizing particle swarm
    optimization", IEEE Trans. Evol. Comput., vol. 8(3): 289-301, 2004.

    The algorithm uses a stochastic optimization approach. Optimization is
    performed by maintaining a swarm (flock) of particles that traverse
    the parameter space, searching for the optimal function value.
    Associated with each particle are its location and speed, in parameter
    space. A particle's next location is determined by its current
    location, its current speed, the location of the best function value
    it previously encountered, the location of the best function value the
    particles in its neighborhood previously encountered and the initial
    position the user specified.

    The assumption is that the user's initial parameter settings are close
    to the minimum, which is often the case for registration. The initial
    parameter values are incorporated into the PSO's update rules, biasing
    the search in their direction. The swarms update equations are thus:

    $v_i(t+1) = wv_i(t) + c_1u_1(p_i-x_i(t)) + c_2u_2(p_g-x_i(t)) +
    c_3u_3(x_{init} - x_i(t))$ $x_i(t+1) = clampToBounds(x_i(t) +
    v_i(t+1))$

    where $u_i$ are $~U(0,1)$ and $w,c_1,c_2, c_3$ are user selected
    weights, and c_3 is linearly decreased per iteration so that it is in
    $c_3=initial, 0$.

    Swarm initialization is performed within the user supplied parameter
    bounds using a uniform distribution or a normal distribution centered
    on the initial parameter values supplied by the user, $x_{init}$. The
    search terminates when the maximal number of iterations has been
    reached or when the change in the best value in the past $g$
    generations is below a threshold and the swarm has collapsed (i.e.
    particles are close to each other in parameter space).

    This implementation only performs minimization. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkInitializationBiasedParticleSwarmOptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkInitializationBiasedParticleSwarmOptimizer_Clone)
    SetInertiaCoefficient = _swig_new_instance_method(_ITKOptimizersBasePython.itkInitializationBiasedParticleSwarmOptimizer_SetInertiaCoefficient)
    GetInertiaCoefficient = _swig_new_instance_method(_ITKOptimizersBasePython.itkInitializationBiasedParticleSwarmOptimizer_GetInertiaCoefficient)
    SetPersonalCoefficient = _swig_new_instance_method(_ITKOptimizersBasePython.itkInitializationBiasedParticleSwarmOptimizer_SetPersonalCoefficient)
    GetPersonalCoefficient = _swig_new_instance_method(_ITKOptimizersBasePython.itkInitializationBiasedParticleSwarmOptimizer_GetPersonalCoefficient)
    SetGlobalCoefficient = _swig_new_instance_method(_ITKOptimizersBasePython.itkInitializationBiasedParticleSwarmOptimizer_SetGlobalCoefficient)
    GetGlobalCoefficient = _swig_new_instance_method(_ITKOptimizersBasePython.itkInitializationBiasedParticleSwarmOptimizer_GetGlobalCoefficient)
    SetInitializationCoefficient = _swig_new_instance_method(_ITKOptimizersBasePython.itkInitializationBiasedParticleSwarmOptimizer_SetInitializationCoefficient)
    GetInitializationCoefficient = _swig_new_instance_method(_ITKOptimizersBasePython.itkInitializationBiasedParticleSwarmOptimizer_GetInitializationCoefficient)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkInitializationBiasedParticleSwarmOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkInitializationBiasedParticleSwarmOptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkInitializationBiasedParticleSwarmOptimizer

        Create a new object of the class itkInitializationBiasedParticleSwarmOptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkInitializationBiasedParticleSwarmOptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkInitializationBiasedParticleSwarmOptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkInitializationBiasedParticleSwarmOptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkInitializationBiasedParticleSwarmOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkInitializationBiasedParticleSwarmOptimizer_swigregister(itkInitializationBiasedParticleSwarmOptimizer)
itkInitializationBiasedParticleSwarmOptimizer___New_orig__ = _ITKOptimizersBasePython.itkInitializationBiasedParticleSwarmOptimizer___New_orig__
itkInitializationBiasedParticleSwarmOptimizer_cast = _ITKOptimizersBasePython.itkInitializationBiasedParticleSwarmOptimizer_cast


def itkLevenbergMarquardtOptimizer_New():
    return itkLevenbergMarquardtOptimizer.New()

class itkLevenbergMarquardtOptimizer(itkMultipleValuedNonLinearVnlOptimizer):
    r"""


    Wrap of the vnl_levenberg_marquardt algorithm. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkLevenbergMarquardtOptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkLevenbergMarquardtOptimizer_Clone)
    GetOptimizer = _swig_new_instance_method(_ITKOptimizersBasePython.itkLevenbergMarquardtOptimizer_GetOptimizer)
    SetNumberOfIterations = _swig_new_instance_method(_ITKOptimizersBasePython.itkLevenbergMarquardtOptimizer_SetNumberOfIterations)
    SetValueTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkLevenbergMarquardtOptimizer_SetValueTolerance)
    SetGradientTolerance = _swig_new_instance_method(_ITKOptimizersBasePython.itkLevenbergMarquardtOptimizer_SetGradientTolerance)
    SetEpsilonFunction = _swig_new_instance_method(_ITKOptimizersBasePython.itkLevenbergMarquardtOptimizer_SetEpsilonFunction)
    GetValue = _swig_new_instance_method(_ITKOptimizersBasePython.itkLevenbergMarquardtOptimizer_GetValue)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkLevenbergMarquardtOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkLevenbergMarquardtOptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkLevenbergMarquardtOptimizer

        Create a new object of the class itkLevenbergMarquardtOptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkLevenbergMarquardtOptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkLevenbergMarquardtOptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkLevenbergMarquardtOptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkLevenbergMarquardtOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkLevenbergMarquardtOptimizer_swigregister(itkLevenbergMarquardtOptimizer)
itkLevenbergMarquardtOptimizer___New_orig__ = _ITKOptimizersBasePython.itkLevenbergMarquardtOptimizer___New_orig__
itkLevenbergMarquardtOptimizer_cast = _ITKOptimizersBasePython.itkLevenbergMarquardtOptimizer_cast


def itkParticleSwarmOptimizer_New():
    return itkParticleSwarmOptimizer.New()

class itkParticleSwarmOptimizer(itkParticleSwarmOptimizerBase):
    r"""


    Implementation of a Particle Swarm Optimization (PSO) algorithm.

    The PSO algorithm was originally presented in:  J. Kennedy, R.
    Eberhart, "Particle Swarm Optimization", Proc. IEEE Int. Neural
    Networks, 1995.

    The algorithm uses a stochastic optimization approach. Optimization is
    performed by maintaining a swarm (flock) of particles that traverse
    the parameter space, searching for the optimal function value.
    Associated with each particle are its location and speed, in parameter
    space. A particle's next location is determined by its current
    location, its current speed, the location of the best function value
    it previously encountered, and the location of the best function value
    the particles in its neighborhood previously encountered. In this
    implementation we use a global neighborhood with the following update
    equations: \\[v_i(t+1) = wv_i(t) + c_1u_1(p_i-x_i(t)) + c_2u_2(p_g-
    x_i(t))\\] \\[x_i(t+1) = clampToBounds(x_i(t) + v_i(t+1))\\]

    where $u_i$ are $~U(0,1)$ and $w,c_1,c_2$ are user selected weights.

    Swarm initialization is performed within the user supplied parameter
    bounds using a uniform distribution or a normal distribution centered
    on the initial parameter values supplied by the user. The search
    terminates when the maximal number of iterations has been reached or
    when the change in the best value in the past $g$ generations is below
    a threshold and the swarm has collapsed (i.e. particles are close to
    each other in parameter space).

    NOTE: This implementation only performs minimization. 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizer___New_orig__)
    Clone = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizer_Clone)
    SetInertiaCoefficient = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizer_SetInertiaCoefficient)
    GetInertiaCoefficient = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizer_GetInertiaCoefficient)
    SetPersonalCoefficient = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizer_SetPersonalCoefficient)
    GetPersonalCoefficient = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizer_GetPersonalCoefficient)
    SetGlobalCoefficient = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizer_SetGlobalCoefficient)
    GetGlobalCoefficient = _swig_new_instance_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizer_GetGlobalCoefficient)
    __swig_destroy__ = _ITKOptimizersBasePython.delete_itkParticleSwarmOptimizer
    cast = _swig_new_static_method(_ITKOptimizersBasePython.itkParticleSwarmOptimizer_cast)

    def New(*args, **kargs):
        """New() -> itkParticleSwarmOptimizer

        Create a new object of the class itkParticleSwarmOptimizer and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkParticleSwarmOptimizer.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkParticleSwarmOptimizer.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkParticleSwarmOptimizer.__New_orig__()
        import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkParticleSwarmOptimizer in _ITKOptimizersBasePython:
_ITKOptimizersBasePython.itkParticleSwarmOptimizer_swigregister(itkParticleSwarmOptimizer)
itkParticleSwarmOptimizer___New_orig__ = _ITKOptimizersBasePython.itkParticleSwarmOptimizer___New_orig__
itkParticleSwarmOptimizer_cast = _ITKOptimizersBasePython.itkParticleSwarmOptimizer_cast



