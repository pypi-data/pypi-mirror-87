{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ZFP to compress data\n",
    "\n",
    "## Importing the required libraries/packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to import the following libraries and/or packages:\n",
    "\n",
    "- `numpy`,\n",
    "- `xarray`,\n",
    "- `math`\n",
    "- `zfpy` which is a python wrapper for ZFP algorithm,\n",
    "- `getsizeof` to check the array sizes in bytes.\n",
    "\n",
    "For the full documentation of `zfpy` you could click\n",
    "[here](https://zfp.readthedocs.io/en/release0.5.5/python.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import math\n",
    "import zfpy\n",
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will provide a separate instruction on how to install `zfpy`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressing a numpy array\n",
    "\n",
    "First we try to compress some numpy array of type `integer` and `double`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(int_arr): <class 'numpy.ndarray'>\n",
      "int_array.dtype: int64\n",
      "number of elements: 100\n",
      "int_array.nbytes: 800\n",
      "size in memory: 896\n"
     ]
    }
   ],
   "source": [
    "int_arr = np.arange(0, 100, dtype=\"int64\")\n",
    "print(f\"type(int_arr): {type(int_arr)}\")\n",
    "print(f\"int_array.dtype: {int_arr.dtype}\")\n",
    "print(f\"number of elements: {int_arr.size}\")\n",
    "print(f\"int_array.nbytes: {int_arr.nbytes}\")\n",
    "print(f\"size in memory: {getsizeof(int_arr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our integer `ndarray` which has 100 `int64` elements, i.e. 8B per elements,\n",
    "consumes 800B for the data portion. The total size in memory (visible to Python)\n",
    "is 896B.\n",
    "\n",
    "Now let's compress it using `zfpy`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(int_arr_compressed): <class 'bytes'>\n",
      "number of elements: 264\n",
      "size in memory: 297\n"
     ]
    }
   ],
   "source": [
    "int_arr_compressed = zfpy.compress_numpy(int_arr)\n",
    "print(f\"type(int_arr_compressed): {type(int_arr_compressed)}\")\n",
    "print(f\"number of elements: {len(int_arr_compressed)}\")\n",
    "print(f\"size in memory: {getsizeof(int_arr_compressed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compressed version has 264 elements of type bytes, but the overall memory\n",
    "consumption is 264B.\n",
    "\n",
    "if we donot provide any other parameters/arguments, the lossless compression is\n",
    "used. This means that once decompressed, we should get the exact data. Let's\n",
    "check it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min difference: 0\n",
      "max difference: 0\n"
     ]
    }
   ],
   "source": [
    "int_arr_decompressed = zfpy.decompress_numpy(int_arr_compressed)\n",
    "print(f\"min difference: {(int_arr_decompressed- int_arr).min()}\")\n",
    "print(f\"max difference: {(int_arr_decompressed- int_arr).max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BTW, now you know how to decompress data using `zfpy` as well.\n",
    "\n",
    "Let's repeat the same procedure for a `double` array:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(double_arr): <class 'numpy.ndarray'>\n",
      "double_array.dtype: float64\n",
      "number of elements: 100\n",
      "double_array.nbytes: 800\n",
      "size in memory: 896\n"
     ]
    }
   ],
   "source": [
    "double_arr = np.arange(0, 100, dtype=\"double\")\n",
    "print(f\"type(double_arr): {type(double_arr)}\")\n",
    "print(f\"double_array.dtype: {double_arr.dtype}\")\n",
    "print(f\"number of elements: {double_arr.size}\")\n",
    "print(f\"double_array.nbytes: {double_arr.nbytes}\")\n",
    "print(f\"size in memory: {getsizeof(double_arr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compressing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(double_arr_compressed): <class 'bytes'>\n",
      "number of elements: 128\n",
      "size in memory: 161\n"
     ]
    }
   ],
   "source": [
    "double_arr_compressed = zfpy.compress_numpy(double_arr)\n",
    "print(f\"type(double_arr_compressed): {type(double_arr_compressed)}\")\n",
    "print(f\"number of elements: {len(double_arr_compressed)}\")\n",
    "print(f\"size in memory: {getsizeof(double_arr_compressed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although both `int_arr` and `double_arr` are storing same numbers (but in\n",
    "different data type) it appears that the `double` is compressed better. Let's\n",
    "decompress and make sure it was lossless:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min difference: 0.0\n",
      "max difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "double_arr_decompressed = zfpy.decompress_numpy(double_arr_compressed)\n",
    "print(f\"min difference: {(double_arr_decompressed- double_arr).min()}\")\n",
    "print(f\"max difference: {(double_arr_decompressed- double_arr).max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All looking good so far.\n",
    "\n",
    "Now let's try a real data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressing real data set\n",
    "\n",
    "Now let's open some real data and check it out:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(TS): <class 'numpy.ndarray'>\n",
      "TS.dtype: float32\n",
      "number of elements: 5529600\n",
      "TS.nbytes: 22118400B or 21.09MB\n",
      "size in memory: 128\n"
     ]
    }
   ],
   "source": [
    "ds = xr.open_dataset(\"../../../data/cam-fv/orig.TS.100days.nc\")\n",
    "TS = ds.TS.values\n",
    "print(f\"type(TS): {type(TS)}\")\n",
    "print(f\"TS.dtype: {TS.dtype}\")\n",
    "print(f\"number of elements: {TS.size}\")\n",
    "print((f\"TS.nbytes: {TS.nbytes}B or %.2fMB\") % (TS.nbytes / 1024 / 1024))\n",
    "\n",
    "print(f\"size in memory: {getsizeof(TS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compressing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(TS_compressed): <class 'bytes'>\n",
      "number of elements: 12464768 (11.89MB)\n",
      "size in memory: 12464801\n"
     ]
    }
   ],
   "source": [
    "TS_compressed = zfpy.compress_numpy(TS)\n",
    "print(f\"type(TS_compressed): {type(TS_compressed)}\")\n",
    "print(\n",
    "    (f\"number of elements: {len(TS_compressed)} (%.2fMB)\")\n",
    "    % (len(TS_compressed) / 1024 / 1024)\n",
    ")\n",
    "print(f\"size in memory: {getsizeof(TS_compressed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the compression ratio:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression ratio: 56.35%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"compression ratio: %0.2f%%\\n\" % (len(TS_compressed) / TS.nbytes * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's decompress and make sure we are getting the original input:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min difference: 0.0\n",
      "max difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "TS_decompressed = zfpy.decompress_numpy(TS_compressed)\n",
    "print(f\"min difference: {(TS_decompressed- TS).min()}\")\n",
    "print(f\"max difference: {(TS_decompressed- TS).max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All is good. Now let's try different tolerance and see how the error and\n",
    "compression ratio changes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying tolerance = 10^p; 0 <= p <= 5. Please wait ......\n",
      "\n",
      "\n",
      " Tolerance     CR               RMSE (min, max err)\n",
      "-----------------------------------------------------------\n",
      " -1.00000     56.35    0.00000000 ( 0.00000000, 0.00000000)\n",
      "  0.00001     58.65    0.00000028 (-0.00001526, 0.00000000)\n",
      "  0.00010     54.91    0.00000135 (-0.00003052, 0.00001526)\n",
      "  0.00100     42.41    0.00004350 (-0.00027466, 0.00024414)\n",
      "  0.01000     33.03    0.00034111 (-0.00196838, 0.00222778)\n",
      "  0.10000     23.71    0.00266330 (-0.01647949, 0.01643372)\n",
      "  1.00000     12.70    0.03611637 (-0.27249146, 0.26344299)\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tolerance = -1\n",
    "tmpTS_compressed = zfpy.compress_numpy(TS, tolerance=tolerance)\n",
    "compression_ratio = len(tmpTS_compressed) / TS.nbytes * 100\n",
    "tmpTS_decompressed = zfpy.decompress_numpy(tmpTS_compressed)\n",
    "rmse = np.sqrt(np.power(tmpTS_decompressed - TS, 2).mean())\n",
    "min_err = (tmpTS_decompressed - TS).min()\n",
    "max_err = (tmpTS_decompressed - TS).max()\n",
    "results = [(tolerance, compression_ratio, rmse, min_err, max_err)]\n",
    "zfpy.compress_numpy(TS, tolerance=-1)\n",
    "max_p = 5\n",
    "print(f\"Trying tolerance = 10^p; 0 <= p <= {max_p}. Please wait \", end=\"\")\n",
    "for p in range(-max_p, 1):\n",
    "    print(\".\", end=\"\")\n",
    "    tolerance = math.pow(10, p)\n",
    "    tmpTS_compressed = zfpy.compress_numpy(TS, tolerance=tolerance)\n",
    "\n",
    "    compression_ratio = len(tmpTS_compressed) / TS.nbytes * 100\n",
    "    tmpTS_decompressed = zfpy.decompress_numpy(tmpTS_compressed)\n",
    "\n",
    "    rmse = np.sqrt(np.power(tmpTS_decompressed - TS, 2).mean())\n",
    "\n",
    "    min_err = (tmpTS_decompressed - TS).min()\n",
    "    max_err = (tmpTS_decompressed - TS).max()\n",
    "\n",
    "    results.append((tolerance, compression_ratio, rmse, min_err, max_err))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\" Tolerance     CR               RMSE (min, max err)\")\n",
    "print(\"-----------------------------------------------------------\")\n",
    "for e in results:\n",
    "    print((f\"%9.{max_p}f     %5.2f    %.8f (%11.8f,%11.8f)\") % e)\n",
    "print(\"-----------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMIP6 2019.10",
   "language": "python",
   "name": "cmip6-201910"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
