# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['gradient_utils']

package_data = \
{'': ['*']}

install_requires = \
['hyperopt==0.1.2',
 'numpy==1.18.5',
 'prometheus-client>=0.8,<0.10',
 'pymongo>=3.11.0,<4.0.0',
 'wheel>=0.35.1,<0.36.0']

setup_kwargs = {
    'name': 'gradient-utils',
    'version': '0.3.2',
    'description': 'This is an SDK for performing Machine Learning with Gradient.',
    'long_description': '![GitHubSplash](https://user-images.githubusercontent.com/585865/65443342-e630d300-ddfb-11e9-9bcd-de1d2033ea60.png)\n\nGradient Utils\n=================\n\n![PyPI](https://img.shields.io/pypi/v/gradient-utils)\n[![codecov](https://codecov.io/gh/Paperspace/gradient-utils/branch/master/graph/badge.svg)](https://codecov.io/gh/Paperspace/gradient-utils)\n\n<br>\n\n**Get started:** [Create Account](https://www.paperspace.com/account/signup?gradient=true) • [Install CLI](https://docs.paperspace.com/gradient/get-started/install-the-cli) • [Tutorials](https://docs.paperspace.com/gradient/tutorials) • [Docs](https://docs.paperspace.com/gradient)\n\n**Resources:** [Website](https://gradient.paperspace.com/) • [Blog](https://blog.paperspace.com/) • [Support](https://support.paperspace.com/hc/en-us) • [Contact Sales](https://use.paperspace.com/contact-sales)\n\n<br>\n\nGradient is an an end-to-end MLOps platform that enables individuals and organizations to quickly develop, train, and deploy Deep Learning models.  The Gradient software stack runs on any infrastructure e.g. AWS, GCP, on-premise and low-cost [Paperspace GPUs](https://gradient.paperspace.com/instances).  Leverage automatic versioning, distributed training, built-in graphs & metrics, hyperparameter search, GradientCI, 1-click Jupyter Notebooks, our Python SDK, and more. \n\nThis is an SDK for performing Machine Learning with Gradientº, it can be installed in addition to [gradient-cli](https://github.com/Paperspace/gradient-cli).\n\n# Requirements\n\nThis SDK requires Python 3.6+.\n\nTo install it, run:\n\n```bash\npip install gradient-utils\n```\n\n# Usage\n\n## Multinode Helper Functions\n\n### Multinode GRPC Tensorflow\n\n**Set the TF_CONFIG environment variable**\nFor multi-worker training, you need to set the `TF_CONFIG` environment variable for each binary running in your cluster. Set the value of `TF_CONFIG` to a JSON string that specifies each task within the cluster, including each task\'s address and role within the cluster. We\'ve provided a Kubernetes template in the tensorflow/ecosystem repo which sets `TF_CONFIG` for your training tasks.\n\n**get_tf_config()**\n\nFunction to set value of `TF_CONFIG` when run on machines within Paperspace infrastructure.\n\nIt can raise a `ConfigError` exception with message if there\'s a problem with its configuration in a particular machine.\n\n**_Usage example:_**\n\n```python\nfrom gradient_utils import get_tf_config\n\nget_tf_config()\n```\n\n## Hyperparameter Tuning\n\nCurrently, Gradientº only supports _Hyperopt_ for Hyperparameter Tuning.\n\n**hyper_tune()**\n\nFunction to run hyperparameter tuning.\n\nIt accepts the following arguments:\n\n- `train_model`\n  User model to tune.\n- `hparam_def`\n  User definition (scope) of search space.\n  To set this value, refer to [hyperopt documentation](https://github.com/hyperopt/hyperopt).\n- `algo`\n  Search algorithm.\n  _Default_: `tpe.suggest` (from hyperopt).\n- `max_ecals`\n  Maximum number of function evaluations to allow before returning.\n  _Default_: `25`.\n- `func`\n  Function to be run by hyper tune.\n  _Default_: `fmin` (from hyperopt). _Do not change this value if you do not know what you are doing!_\n\nIt returns a dict with information about the tuning process.\n\nIt can raise a `ConfigError` exception with message if there\'s no connection to MongoDB.\n\n**Note:** _You do not need to worry about setting your MongoDB version; it will be set within Paperspace infrastructure for hyperparameter tuning._\n\n**Usage example:**\n\n```python\nfrom gradient_utils import hyper_tune\n\n# Prepare model and search scope\n\n# minimal version\nargmin1 = hyper_tune(model, scope)\n\n# pass more arguments\nargmin2 = hyper_tune(model, scope, algo=tpe.suggest, max_evals=100)\n```\n\n## Utility Functions\n\n**get_mongo_conn_str()**\n\nFunction to check and construct MongoDB connection string.\n\nIt returns a connection string to MongoDB.\n\nIt can raise a `ConfigError` exception with message if there\'s a problem with any values used to prepare the MongoDB connection string.\n\nUsage example:\n\n```python\nfrom gradient_utils import get_mongo_conn_str\n\nconn_str = get_mongo_conn_str()\n```\n\n**data_dir()**\n\nFunction to retrieve path to job space.\n\nUsage example:\n\n```python\nfrom gradient_utils import data_dir\n\njob_space = data_dir()\n```\n\n**model_dir()**\n\nFunction to retrieve path to model space.\n\nUsage example:\n\n```python\nfrom gradient_utils import model_dir\n\nmodel_path = model_dir(model_name)\n```\n\n**export_dir()**\n\nFunction to retrieve path for model export.\n\nUsage example:\n\n```python\nfrom gradient_utils import export_dir\n\nmodel_path = export_dir(model_name)\n```\n\n**worker_hosts()**\n\nFunction to retrieve information about worker hosts.\n\nUsage example:\n\n```python\nfrom gradient_utils import worker_hosts\n\nmodel_path = worker_hosts()\n```\n\n**ps_hosts()**\n\nFunction to retrieve information about Paperspace hosts.\n\nUsage example:\n\n```python\nfrom gradient_utils import ps_hosts\n\nmodel_path = ps_hosts()\n```\n\n**task_index()**\n\nFunction to retrieve information about task index.\n\nUsage example:\n\n```python\nfrom gradient_utils import task_index\n\nmodel_path = task_index()\n```\n\n**job_name()**\n\nFunction to retrieve information about job name.\n\nUsage example:\n\n```python\nfrom gradient_utils import job_name\n\nmodel_path = job_name()\n```\n\n## Metrics\nPrometheus wrapper for logging custom metrics\n\nUsage example:\n\n```python\nfrom gradient_utils import MetricsLogger\n# Comment: add_metrics is not supported at the moment. Stay tuned!\n# from gradient_utils.metrics import add_metrics\nm_logger = MetricsLogger()\nm_logger.add_gauge("some_metric_1")\nm_logger["some_metric_1"].set(3)\nm_logger["some_metric_1"].inc()\n\nm_logger.add_gauge("some_metric_2")\nm_logger["some_metric_2"].set_to_current_time()\n\nm_logger.push_metrics()\n\n# Insert metrics with a single command\n# add_metrics({\n#   \'loss\': 0.25,\n#   \'accuracy\': 0.99\n# })\n\n```\n\n# Contributing\n\n## Setup\nWe use Docker and Docker-compose to run the tests locally.\n\n```\n# To setup the integration test framework\ndocker-compose up --remove-orphans -d pushgateway\ndocker-compose build utils\n\n# To run tests\ndocker-compose -f docker-compose.ci.yml run utils poetry run pytest\n```\n\n',
    'author': 'Paperspace Co.',
    'author_email': 'info@paperspace.com',
    'maintainer': None,
    'maintainer_email': None,
    'url': 'https://github.com/Paperspace/gradient-utils',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'python_requires': '>=3.6,<4.0',
}


setup(**setup_kwargs)
